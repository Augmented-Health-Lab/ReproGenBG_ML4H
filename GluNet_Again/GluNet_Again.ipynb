{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "from GlucNet_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"../OhioT1DM/2018/train/559-ws-training.xml\"\n",
    "tree = ET.parse(filepath)\n",
    "root = tree.getroot()\n",
    "glucose = read_ohio(filepath, \"glucose_level\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2% lower threshold: 64.0\n",
      "98% upper threshold: 337.0\n"
     ]
    }
   ],
   "source": [
    "glucose_dict = {entry[0]['ts']: entry[0]['value'] for entry in glucose}\n",
    "\n",
    "# Create the multi-channel database\n",
    "g_data = []\n",
    "for timestamp in glucose_dict:\n",
    "    record = {\n",
    "        'timestamp': timestamp,\n",
    "        'glucose_value': glucose_dict[timestamp],\n",
    "        # 'meal_type': None,\n",
    "        # 'meal_carbs': 0\n",
    "    }\n",
    "    \n",
    "    g_data.append(record)\n",
    "glucose_df = pd.DataFrame(g_data)\n",
    "\n",
    "# Convert glucose values to numeric type for analysis\n",
    "glucose_df['glucose_value'] = pd.to_numeric(glucose_df['glucose_value'])\n",
    "\n",
    "# Calculate percentiles\n",
    "lower_percentile = np.percentile(glucose_df['glucose_value'], 2)\n",
    "upper_percentile = np.percentile(glucose_df['glucose_value'], 98)\n",
    "\n",
    "# Print thresholds\n",
    "print(f\"2% lower threshold: {lower_percentile}\")\n",
    "print(f\"98% upper threshold: {upper_percentile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2, P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_3\n",
      "before:  2021-12-12 04:54:00\n",
      "after:  2021-12-12 05:29:00\n",
      "segment_3\n",
      "before:  2021-12-12 12:34:00\n",
      "after:  2021-12-12 12:44:00\n",
      "segment_3\n",
      "before:  2021-12-12 22:09:00\n",
      "after:  2021-12-12 22:39:00\n",
      "segment_7\n",
      "before:  2021-12-16 17:53:00\n",
      "after:  2021-12-16 18:18:00\n",
      "segment_14\n",
      "before:  2021-12-22 17:52:00\n",
      "after:  2021-12-22 18:52:00\n",
      "segment_14\n",
      "before:  2021-12-24 17:52:00\n",
      "after:  2021-12-24 18:32:00\n",
      "segment_15\n",
      "before:  2021-12-26 18:57:00\n",
      "after:  2021-12-26 19:22:00\n",
      "segment_18\n",
      "before:  2022-01-01 20:50:00\n",
      "after:  2022-01-01 21:10:00\n",
      "segment_21\n",
      "before:  2022-01-06 06:26:00\n",
      "after:  2022-01-06 07:21:00\n",
      "segment_25\n",
      "before:  2022-01-08 18:05:00\n",
      "after:  2022-01-08 18:40:00\n",
      "segment_29\n",
      "before:  2022-01-14 01:05:00\n",
      "after:  2022-01-14 01:35:00\n",
      "segment_31\n",
      "before:  2022-01-16 19:11:00\n",
      "after:  2022-01-16 19:56:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:35: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  datetime_list = np.array(pd.date_range(start=min(segments[sequence]['timestamp']), end=max(segments[sequence]['timestamp']), freq='5T').tolist())\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:48: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  time_index_interpolated = pd.date_range(start=reference_time, periods=len(interpolated_xs), freq='5T')\n"
     ]
    }
   ],
   "source": [
    "segments = segement_data_as_1hour(glucose_df)\n",
    "interpolated_segements = detect_missing_and_spline_interpolate(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '18' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '45' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '63' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '75' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '48' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '70' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '65' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '55' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '50' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '45' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '40' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '45' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '60' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '55' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '20' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:421: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '36' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'carbs'] = closest_meal['carbs']\n"
     ]
    }
   ],
   "source": [
    "meal = read_ohio(filepath, \"meal\", False)\n",
    "\n",
    "flattened_meal_data = [item[0] for item in meal]  # Take the first (and only) item from each sublist\n",
    "\n",
    "# Convert to DataFrame\n",
    "meal_df = pd.DataFrame(flattened_meal_data)\n",
    "\n",
    "meal_df['assigned'] = False\n",
    "\n",
    "meal_updated_segments = update_segments_with_meals(interpolated_segements, meal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>value</th>\n",
       "      <th>assigned</th>\n",
       "      <th>end_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07 00:00:00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-07 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07 04:00:00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-07 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07 08:00:00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-07 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-07 11:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-08 00:00:00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-08 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-08 04:00:00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-08 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-08 08:00:00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-08 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-08 11:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-08 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-08 18:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-11 00:00:00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-11 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ts value  assigned              end_ts\n",
       "0 2021-12-07 00:00:00  0.65     False 2021-12-07 04:00:00\n",
       "1 2021-12-07 04:00:00  0.73     False 2021-12-07 08:00:00\n",
       "2 2021-12-07 08:00:00  1.15     False 2021-12-07 11:00:00\n",
       "3 2021-12-07 11:00:00   0.9     False 2021-12-08 00:00:00\n",
       "4 2021-12-08 00:00:00  0.65     False 2021-12-08 04:00:00\n",
       "5 2021-12-08 04:00:00  0.73     False 2021-12-08 08:00:00\n",
       "6 2021-12-08 08:00:00  1.15     False 2021-12-08 11:00:00\n",
       "7 2021-12-08 11:00:00   0.9     False 2021-12-08 18:00:00\n",
       "8 2021-12-08 18:00:00  1.25     False 2021-12-11 00:00:00\n",
       "9 2021-12-11 00:00:00  0.65     False 2021-12-11 04:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basal = read_ohio(filepath, \"basal\", False)\n",
    "\n",
    "flattened_basal_data = [item[0] for item in basal]  # Take the first (and only) item from each sublist\n",
    "\n",
    "# Convert to DataFrame\n",
    "basal_df = pd.DataFrame(flattened_basal_data)\n",
    "\n",
    "basal_df['assigned'] = False\n",
    "basal_df['end_ts'] = basal_df['ts'].shift(-1)\n",
    "basal_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basal_updated_segments = update_segments_with_basal(meal_updated_segments, basal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_begin</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>type</th>\n",
       "      <th>dose</th>\n",
       "      <th>bwz_carb_input</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07 01:08:04</td>\n",
       "      <td>2021-12-07 01:08:04</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.6</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07 11:21:49</td>\n",
       "      <td>2021-12-07 11:21:49</td>\n",
       "      <td>normal</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07 23:50:34</td>\n",
       "      <td>2021-12-07 23:50:34</td>\n",
       "      <td>normal</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-08 05:11:38</td>\n",
       "      <td>2021-12-08 05:11:38</td>\n",
       "      <td>normal</td>\n",
       "      <td>4.1</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-08 11:27:23</td>\n",
       "      <td>2021-12-08 11:27:23</td>\n",
       "      <td>normal</td>\n",
       "      <td>6.3</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-08 19:06:34</td>\n",
       "      <td>2021-12-08 19:06:34</td>\n",
       "      <td>normal</td>\n",
       "      <td>2.2</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-09 02:05:46</td>\n",
       "      <td>2021-12-09 02:05:46</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-09 08:20:50</td>\n",
       "      <td>2021-12-09 08:20:50</td>\n",
       "      <td>normal</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-09 13:15:16</td>\n",
       "      <td>2021-12-09 13:15:16</td>\n",
       "      <td>normal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-09 15:03:10</td>\n",
       "      <td>2021-12-09 15:03:10</td>\n",
       "      <td>normal</td>\n",
       "      <td>4.5</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts_begin              ts_end    type dose bwz_carb_input  \\\n",
       "0 2021-12-07 01:08:04 2021-12-07 01:08:04  normal  1.6             25   \n",
       "1 2021-12-07 11:21:49 2021-12-07 11:21:49  normal  9.3              0   \n",
       "2 2021-12-07 23:50:34 2021-12-07 23:50:34  normal  3.8              0   \n",
       "3 2021-12-08 05:11:38 2021-12-08 05:11:38  normal  4.1             45   \n",
       "4 2021-12-08 11:27:23 2021-12-08 11:27:23  normal  6.3             63   \n",
       "5 2021-12-08 19:06:34 2021-12-08 19:06:34  normal  2.2             20   \n",
       "6 2021-12-09 02:05:46 2021-12-09 02:05:46  normal  0.6              0   \n",
       "7 2021-12-09 08:20:50 2021-12-09 08:20:50  normal  4.2              0   \n",
       "8 2021-12-09 13:15:16 2021-12-09 13:15:16  normal  2.0             20   \n",
       "9 2021-12-09 15:03:10 2021-12-09 15:03:10  normal  4.5             45   \n",
       "\n",
       "   assigned  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8     False  \n",
       "9     False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Bolus into the dataframe\n",
    "bolus = read_ohio_bolus_tempbasal(filepath, \"bolus\", False)\n",
    "\n",
    "flattened_bolus_data = [item[0] for item in bolus]  # Take the first (and only) item from each sublist\n",
    "\n",
    "# Convert to DataFrame\n",
    "bolus_df = pd.DataFrame(flattened_bolus_data)\n",
    "\n",
    "bolus_df['assigned'] = False\n",
    "bolus_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.1' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.6' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.8' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.6' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '7.2' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.8' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.8' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.9' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.2' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.7' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.7' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n",
      "/dartfs-hpc/rc/home/j/f007g3j/ReproGenBG_ML4H/GluNet_Again/GlucNet_functions.py:312: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.at[i, 'bolus_dose'] = closest_bolus['dose']\n"
     ]
    }
   ],
   "source": [
    "bolus_updated_segments = update_segments_with_bolus(basal_updated_segments, bolus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempbasal = read_ohio_bolus_tempbasal(filepath, \"temp_basal\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_begin</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>value</th>\n",
       "      <th>assigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07 04:49:28</td>\n",
       "      <td>2021-12-07 05:08:39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07 17:01:44</td>\n",
       "      <td>2021-12-07 18:03:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-08 15:12:19</td>\n",
       "      <td>2021-12-08 16:12:27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-09 11:11:10</td>\n",
       "      <td>2021-12-09 12:19:17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-10 14:14:00</td>\n",
       "      <td>2021-12-10 16:14:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-10 19:51:28</td>\n",
       "      <td>2021-12-10 21:30:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-11 17:25:48</td>\n",
       "      <td>2021-12-11 18:10:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-15 01:32:00</td>\n",
       "      <td>2021-12-15 03:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-17 20:24:00</td>\n",
       "      <td>2021-12-17 22:24:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-22 19:52:33</td>\n",
       "      <td>2021-12-22 21:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts_begin              ts_end value  assigned\n",
       "0 2021-12-07 04:49:28 2021-12-07 05:08:39   0.0     False\n",
       "1 2021-12-07 17:01:44 2021-12-07 18:03:20   0.0     False\n",
       "2 2021-12-08 15:12:19 2021-12-08 16:12:27   0.0     False\n",
       "3 2021-12-09 11:11:10 2021-12-09 12:19:17   0.0     False\n",
       "4 2021-12-10 14:14:00 2021-12-10 16:14:00   0.0     False\n",
       "5 2021-12-10 19:51:28 2021-12-10 21:30:37   0.0     False\n",
       "6 2021-12-11 17:25:48 2021-12-11 18:10:10   0.0     False\n",
       "7 2021-12-15 01:32:00 2021-12-15 03:30:00   0.0     False\n",
       "8 2021-12-17 20:24:00 2021-12-17 22:24:00   0.0     False\n",
       "9 2021-12-22 19:52:33 2021-12-22 21:52:00   0.0     False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_tempbasal_data = [item[0] for item in tempbasal]  # Take the first (and only) item from each sublist\n",
    "\n",
    "# Convert to DataFrame\n",
    "tempbasal_df = pd.DataFrame(flattened_tempbasal_data)\n",
    "\n",
    "tempbasal_df['assigned'] = False\n",
    "tempbasal_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Update the segments with meal data\n",
    "final_updated_segments = update_segments_with_tempbasal(bolus_updated_segments, tempbasal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_delta_transform(labels_list):\n",
    "    # label_lower_percentile = -12.75\n",
    "    # label_upper_percentile = 12.85\n",
    "    label_lower_percentile = np.percentile(labels_list, 10)\n",
    "    label_upper_percentile = np.percentile(labels_list, 90)\n",
    "    transformed_labels = []\n",
    "    for label in labels_list:\n",
    "        if label <= label_lower_percentile:\n",
    "            transformed_labels.append(1)\n",
    "        elif label_lower_percentile < label < label_upper_percentile:\n",
    "            trans_label = round((256/(label_upper_percentile - label_lower_percentile))*(label + abs(label_lower_percentile) + 0.05))\n",
    "            transformed_labels.append(trans_label)\n",
    "        elif label >= label_upper_percentile:\n",
    "            transformed_labels.append(256)\n",
    "    return transformed_labels\n",
    "\n",
    "\n",
    "def prepare_dataset(segments, ph):\n",
    "    '''\n",
    "    ph = 6, 30 minutes ahead\n",
    "    ph = 12, 60 minutes ahead\n",
    "    '''\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    raw_glu_list = []\n",
    "    \n",
    "    history_len = 15\n",
    "    \n",
    "    # Iterate over each segment\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        # Ensure all columns are of numeric type\n",
    "        segment_df['carbs'] = pd.to_numeric(segment_df['carbs'], errors='coerce')\n",
    "        segment_df['basal_rate'] = pd.to_numeric(segment_df['basal_rate'], errors='coerce')\n",
    "        segment_df['bolus_dose'] = pd.to_numeric(segment_df['bolus_dose'], errors='coerce')\n",
    "\n",
    "        # Fill NaNs that might have been introduced by conversion errors\n",
    "        segment_df.fillna(0, inplace=True)\n",
    "\n",
    "        # Maximum index for creating a complete feature set\n",
    "        print(\"len of segment_df is \", len(segment_df))\n",
    "        max_index = len(segment_df) - (history_len + ph)  # Subtracting only 15+ph to ensure i + 15 + ph is within bounds\n",
    "        \n",
    "        # Iterate through the data to create feature-label pairs\n",
    "        for i in range(max_index):\n",
    "            # Extracting features from index i to i+15\n",
    "            segment_df = segment_df.reset_index(drop = True)\n",
    "            features = segment_df.loc[i:i+history_len, ['glucose_value', 'carbs', 'basal_rate', 'bolus_dose']].values\n",
    "            # Extracting label for index i+15+ph\n",
    "            # label = segment_df.loc[i+15+ph, 'glucose_value'] - segment_df.loc[i+15, 'glucose_value']\n",
    "            \n",
    "            raw_glu_list.append(segment_df.loc[i+history_len+ph, 'glucose_value'])\n",
    "            features_list.append(features)\n",
    "            # labels_list.append(label)\n",
    "            \n",
    "    print(\"len of features_list \" + str(len(features_list)))\n",
    "    # print(\"len of labels_list \" + str(len(labels_list)))\n",
    "    \n",
    "    # new_labels_list = label_delta_transform(labels_list)    \n",
    "    # print(\"after label transform, the len of label list \"+str(len(new_labels_list)))    \n",
    "    \n",
    "    return features_list, raw_glu_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of segment_df is  228\n",
      "len of segment_df is  958\n",
      "len of segment_df is  635\n",
      "len of segment_df is  26\n",
      "len of segment_df is  70\n",
      "len of segment_df is  412\n",
      "len of segment_df is  287\n",
      "len of segment_df is  142\n",
      "len of segment_df is  346\n",
      "len of segment_df is  142\n",
      "len of segment_df is  258\n",
      "len of segment_df is  70\n",
      "len of segment_df is  142\n",
      "len of segment_df is  1161\n",
      "len of segment_df is  272\n",
      "len of segment_df is  70\n",
      "len of segment_df is  1291\n",
      "len of segment_df is  299\n",
      "len of segment_df is  433\n",
      "len of segment_df is  174\n",
      "len of segment_df is  504\n",
      "len of segment_df is  153\n",
      "len of segment_df is  272\n",
      "len of segment_df is  21\n",
      "len of segment_df is  212\n",
      "len of segment_df is  228\n",
      "len of segment_df is  251\n",
      "len of segment_df is  429\n",
      "len of segment_df is  491\n",
      "len of segment_df is  364\n",
      "len of segment_df is  525\n",
      "len of features_list 10215\n"
     ]
    }
   ],
   "source": [
    "features_list, labels_list = prepare_dataset(segments, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "# Step 1: Split into 80% train+val and 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(features_array, labels_array, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 2: Split the 80% into 70% train and 10% val (0.7/0.8 = 0.875)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, shuffle=False)\n",
    "\n",
    "# Convert the splits to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([32, 16, 4])\n",
      "Label batch shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to PyTorch tensors\n",
    "features_tensor = torch.tensor(features_list, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels_list, dtype=torch.float32).unsqueeze(1)  # Making labels tensor 2D\n",
    "\n",
    "feature_label_tensor = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(feature_label_tensor, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example of using DataLoader in a training loop\n",
    "for features, labels in train_loader:\n",
    "    print(\"Features batch shape:\", features.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    # Example: print(features, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cuda option\n",
    "dtype = torch.FloatTensor # data type\n",
    "ltype = torch.LongTensor # label type\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('use gpu')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveNet(\n",
      "  (initial_conv): Conv1d(4, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "  (blocks): ModuleList(\n",
      "    (0): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (1): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (2): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (3): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (final_conv1): Conv1d(32, 128, kernel_size=(2,), stride=(1,))\n",
      "  (final_conv2): Conv1d(128, 256, kernel_size=(2,), stride=(1,))\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the dilate CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WaveNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, dilation):\n",
    "        super(WaveNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, in_channels, kernel_size=2, dilation=dilation, padding=1+dilation - 2^(dilation-1))\n",
    "        self.conv2 = nn.Conv1d(in_channels, in_channels, kernel_size=2, dilation=dilation, padding=dilation)\n",
    "        self.res_conv = nn.Conv1d(in_channels, in_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(\"shape of x: \", x.shape)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        # print(\"shape of first out: \", out.shape)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        # print(\"shape of second out: \", out.shape)\n",
    "        res = self.res_conv(x)\n",
    "        # print(\"shape of res: \", res.shape)\n",
    "        return out + res\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, dilations):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.initial_conv = nn.Conv1d(in_channels, 32, kernel_size=2, padding=1)\n",
    "        self.blocks = nn.ModuleList([WaveNetBlock(32, dilation) for dilation in dilations])\n",
    "        self.final_conv1 = nn.Conv1d(32, 128, kernel_size=2, padding=0)\n",
    "        self.final_conv2 = nn.Conv1d(128, 256, kernel_size=2, padding=0)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.initial_conv(x))\n",
    "        for block in self.blocks:\n",
    "            # print(\"enter the block loop\")\n",
    "            x = block(x)\n",
    "        x = F.relu(self.final_conv1(x))\n",
    "        x = F.relu(self.final_conv2(x))\n",
    "        x = x[:, :, -1]  # Get the last time step\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 4  # Number of features\n",
    "output_channels = 1  # Predicting a single value (glucose level)\n",
    "num_blocks = 4  # Number of WaveNet blocks\n",
    "dilations = [2**i for i in range(num_blocks)]  # Dilation rates: 1, 2, 4, 8\n",
    "\n",
    "model = WaveNet(input_channels, output_channels, num_blocks, dilations)\n",
    "print(model)\n",
    "\n",
    "# Example of how to define the loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0008)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([32, 16, 4])\n",
      "Input tensor total elements: 2048\n",
      "Target tensor shape: torch.Size([32, 1])\n",
      "Sequence length: 16\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(\"Input tensor shape:\", inputs.shape)\n",
    "    print(\"Input tensor total elements:\", inputs.numel())\n",
    "    print(\"Target tensor shape:\", targets.shape)\n",
    "    print(\"Sequence length:\", inputs.shape[1])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of segment_df is  228\n",
      "len of segment_df is  958\n",
      "len of segment_df is  635\n",
      "len of segment_df is  26\n",
      "len of segment_df is  70\n",
      "len of segment_df is  412\n",
      "len of segment_df is  287\n",
      "len of segment_df is  142\n",
      "len of segment_df is  346\n",
      "len of segment_df is  142\n",
      "len of segment_df is  258\n",
      "len of segment_df is  70\n",
      "len of segment_df is  142\n",
      "len of segment_df is  1161\n",
      "len of segment_df is  272\n",
      "len of segment_df is  70\n",
      "len of segment_df is  1291\n",
      "len of segment_df is  299\n",
      "len of segment_df is  433\n",
      "len of segment_df is  174\n",
      "len of segment_df is  504\n",
      "len of segment_df is  153\n",
      "len of segment_df is  272\n",
      "len of segment_df is  21\n",
      "len of segment_df is  212\n",
      "len of segment_df is  228\n",
      "len of segment_df is  251\n",
      "len of segment_df is  429\n",
      "len of segment_df is  491\n",
      "len of segment_df is  364\n",
      "len of segment_df is  525\n",
      "len of features_list 10215\n"
     ]
    }
   ],
   "source": [
    "features_list, labels_list = prepare_dataset(final_updated_segments, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "# Step 1: Split into 80% train+val and 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(features_array, labels_array, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 2: Split the 80% into 70% train and 10% val (0.7/0.8 = 0.875)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, shuffle=False)\n",
    "\n",
    "# Convert the splits to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "# Step 1: Split into 80% train+val and 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(features_array, labels_array, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 2: Split the 80% into 70% train and 10% val (0.7/0.8 = 0.875)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, shuffle=False)\n",
    "\n",
    "# Convert the splits to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([32, 16, 4])\n",
      "Label batch shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to PyTorch tensors\n",
    "features_tensor = torch.tensor(features_list, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels_list, dtype=torch.float32).unsqueeze(1)  # Making labels tensor 2D\n",
    "\n",
    "feature_label_tensor = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(feature_label_tensor, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example of using DataLoader in a training loop\n",
    "for features, labels in train_loader:\n",
    "    print(\"Features batch shape:\", features.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    # Example: print(features, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cuda option\n",
    "dtype = torch.FloatTensor # data type\n",
    "ltype = torch.LongTensor # label type\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('use gpu')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaveNet(\n",
      "  (initial_conv): Conv1d(4, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "  (blocks): ModuleList(\n",
      "    (0): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (1): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (2): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (3): WaveNetBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "      (res_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (final_conv1): Conv1d(32, 128, kernel_size=(2,), stride=(1,))\n",
      "  (final_conv2): Conv1d(128, 256, kernel_size=(2,), stride=(1,))\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the dilate CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WaveNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, dilation):\n",
    "        super(WaveNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, in_channels, kernel_size=2, dilation=dilation, padding=1+dilation - 2^(dilation-1))\n",
    "        self.conv2 = nn.Conv1d(in_channels, in_channels, kernel_size=2, dilation=dilation, padding=dilation)\n",
    "        self.res_conv = nn.Conv1d(in_channels, in_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(\"shape of x: \", x.shape)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        # print(\"shape of first out: \", out.shape)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        # print(\"shape of second out: \", out.shape)\n",
    "        res = self.res_conv(x)\n",
    "        # print(\"shape of res: \", res.shape)\n",
    "        return out + res\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, dilations):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.initial_conv = nn.Conv1d(in_channels, 32, kernel_size=2, padding=1)\n",
    "        self.blocks = nn.ModuleList([WaveNetBlock(32, dilation) for dilation in dilations])\n",
    "        self.final_conv1 = nn.Conv1d(32, 128, kernel_size=2, padding=0)\n",
    "        self.final_conv2 = nn.Conv1d(128, 256, kernel_size=2, padding=0)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.initial_conv(x))\n",
    "        for block in self.blocks:\n",
    "            # print(\"enter the block loop\")\n",
    "            x = block(x)\n",
    "        x = F.relu(self.final_conv1(x))\n",
    "        x = F.relu(self.final_conv2(x))\n",
    "        x = x[:, :, -1]  # Get the last time step\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 4  # Number of features\n",
    "output_channels = 1  # Predicting a single value (glucose level)\n",
    "num_blocks = 4  # Number of WaveNet blocks\n",
    "dilations = [2**i for i in range(num_blocks)]  # Dilation rates: 1, 2, 4, 8\n",
    "\n",
    "model = WaveNet(input_channels, output_channels, num_blocks, dilations)\n",
    "print(model)\n",
    "\n",
    "# Example of how to define the loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0008)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([32, 16, 4])\n",
      "Input tensor total elements: 2048\n",
      "Target tensor shape: torch.Size([32, 1])\n",
      "Sequence length: 16\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(\"Input tensor shape:\", inputs.shape)\n",
    "    print(\"Input tensor total elements:\", inputs.numel())\n",
    "    print(\"Target tensor shape:\", targets.shape)\n",
    "    print(\"Sequence length:\", inputs.shape[1])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/j/f007g3j/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/dartfs-hpc/rc/home/j/f007g3j/miniconda3/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 4863.485068321228\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Permute to match (batch, channels, seq_len)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.permute(0, 2, 1))  # Permute to match (batch, channels, seq_len)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs.permute(0, 2, 1))  # Permute to match (batch, channels, seq_len)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss / len(val_loader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
