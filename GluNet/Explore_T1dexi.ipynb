{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU...\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the overlap\n",
    "import os\n",
    "\n",
    "# Function to get filenames from a folder\n",
    "def get_filenames(folder_path):\n",
    "    return set(os.listdir(folder_path))\n",
    "\n",
    "# Replace these paths with your actual folder paths\n",
    "folder1 = f'C:/Users/username/OneDrive/Desktop/BGprediction/FA_split'\n",
    "folder2 = f'C:/Users/username/OneDrive/Desktop/BGprediction/ML_split'\n",
    "folder3 = f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split'\n",
    "folder4 = f'C:/Users/username/OneDrive/Desktop/BGprediction/FACM_split'\n",
    "\n",
    "# Get filenames from each folder\n",
    "filenames1 = get_filenames(folder1)\n",
    "filenames2 = get_filenames(folder2)\n",
    "filenames3 = get_filenames(folder3)\n",
    "filenames4 = get_filenames(folder4)\n",
    "\n",
    "# Find common filenames across all folders\n",
    "common_filenames = filenames1 & filenames2 & filenames3 & filenames4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_filenames = ['1100.csv',\n",
    " '870.csv',\n",
    " '958.csv',\n",
    " '255.csv',\n",
    " '933.csv',\n",
    " '1718.csv',\n",
    " '367.csv',\n",
    " '854.csv',\n",
    " '95.csv',\n",
    " '1287.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align first, then split, otherwise the order can be strange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the directory path\n",
    "# train_directory_path = r'C:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\LB_split'  # Use a raw string for paths on Windows\n",
    "\n",
    "# # List files without their extensions\n",
    "# train_file_names = [os.path.splitext(file)[0] for file in os.listdir(train_directory_path)\n",
    "#               if os.path.isfile(os.path.join(train_directory_path, file))]\n",
    "\n",
    "# # Print the list of file names\n",
    "# print(train_file_names)\n",
    "\n",
    "subject = pd.read_csv(f\"../LB_split/1100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_t1dexi(path):\n",
    "\n",
    "    subject = pd.read_csv(path)\n",
    "    subject['LBDTC'] = pd.to_datetime(subject['LBDTC'], errors='coerce')  # Convert 'date' column to datetime if not already\n",
    "    # print(subject['date'][0])\n",
    "    subject.sort_values('LBDTC', inplace=True)  # Sort the DataFrame by the 'date' column\n",
    "\n",
    "    # # Assuming self.interval_timedelta is set, for example:\n",
    "    # interval_timedelta = datetime.timedelta(minutes=6)  # Example timedelta of 6 minutes, providing a range for latency\n",
    "\n",
    "    # # Create a list to store the results\n",
    "    # res = []\n",
    "\n",
    "    # # Initialize the first group\n",
    "    # if not subject.empty:\n",
    "    #     current_group = [subject.iloc[0]['LBORRES']]\n",
    "    #     last_time = subject.iloc[0]['LBDTC']\n",
    "\n",
    "    # # Iterate over rows in DataFrame starting from the second row\n",
    "    # for index, row in subject.iloc[1:].iterrows():\n",
    "    #     current_time = row['LBDTC']\n",
    "    #     if (current_time - last_time) <= interval_timedelta:\n",
    "    #         # If the time difference is within the limit, add to the current group\n",
    "    #         current_group.append(row['LBORRES'])\n",
    "    #     else:\n",
    "    #         # Otherwise, start a new group\n",
    "    #         res.append(current_group)\n",
    "    #         current_group = [row['LBORRES']]\n",
    "    #     last_time = current_time\n",
    "\n",
    "    # # Add the last group if it's not empty\n",
    "    # if current_group:\n",
    "    #     res.append(current_group)\n",
    "    \n",
    "    # # Filter out groups with fewer than 10 glucose readings\n",
    "    # res = [group for group in res if len(group) >= 10]\n",
    "\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm = preprocess_t1dexi(f\"../LB_split/1100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meal quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing your CSV files\n",
    "directory_path = '../ML_split'\n",
    "\n",
    "# List to store filenames with no \"NA\" in the \"MLDOSE\" column\n",
    "valid_files = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if the \"MLDOSE\" column has no \"NA\" values\n",
    "        if df[\"MLDOSE\"].notna().all():\n",
    "            valid_files.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_t1dexi(path):\n",
    "    subject = pd.read_csv(path)\n",
    "    subject['LBDTC'] = pd.to_datetime(subject['LBDTC'], errors='coerce')  # Convert 'date' column to datetime if not already\n",
    "    # print(subject['date'][0])\n",
    "    subject.sort_values('LBDTC', inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_meal = pd.read_csv(f\"../ML_split/870.csv\")\n",
    "subject_meal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_meal[\"MLDOSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
