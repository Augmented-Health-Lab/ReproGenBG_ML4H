{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-29 17:17:28,379 DEBUG matplotlib data path: c:\\Users\\baiyi\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\matplotlib\\mpl-data\n",
      "2025-01-29 17:17:28,379 DEBUG CONFIGDIR=C:\\Users\\baiyi\\.matplotlib\n",
      "2025-01-29 17:17:28,379 DEBUG interactive is False\n",
      "2025-01-29 17:17:28,379 DEBUG platform is win32\n",
      "2025-01-29 17:17:28,413 DEBUG CACHEDIR=C:\\Users\\baiyi\\.matplotlib\n",
      "2025-01-29 17:17:28,413 DEBUG Using fontManager instance from C:\\Users\\baiyi\\.matplotlib\\fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pprint\n",
    "import importlib.util\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import copy\n",
    "import datetime\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "import numpy as np\n",
    "import metrics\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "# Look at the output of ohio data loader\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start to work on the DiaTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_module(script_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"module.name\", script_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "def load_cfg(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load a YAML configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream)\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "    return cfg\n",
    "\n",
    "def load_cfgs(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load YAML configuration files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfgs : [dict]\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream, Loader=yaml.SafeLoader)\n",
    "\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "\n",
    "    hyperparameters = []\n",
    "    hyperparameter_names = []\n",
    "    hyperparameter_values = []\n",
    "    # TODO: ugly, should handle arbitrary depth\n",
    "    for k1 in cfg.keys():\n",
    "        for k2 in cfg[k1].keys():\n",
    "            if k2.startswith(\"param_\"):\n",
    "                hyperparameters.append((k1, k2))\n",
    "                hyperparameter_names.append((k1, k2[6:]))\n",
    "                hyperparameter_values.append(cfg[k1][k2])\n",
    "\n",
    "    hyperparameter_valuess = itertools.product(*hyperparameter_values)\n",
    "\n",
    "\n",
    "    artifacts_path = cfg['train']['artifacts_path']\n",
    "\n",
    "    cfgs = []\n",
    "    for hyperparameter_values in hyperparameter_valuess:\n",
    "        configuration_name = \"\"\n",
    "        for ((k1, k2), value) in zip(hyperparameter_names, hyperparameter_values):\n",
    "            #print(k1, k2, value)\n",
    "            cfg[k1][k2] = value\n",
    "            configuration_name += \"{}_{}_\".format(k2, str(value))\n",
    "\n",
    "        cfg['train']['artifacts_path'] = os.path.join(artifacts_path, configuration_name)\n",
    "\n",
    "        cfgs.append(copy.deepcopy(cfg))\n",
    "\n",
    "    return cfgs\n",
    "\n",
    "\n",
    "\n",
    "def make_paths_absolute(dir_, cfg):\n",
    "    \"\"\"\n",
    "    Make all values for keys ending with `_path` absolute to dir_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_ : str\n",
    "    cfg : dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    for key in cfg.keys():\n",
    "        if key.endswith(\"_path\"):\n",
    "            cfg[key] = os.path.join(dir_, cfg[key])\n",
    "            cfg[key] = os.path.abspath(cfg[key])\n",
    "            if not os.path.exists(cfg[key]):\n",
    "                logging.error(\"%s does not exist.\", cfg[key])\n",
    "        if type(cfg[key]) is dict:\n",
    "            cfg[key] = make_paths_absolute(dir_, cfg[key])\n",
    "    return cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('_')[-1].split('.')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    print(f\"Evaluating for patient_id: {patient_id}\")\n",
    "    # load the trained weights\n",
    "    weights_path = os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\")\n",
    "    print(\"loading weights: {}\".format(weights_path))\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    y_pred = model.predict(x_test)[:,1].flatten()/scale\n",
    "    y_std  = model.predict(x_test)[:,0].flatten()/scale\n",
    "    y_test = y_test.flatten()/scale\n",
    "    t0 = x_test[:,-1,0]/scale\n",
    "\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    print(\"patient id: \", patient_id)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(rmse))\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mae.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(mae))\n",
    "\n",
    "    # Calculate MSE\n",
    "    # mse = np.mean((y_test - y_pred) ** 2)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(mse))\n",
    "\n",
    "    # Calculate MAPE\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Multiply by 100 for percentage\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mape.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(mape))\n",
    "\n",
    "    # seg = metrics.surveillance_error(y_test, y_pred)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(seg))\n",
    "\n",
    "    # t0_rmse = metrics.root_mean_squared_error(y_test, t0)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(t0_rmse))\n",
    "\n",
    "    # t0_seg = metrics.surveillance_error(y_test, t0)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(t0_seg))\n",
    "\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mean_std.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(np.mean(y_std)))\n",
    "\n",
    "    # print(\"RMSE: \", rmse)\n",
    "    # print(\"t0 RMSE: \", t0_rmse)\n",
    "    # print(\"SEG: \", seg)\n",
    "    # print(\"t0 SEG: \", t0_seg)\n",
    "\n",
    "def train(model, module_train, x_train, y_train, x_valid, y_valid, cfg):\n",
    "    model = module_train.train(\n",
    "        model          = model,\n",
    "        x_train        = x_train,\n",
    "        y_train        = y_train,\n",
    "        x_valid        = x_valid,\n",
    "        y_valid        = y_valid,\n",
    "        batch_size     = int(cfg['train']['batch_size']),\n",
    "        epochs         = int(cfg['train']['epochs']),\n",
    "        patience       = int(cfg['train']['patience']),\n",
    "        shuffle        = cfg['train']['shuffle'],\n",
    "        artifacts_path = cfg['train']['artifacts_path']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_target_distribution(y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    plt.figure()\n",
    "    sns.distplot(y_test.flatten()/scale, kde=False, norm_hist=True)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_dist_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_nll(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    for i in range(5):\n",
    "        start_index = i*to_plot\n",
    "        y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]/scale\n",
    "        y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]/scale\n",
    "        y_true      = y_test[:,0][start_index:start_index+to_plot]/scale\n",
    "\n",
    "        xs = np.arange(len(y_true))\n",
    "        plt.clf()\n",
    "        plt.ylim([0, 400])\n",
    "        #plt.ylim([-2, 2])\n",
    "        plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "        plt.plot(xs, y_pred_mean, label='prediction')\n",
    "        plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "                alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "        plt.xlabel(\"Time [h]\")\n",
    "        plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "        plt.legend(loc='upper right')\n",
    "        #plt.xlabel(\"y\")\n",
    "        #plt.ylabel(\"x\")\n",
    "        plt.xticks(ticks, ticks_labels)\n",
    "        save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_nll_plot_{}.pdf\".format(patient_id, i))\n",
    "        print(\"saving plot to: \", save_path)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_noise_experiment(model, x_test, y_test, cfg):\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    start_index = 0\n",
    "    y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]\n",
    "    y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]\n",
    "    y_true      = y_test[:,0][start_index:start_index+to_plot]\n",
    "\n",
    "    xs = np.arange(len(y_true))\n",
    "    plt.clf()\n",
    "    #plt.ylim([0, 400])\n",
    "    plt.ylim([-3, 3])\n",
    "    plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "    plt.plot(xs, y_pred_mean, label='prediction')\n",
    "    plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "            alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "    #plt.xlabel(\"Time [h]\")\n",
    "    #plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xticks(ticks, ticks_labels)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"noise_experiment_plot.pdf\")\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "def plot_seg(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "    y_pred_std  = y_pred[:,0][:]/scale\n",
    "    y_pred_mean = y_pred[:,1][:]/scale\n",
    "    y_true      = y_test[:,0][:]/scale\n",
    "\n",
    "    data = np.loadtxt('seg.csv')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Patient {} SEG'.format(patient_id))\n",
    "    ax.set_xlabel('Reference Concentration [mg/dl]')\n",
    "    ax.set_ylabel('Predicted Concentration [mg/dl]')\n",
    "    cax = ax.imshow(np.transpose(data), origin='lower', interpolation='nearest')\n",
    "    cbar = fig.colorbar(cax, ticks=[0.25, 1.0, 2.0, 3.0, 3.75], orientation='vertical')\n",
    "    cbar.ax.set_yticklabels(['None', 'Mild', 'Moderate', 'High', 'Extreme'],\n",
    "            rotation=90, va='center')\n",
    "\n",
    "    plt.scatter(y_true, y_pred_mean, s=25, facecolors='white', edgecolors='black')\n",
    "\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_seg_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-17 17:35:02,198 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold1_training\\all does not exist.\n",
      "2025-01-17 17:35:02,199 ERROR c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh does not exist.\n",
      "Running 1 experiments.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-01-17 17:35:02,202 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold1_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 34\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 46\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 112\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 25\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 24\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 78\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "x_train.shape:  (358389, 24, 1)\n",
      "y_train.shape:  (358389, 1)\n",
      "x_valid.shape:  (89575, 24, 1)\n",
      "y_valid.shape:  (89575, 1)\n",
      "x_test.shape:  (0, 24, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 17:35:50,527 WARNING Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-01-17 17:35:50,695 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-01-17 17:35:50,697 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 17:35:50,697 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 358389 samples, validate on 89575 samples\n",
      "Epoch 1/10000\n",
      "358389/358389 [==============================] - ETA: 0s - loss: 0.3078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358389/358389 [==============================] - 8s 21us/sample - loss: 0.3078 - val_loss: 0.0594\n",
      "Epoch 2/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.1291 - val_loss: 0.0017\n",
      "Epoch 3/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0882 - val_loss: 0.0038\n",
      "Epoch 4/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0625 - val_loss: -0.0203\n",
      "Epoch 5/10000\n",
      "355328/358389 [============================>.] - ETA: 0s - loss: 0.04682025-01-17 17:36:25,423 DEBUG Creating converter from 5 to 3\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0465 - val_loss: -0.0269\n",
      "Epoch 6/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0331 - val_loss: 0.0083\n",
      "Epoch 7/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0196 - val_loss: -0.0482\n",
      "Epoch 8/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: 0.0096 - val_loss: -0.0373\n",
      "Epoch 9/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: -7.8944e-04 - val_loss: -0.0565\n",
      "Epoch 10/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: -0.0083 - val_loss: -0.0614\n",
      "Epoch 11/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: -0.0154 - val_loss: -0.0600\n",
      "Epoch 12/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: -0.0204 - val_loss: -0.0732\n",
      "Epoch 13/10000\n",
      "358389/358389 [==============================] - 7s 19us/sample - loss: -0.0262 - val_loss: -0.0703\n",
      "Epoch 14/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0298 - val_loss: -0.0627\n",
      "Epoch 15/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0351 - val_loss: -0.0479\n",
      "Epoch 16/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0390 - val_loss: -0.0726\n",
      "Epoch 17/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0434 - val_loss: -0.0759\n",
      "Epoch 18/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0462 - val_loss: -0.0730\n",
      "Epoch 19/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0482 - val_loss: -0.0817\n",
      "Epoch 20/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0511 - val_loss: -0.0801\n",
      "Epoch 21/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0560 - val_loss: -0.0741\n",
      "Epoch 22/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0565 - val_loss: -0.0735\n",
      "Epoch 23/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0577 - val_loss: -0.0685\n",
      "Epoch 24/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0609 - val_loss: -0.0811\n",
      "Epoch 25/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0636 - val_loss: -0.0794\n",
      "Epoch 26/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0644 - val_loss: -0.0857\n",
      "Epoch 27/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0666 - val_loss: -0.0757\n",
      "Epoch 28/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0671 - val_loss: -0.0831\n",
      "Epoch 29/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0688 - val_loss: -0.0834\n",
      "Epoch 30/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0698 - val_loss: -0.0803\n",
      "Epoch 31/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0722 - val_loss: -0.0849\n",
      "Epoch 32/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0728 - val_loss: -0.0767\n",
      "Epoch 33/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0748 - val_loss: -0.0774\n",
      "Epoch 34/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0749 - val_loss: -0.0864\n",
      "Epoch 35/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0752 - val_loss: -0.0746\n",
      "Epoch 36/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0752 - val_loss: -0.0786\n",
      "Epoch 37/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0777 - val_loss: -0.0838\n",
      "Epoch 38/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0768 - val_loss: -0.0856\n",
      "Epoch 39/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0790 - val_loss: -0.0691\n",
      "Epoch 40/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0784 - val_loss: -0.0898\n",
      "Epoch 41/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0797 - val_loss: -0.0774\n",
      "Epoch 42/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0806 - val_loss: -0.0899\n",
      "Epoch 43/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0815 - val_loss: -0.0825\n",
      "Epoch 44/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0824 - val_loss: -0.0902\n",
      "Epoch 45/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0820 - val_loss: -0.0879\n",
      "Epoch 46/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0828 - val_loss: -0.0844\n",
      "Epoch 47/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0855 - val_loss: -0.0781\n",
      "Epoch 48/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.0836 - val_loss: -0.0829\n",
      "Epoch 49/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.0849 - val_loss: -0.0855\n",
      "Epoch 50/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0863 - val_loss: -0.0864\n",
      "Epoch 51/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0865 - val_loss: -0.0820\n",
      "Epoch 52/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0861 - val_loss: -0.0905\n",
      "Epoch 53/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0861 - val_loss: -0.0851\n",
      "Epoch 54/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0890 - val_loss: -0.0866\n",
      "Epoch 55/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0890 - val_loss: -0.0864\n",
      "Epoch 56/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0892 - val_loss: -0.0837\n",
      "Epoch 57/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0897 - val_loss: -0.0808\n",
      "Epoch 58/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0907 - val_loss: -0.0817\n",
      "Epoch 59/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0920 - val_loss: -0.0893\n",
      "Epoch 60/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0915 - val_loss: -0.0862\n",
      "Epoch 61/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0931 - val_loss: -0.0831\n",
      "Epoch 62/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0929 - val_loss: -0.0889\n",
      "Epoch 63/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0946 - val_loss: -0.0683\n",
      "Epoch 64/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0953 - val_loss: -0.0871\n",
      "Epoch 65/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0950 - val_loss: -0.0840\n",
      "Epoch 66/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.0960 - val_loss: -0.0857\n",
      "Epoch 67/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.0975 - val_loss: -0.0899\n",
      "Epoch 68/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0978 - val_loss: -0.0877\n",
      "Epoch 69/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0990 - val_loss: -0.0819\n",
      "Epoch 70/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.0998 - val_loss: -0.0832\n",
      "Epoch 71/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1005 - val_loss: -0.0809\n",
      "Epoch 72/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1002 - val_loss: -0.0809\n",
      "Epoch 73/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1028 - val_loss: -0.0744\n",
      "Epoch 74/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1030 - val_loss: -0.0726\n",
      "Epoch 75/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1052 - val_loss: -0.0846\n",
      "Epoch 76/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1059 - val_loss: -0.0763\n",
      "Epoch 77/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1070 - val_loss: -0.0736\n",
      "Epoch 78/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1076 - val_loss: -0.0735\n",
      "Epoch 79/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1078 - val_loss: -0.0771\n",
      "Epoch 80/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1098 - val_loss: -0.0775\n",
      "Epoch 81/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1120 - val_loss: -0.0757\n",
      "Epoch 82/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1123 - val_loss: -0.0693\n",
      "Epoch 83/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1145 - val_loss: -0.0649\n",
      "Epoch 84/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1145 - val_loss: -0.0726\n",
      "Epoch 85/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1152 - val_loss: -0.0700\n",
      "Epoch 86/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1163 - val_loss: -0.0616\n",
      "Epoch 87/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1194 - val_loss: -0.0687\n",
      "Epoch 88/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1198 - val_loss: -0.0673\n",
      "Epoch 89/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1215 - val_loss: -0.0615\n",
      "Epoch 90/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1245 - val_loss: -0.0645\n",
      "Epoch 91/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1243 - val_loss: -0.0556\n",
      "Epoch 92/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1267 - val_loss: -0.0582\n",
      "Epoch 93/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1269 - val_loss: -0.0569\n",
      "Epoch 94/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1305 - val_loss: -0.0578\n",
      "Epoch 95/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1328 - val_loss: -0.0493\n",
      "Epoch 96/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1327 - val_loss: -0.0435\n",
      "Epoch 97/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1362 - val_loss: -0.0473\n",
      "Epoch 98/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1377 - val_loss: -0.0432\n",
      "Epoch 99/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1397 - val_loss: -0.0419\n",
      "Epoch 100/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.1438 - val_loss: -0.0439\n",
      "Epoch 101/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.1427 - val_loss: -0.0355\n",
      "Epoch 102/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1465 - val_loss: -0.0387\n",
      "Epoch 103/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1498 - val_loss: -0.0239\n",
      "Epoch 104/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1507 - val_loss: -0.0220\n",
      "Epoch 105/10000\n",
      "358389/358389 [==============================] - 9s 24us/sample - loss: -0.1545 - val_loss: -0.0347\n",
      "Epoch 106/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1556 - val_loss: -0.0086\n",
      "Epoch 107/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1588 - val_loss: -0.0124\n",
      "Epoch 108/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1617 - val_loss: -0.0170\n",
      "Epoch 109/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1625 - val_loss: -0.0184\n",
      "Epoch 110/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1670 - val_loss: -0.0125\n",
      "Epoch 111/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1687 - val_loss: -0.0110\n",
      "Epoch 112/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1728 - val_loss: -0.0062\n",
      "Epoch 113/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1757 - val_loss: 0.0111\n",
      "Epoch 114/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1777 - val_loss: 0.0214\n",
      "Epoch 115/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.1805 - val_loss: 0.0222\n",
      "Epoch 116/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1840 - val_loss: 0.0294\n",
      "Epoch 117/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1870 - val_loss: 0.0200\n",
      "Epoch 118/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1901 - val_loss: 0.0256\n",
      "Epoch 119/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1914 - val_loss: 0.0334\n",
      "Epoch 120/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.1963 - val_loss: 0.0317\n",
      "Epoch 121/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.1970 - val_loss: 0.0421\n",
      "Epoch 122/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2028 - val_loss: 0.0501\n",
      "Epoch 123/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2055 - val_loss: 0.0529\n",
      "Epoch 124/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2076 - val_loss: 0.0598\n",
      "Epoch 125/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2099 - val_loss: 0.0583\n",
      "Epoch 126/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2151 - val_loss: 0.0669\n",
      "Epoch 127/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2185 - val_loss: 0.0659\n",
      "Epoch 128/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2217 - val_loss: 0.0945\n",
      "Epoch 129/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2245 - val_loss: 0.0911\n",
      "Epoch 130/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2289 - val_loss: 0.0942\n",
      "Epoch 131/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2310 - val_loss: 0.0748\n",
      "Epoch 132/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2352 - val_loss: 0.0906\n",
      "Epoch 133/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2381 - val_loss: 0.1012\n",
      "Epoch 134/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2427 - val_loss: 0.1102\n",
      "Epoch 135/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2451 - val_loss: 0.1321\n",
      "Epoch 136/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2482 - val_loss: 0.1143\n",
      "Epoch 137/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2521 - val_loss: 0.1478\n",
      "Epoch 138/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2555 - val_loss: 0.1402\n",
      "Epoch 139/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2579 - val_loss: 0.1450\n",
      "Epoch 140/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2608 - val_loss: 0.1656\n",
      "Epoch 141/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2652 - val_loss: 0.1775\n",
      "Epoch 142/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2710 - val_loss: 0.1848\n",
      "Epoch 143/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2730 - val_loss: 0.1786\n",
      "Epoch 144/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2759 - val_loss: 0.1635\n",
      "Epoch 145/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2787 - val_loss: 0.2098\n",
      "Epoch 146/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2818 - val_loss: 0.1926\n",
      "Epoch 147/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.2860 - val_loss: 0.2216\n",
      "Epoch 148/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.2895 - val_loss: 0.2014\n",
      "Epoch 149/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2919 - val_loss: 0.2257\n",
      "Epoch 150/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2963 - val_loss: 0.2467\n",
      "Epoch 151/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.2984 - val_loss: 0.2538\n",
      "Epoch 152/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3021 - val_loss: 0.2224\n",
      "Epoch 153/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3067 - val_loss: 0.2745\n",
      "Epoch 154/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3084 - val_loss: 0.2492\n",
      "Epoch 155/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3138 - val_loss: 0.2840\n",
      "Epoch 156/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3155 - val_loss: 0.2627\n",
      "Epoch 157/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3195 - val_loss: 0.2836\n",
      "Epoch 158/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3239 - val_loss: 0.2945\n",
      "Epoch 159/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3271 - val_loss: 0.2996\n",
      "Epoch 160/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3303 - val_loss: 0.3209\n",
      "Epoch 161/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3317 - val_loss: 0.3287\n",
      "Epoch 162/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3349 - val_loss: 0.3329\n",
      "Epoch 163/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3414 - val_loss: 0.3046\n",
      "Epoch 164/10000\n",
      "358389/358389 [==============================] - 7s 20us/sample - loss: -0.3415 - val_loss: 0.3402\n",
      "Epoch 165/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3455 - val_loss: 0.3753\n",
      "Epoch 166/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3480 - val_loss: 0.3567\n",
      "Epoch 167/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3519 - val_loss: 0.3841\n",
      "Epoch 168/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3561 - val_loss: 0.3877\n",
      "Epoch 169/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3577 - val_loss: 0.3725\n",
      "Epoch 170/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3616 - val_loss: 0.4021\n",
      "Epoch 171/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3649 - val_loss: 0.4282\n",
      "Epoch 172/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3670 - val_loss: 0.4246\n",
      "Epoch 173/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3715 - val_loss: 0.4408\n",
      "Epoch 174/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3739 - val_loss: 0.4754\n",
      "Epoch 175/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3781 - val_loss: 0.4378\n",
      "Epoch 176/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.3805 - val_loss: 0.4509\n",
      "Epoch 177/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3849 - val_loss: 0.4563\n",
      "Epoch 178/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3865 - val_loss: 0.4562\n",
      "Epoch 179/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.3867 - val_loss: 0.4821\n",
      "Epoch 180/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3902 - val_loss: 0.4894\n",
      "Epoch 181/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3944 - val_loss: 0.4953\n",
      "Epoch 182/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.3995 - val_loss: 0.5129\n",
      "Epoch 183/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4000 - val_loss: 0.4915\n",
      "Epoch 184/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4035 - val_loss: 0.5525\n",
      "Epoch 185/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4071 - val_loss: 0.5445\n",
      "Epoch 186/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4111 - val_loss: 0.5740\n",
      "Epoch 187/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4132 - val_loss: 0.5432\n",
      "Epoch 188/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4165 - val_loss: 0.5667\n",
      "Epoch 189/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4184 - val_loss: 0.6120\n",
      "Epoch 190/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4219 - val_loss: 0.5820\n",
      "Epoch 191/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4234 - val_loss: 0.5867\n",
      "Epoch 192/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4261 - val_loss: 0.5693\n",
      "Epoch 193/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4284 - val_loss: 0.5922\n",
      "Epoch 194/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4307 - val_loss: 0.6309\n",
      "Epoch 195/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4355 - val_loss: 0.6313\n",
      "Epoch 196/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4391 - val_loss: 0.6801\n",
      "Epoch 197/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4414 - val_loss: 0.6484\n",
      "Epoch 198/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4436 - val_loss: 0.6501\n",
      "Epoch 199/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4445 - val_loss: 0.7024\n",
      "Epoch 200/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4492 - val_loss: 0.6846\n",
      "Epoch 201/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4513 - val_loss: 0.6397\n",
      "Epoch 202/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4524 - val_loss: 0.6950\n",
      "Epoch 203/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4554 - val_loss: 0.6829\n",
      "Epoch 204/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4587 - val_loss: 0.6734\n",
      "Epoch 205/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4620 - val_loss: 0.6653\n",
      "Epoch 206/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4659 - val_loss: 0.7274\n",
      "Epoch 207/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4667 - val_loss: 0.7525\n",
      "Epoch 208/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4678 - val_loss: 0.7811\n",
      "Epoch 209/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4695 - val_loss: 0.7345\n",
      "Epoch 210/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4722 - val_loss: 0.7606\n",
      "Epoch 211/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4734 - val_loss: 0.7353\n",
      "Epoch 212/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4802 - val_loss: 0.7595\n",
      "Epoch 213/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4797 - val_loss: 0.7098\n",
      "Epoch 214/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4837 - val_loss: 0.8177\n",
      "Epoch 215/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.4844 - val_loss: 0.7973\n",
      "Epoch 216/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4881 - val_loss: 0.7918\n",
      "Epoch 217/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4919 - val_loss: 0.8263\n",
      "Epoch 218/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.4942 - val_loss: 0.8507\n",
      "Epoch 219/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4953 - val_loss: 0.7653\n",
      "Epoch 220/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.4970 - val_loss: 0.8865\n",
      "Epoch 221/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5007 - val_loss: 0.8188\n",
      "Epoch 222/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5008 - val_loss: 0.8345\n",
      "Epoch 223/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5022 - val_loss: 0.8528\n",
      "Epoch 224/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5056 - val_loss: 0.8815\n",
      "Epoch 225/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5088 - val_loss: 0.8582\n",
      "Epoch 226/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5117 - val_loss: 0.8665\n",
      "Epoch 227/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5146 - val_loss: 1.0056\n",
      "Epoch 228/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5146 - val_loss: 0.8531\n",
      "Epoch 229/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5198 - val_loss: 0.9385\n",
      "Epoch 230/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5209 - val_loss: 0.9326\n",
      "Epoch 231/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5235 - val_loss: 0.9631\n",
      "Epoch 232/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5237 - val_loss: 0.9509\n",
      "Epoch 233/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5252 - val_loss: 0.9398\n",
      "Epoch 234/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5291 - val_loss: 0.9693\n",
      "Epoch 235/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5307 - val_loss: 0.9672\n",
      "Epoch 236/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5328 - val_loss: 1.0191\n",
      "Epoch 237/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5333 - val_loss: 0.9731\n",
      "Epoch 238/10000\n",
      "358389/358389 [==============================] - 7s 21us/sample - loss: -0.5348 - val_loss: 0.9732\n",
      "Epoch 239/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5389 - val_loss: 0.9726\n",
      "Epoch 240/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5415 - val_loss: 0.9759\n",
      "Epoch 241/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5431 - val_loss: 0.9820\n",
      "Epoch 242/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5452 - val_loss: 1.0280\n",
      "Epoch 243/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5474 - val_loss: 1.0536\n",
      "Epoch 244/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5494 - val_loss: 1.0226\n",
      "Epoch 245/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5516 - val_loss: 0.9779\n",
      "Epoch 246/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5523 - val_loss: 1.0491\n",
      "Epoch 247/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5553 - val_loss: 1.0799\n",
      "Epoch 248/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5576 - val_loss: 1.0937\n",
      "Epoch 249/10000\n",
      "358389/358389 [==============================] - 8s 22us/sample - loss: -0.5591 - val_loss: 1.0883\n",
      "Epoch 250/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5612 - val_loss: 1.0376\n",
      "Epoch 251/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5626 - val_loss: 1.1159\n",
      "Epoch 252/10000\n",
      "358389/358389 [==============================] - 8s 21us/sample - loss: -0.5663 - val_loss: 1.0435\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject10.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject10.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11649, 24, 1)\n",
      "y_test.shape:  (11649, 1)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:27,691 WARNING Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject10\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n",
      "2025-01-17 18:07:27,789 DEBUG Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject10\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject11.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject11.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 17\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11304, 24, 1)\n",
      "y_test.shape:  (11304, 1)\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:32,795 WARNING Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject11\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject11\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject1.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject1.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 106\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (6347, 24, 1)\n",
      "y_test.shape:  (6347, 1)\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:37,474 WARNING Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject1\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject1\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject2.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject2.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 108\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (4674, 24, 1)\n",
      "y_test.shape:  (4674, 1)\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:40,601 WARNING Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject2\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject2\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject3.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject3.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 102\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5580, 24, 1)\n",
      "y_test.shape:  (5580, 1)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:43,208 WARNING Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject3\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject3\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject4.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject4.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 16\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11154, 24, 1)\n",
      "y_test.shape:  (11154, 1)\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:46,365 WARNING Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject4\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject4\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject5.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject5.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (9961, 24, 1)\n",
      "y_test.shape:  (9961, 1)\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:51,253 WARNING Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject5\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject5\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject6.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject6.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 20\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11176, 24, 1)\n",
      "y_test.shape:  (11176, 1)\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:07:55,872 WARNING Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject6\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject6\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject7.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject7.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11173, 24, 1)\n",
      "y_test.shape:  (11173, 1)\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:08:00,873 WARNING Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject7\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject7\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject8.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject8.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 19\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10978, 24, 1)\n",
      "y_test.shape:  (10978, 1)\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:08:05,897 WARNING Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject8\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject8\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject9.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject9.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11565, 24, 1)\n",
      "y_test.shape:  (11565, 1)\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:08:10,944 WARNING Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject9\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject9\n",
      "2025-01-17 18:08:14,815 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold2_training\\all does not exist.\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold2_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 106\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 108\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 46\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 112\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 102\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 25\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 24\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 78\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (342943, 24, 1)\n",
      "y_train.shape:  (342943, 1)\n",
      "x_valid.shape:  (85712, 24, 1)\n",
      "y_valid.shape:  (85712, 1)\n",
      "x_test.shape:  (0, 24, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:09:02,023 WARNING Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 18:09:02,140 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 342943 samples, validate on 85712 samples\n",
      "Epoch 1/10000\n",
      "340992/342943 [============================>.] - ETA: 0s - loss: 0.2937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342943/342943 [==============================] - 8s 23us/sample - loss: 0.2930 - val_loss: 0.0630\n",
      "Epoch 2/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: 0.1248 - val_loss: 0.0173\n",
      "Epoch 3/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: 0.0867 - val_loss: 0.0365\n",
      "Epoch 4/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: 0.0642 - val_loss: 0.0119\n",
      "Epoch 5/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: 0.0443 - val_loss: 0.0248\n",
      "Epoch 6/10000\n",
      "342943/342943 [==============================] - 7s 19us/sample - loss: 0.0322 - val_loss: -0.0232\n",
      "Epoch 7/10000\n",
      "342943/342943 [==============================] - 6s 19us/sample - loss: 0.0190 - val_loss: -0.0016\n",
      "Epoch 8/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: 0.0081 - val_loss: -0.0300\n",
      "Epoch 9/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: 9.0219e-04 - val_loss: -0.0395\n",
      "Epoch 10/10000\n",
      "342943/342943 [==============================] - 7s 19us/sample - loss: -0.0078 - val_loss: -0.0455\n",
      "Epoch 11/10000\n",
      "342943/342943 [==============================] - 7s 19us/sample - loss: -0.0155 - val_loss: -0.0408\n",
      "Epoch 12/10000\n",
      "342943/342943 [==============================] - 7s 19us/sample - loss: -0.0221 - val_loss: -0.0567\n",
      "Epoch 13/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0271 - val_loss: -0.0535\n",
      "Epoch 14/10000\n",
      "342943/342943 [==============================] - 7s 19us/sample - loss: -0.0328 - val_loss: -0.0468\n",
      "Epoch 15/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0371 - val_loss: -0.0624\n",
      "Epoch 16/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0397 - val_loss: -0.0581\n",
      "Epoch 17/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0455 - val_loss: -0.0605\n",
      "Epoch 18/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0495 - val_loss: -0.0679\n",
      "Epoch 19/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0528 - val_loss: -0.0649\n",
      "Epoch 20/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0551 - val_loss: -0.0725\n",
      "Epoch 21/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0580 - val_loss: -0.0656\n",
      "Epoch 22/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0608 - val_loss: -0.0605\n",
      "Epoch 23/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0632 - val_loss: -0.0570\n",
      "Epoch 24/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0640 - val_loss: -0.0701\n",
      "Epoch 25/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0657 - val_loss: -0.0650\n",
      "Epoch 26/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0675 - val_loss: -0.0696\n",
      "Epoch 27/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0701 - val_loss: -0.0648\n",
      "Epoch 28/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0711 - val_loss: -0.0707\n",
      "Epoch 29/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0715 - val_loss: -0.0691\n",
      "Epoch 30/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0738 - val_loss: -0.0661\n",
      "Epoch 31/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0748 - val_loss: -0.0704\n",
      "Epoch 32/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0730 - val_loss: -0.0705\n",
      "Epoch 33/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0742 - val_loss: -0.0763\n",
      "Epoch 34/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0780 - val_loss: -0.0760\n",
      "Epoch 35/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0764 - val_loss: -0.0701\n",
      "Epoch 36/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0798 - val_loss: -0.0735\n",
      "Epoch 37/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0786 - val_loss: -0.0695\n",
      "Epoch 38/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.0800 - val_loss: -0.0771\n",
      "Epoch 39/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.0819 - val_loss: -0.0704\n",
      "Epoch 40/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.0810 - val_loss: -0.0716\n",
      "Epoch 41/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.0823 - val_loss: -0.0703\n",
      "Epoch 42/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.0836 - val_loss: -0.0608\n",
      "Epoch 43/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.0838 - val_loss: -0.0739\n",
      "Epoch 44/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.0827 - val_loss: -0.0771\n",
      "Epoch 45/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0849 - val_loss: -0.0756\n",
      "Epoch 46/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.0853 - val_loss: -0.0704\n",
      "Epoch 47/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0865 - val_loss: -0.0756\n",
      "Epoch 48/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0864 - val_loss: -0.0730\n",
      "Epoch 49/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0881 - val_loss: -0.0747\n",
      "Epoch 50/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0878 - val_loss: -0.0734\n",
      "Epoch 51/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0884 - val_loss: -0.0726\n",
      "Epoch 52/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0902 - val_loss: -0.0671\n",
      "Epoch 53/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0905 - val_loss: -0.0735\n",
      "Epoch 54/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0897 - val_loss: -0.0735\n",
      "Epoch 55/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0914 - val_loss: -0.0729\n",
      "Epoch 56/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0924 - val_loss: -0.0706\n",
      "Epoch 57/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0939 - val_loss: -0.0701\n",
      "Epoch 58/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0947 - val_loss: -0.0713\n",
      "Epoch 59/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0942 - val_loss: -0.0740\n",
      "Epoch 60/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0958 - val_loss: -0.0697\n",
      "Epoch 61/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0968 - val_loss: -0.0712\n",
      "Epoch 62/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.0975 - val_loss: -0.0699\n",
      "Epoch 63/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0970 - val_loss: -0.0674\n",
      "Epoch 64/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0975 - val_loss: -0.0584\n",
      "Epoch 65/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0982 - val_loss: -0.0696\n",
      "Epoch 66/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.0999 - val_loss: -0.0716\n",
      "Epoch 67/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1015 - val_loss: -0.0664\n",
      "Epoch 68/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1020 - val_loss: -0.0601\n",
      "Epoch 69/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1011 - val_loss: -0.0719\n",
      "Epoch 70/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1030 - val_loss: -0.0654\n",
      "Epoch 71/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1045 - val_loss: -0.0661\n",
      "Epoch 72/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1037 - val_loss: -0.0699\n",
      "Epoch 73/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1067 - val_loss: -0.0701\n",
      "Epoch 74/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1068 - val_loss: -0.0650\n",
      "Epoch 75/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1081 - val_loss: -0.0672\n",
      "Epoch 76/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1100 - val_loss: -0.0577\n",
      "Epoch 77/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1110 - val_loss: -0.0595\n",
      "Epoch 78/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1130 - val_loss: -0.0641\n",
      "Epoch 79/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1148 - val_loss: -0.0553\n",
      "Epoch 80/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1161 - val_loss: -0.0587\n",
      "Epoch 81/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1180 - val_loss: -0.0580\n",
      "Epoch 82/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1182 - val_loss: -0.0568\n",
      "Epoch 83/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1204 - val_loss: -0.0510\n",
      "Epoch 84/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1223 - val_loss: -0.0496\n",
      "Epoch 85/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1251 - val_loss: -0.0502\n",
      "Epoch 86/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.1241 - val_loss: -0.0497\n",
      "Epoch 87/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1269 - val_loss: -0.0422\n",
      "Epoch 88/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1289 - val_loss: -0.0443\n",
      "Epoch 89/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1308 - val_loss: -0.0470\n",
      "Epoch 90/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1333 - val_loss: -0.0394\n",
      "Epoch 91/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1343 - val_loss: -0.0394\n",
      "Epoch 92/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1364 - val_loss: -0.0381\n",
      "Epoch 93/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1379 - val_loss: -0.0302\n",
      "Epoch 94/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.1415 - val_loss: -0.0338\n",
      "Epoch 95/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1436 - val_loss: -0.0374\n",
      "Epoch 96/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1466 - val_loss: -0.0241\n",
      "Epoch 97/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1475 - val_loss: -0.0236\n",
      "Epoch 98/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1492 - val_loss: -0.0270\n",
      "Epoch 99/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1522 - val_loss: -0.0157\n",
      "Epoch 100/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1546 - val_loss: -0.0143\n",
      "Epoch 101/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1582 - val_loss: -0.0061\n",
      "Epoch 102/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1623 - val_loss: -0.0054\n",
      "Epoch 103/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1626 - val_loss: -0.0034\n",
      "Epoch 104/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1646 - val_loss: 0.0019\n",
      "Epoch 105/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1689 - val_loss: 1.1632e-04\n",
      "Epoch 106/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1717 - val_loss: 0.0037\n",
      "Epoch 107/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1745 - val_loss: 0.0246\n",
      "Epoch 108/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1768 - val_loss: 0.0202\n",
      "Epoch 109/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1803 - val_loss: 0.0297\n",
      "Epoch 110/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1843 - val_loss: 0.0214\n",
      "Epoch 111/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1860 - val_loss: 0.0388\n",
      "Epoch 112/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1905 - val_loss: 0.0425\n",
      "Epoch 113/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.1941 - val_loss: 0.0524\n",
      "Epoch 114/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.1957 - val_loss: 0.0697\n",
      "Epoch 115/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2001 - val_loss: 0.0620\n",
      "Epoch 116/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2026 - val_loss: 0.0532\n",
      "Epoch 117/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.2050 - val_loss: 0.0700\n",
      "Epoch 118/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2084 - val_loss: 0.0817\n",
      "Epoch 119/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2123 - val_loss: 0.0914\n",
      "Epoch 120/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.2148 - val_loss: 0.0893\n",
      "Epoch 121/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2196 - val_loss: 0.0978\n",
      "Epoch 122/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2191 - val_loss: 0.0914\n",
      "Epoch 123/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2259 - val_loss: 0.1133\n",
      "Epoch 124/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2290 - val_loss: 0.1055\n",
      "Epoch 125/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2303 - val_loss: 0.1010\n",
      "Epoch 126/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2349 - val_loss: 0.1470\n",
      "Epoch 127/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2387 - val_loss: 0.1446\n",
      "Epoch 128/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.2432 - val_loss: 0.1405\n",
      "Epoch 129/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.2444 - val_loss: 0.1828\n",
      "Epoch 130/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.2496 - val_loss: 0.1502\n",
      "Epoch 131/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2526 - val_loss: 0.1561\n",
      "Epoch 132/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2554 - val_loss: 0.1411\n",
      "Epoch 133/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2623 - val_loss: 0.1822\n",
      "Epoch 134/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2636 - val_loss: 0.1711\n",
      "Epoch 135/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.2663 - val_loss: 0.1684\n",
      "Epoch 136/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.2703 - val_loss: 0.1856\n",
      "Epoch 137/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2729 - val_loss: 0.2108\n",
      "Epoch 138/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.2769 - val_loss: 0.2322\n",
      "Epoch 139/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.2801 - val_loss: 0.2113\n",
      "Epoch 140/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.2833 - val_loss: 0.2169\n",
      "Epoch 141/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.2878 - val_loss: 0.2249\n",
      "Epoch 142/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.2883 - val_loss: 0.2440\n",
      "Epoch 143/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.2943 - val_loss: 0.2511\n",
      "Epoch 144/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.2978 - val_loss: 0.2565\n",
      "Epoch 145/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.3019 - val_loss: 0.2448\n",
      "Epoch 146/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3037 - val_loss: 0.2478\n",
      "Epoch 147/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3068 - val_loss: 0.2715\n",
      "Epoch 148/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3092 - val_loss: 0.2882\n",
      "Epoch 149/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3132 - val_loss: 0.2779\n",
      "Epoch 150/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3155 - val_loss: 0.3099\n",
      "Epoch 151/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3218 - val_loss: 0.3481\n",
      "Epoch 152/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3259 - val_loss: 0.3310\n",
      "Epoch 153/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3258 - val_loss: 0.3161\n",
      "Epoch 154/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3282 - val_loss: 0.3538\n",
      "Epoch 155/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3320 - val_loss: 0.3324\n",
      "Epoch 156/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3364 - val_loss: 0.3264\n",
      "Epoch 157/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3400 - val_loss: 0.3612\n",
      "Epoch 158/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3428 - val_loss: 0.3823\n",
      "Epoch 159/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3472 - val_loss: 0.3789\n",
      "Epoch 160/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.3508 - val_loss: 0.4048\n",
      "Epoch 161/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.3533 - val_loss: 0.4173\n",
      "Epoch 162/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3564 - val_loss: 0.4317\n",
      "Epoch 163/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3598 - val_loss: 0.4208\n",
      "Epoch 164/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3630 - val_loss: 0.4503\n",
      "Epoch 165/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3643 - val_loss: 0.3903\n",
      "Epoch 166/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3672 - val_loss: 0.4568\n",
      "Epoch 167/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3716 - val_loss: 0.4509\n",
      "Epoch 168/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3754 - val_loss: 0.4883\n",
      "Epoch 169/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3788 - val_loss: 0.5065\n",
      "Epoch 170/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3796 - val_loss: 0.5038\n",
      "Epoch 171/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3844 - val_loss: 0.4740\n",
      "Epoch 172/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.3865 - val_loss: 0.4791\n",
      "Epoch 173/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.3892 - val_loss: 0.5035\n",
      "Epoch 174/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.3926 - val_loss: 0.4957\n",
      "Epoch 175/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.3961 - val_loss: 0.5271\n",
      "Epoch 176/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.3995 - val_loss: 0.5526\n",
      "Epoch 177/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4018 - val_loss: 0.5605\n",
      "Epoch 178/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4049 - val_loss: 0.5420\n",
      "Epoch 179/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4075 - val_loss: 0.5749\n",
      "Epoch 180/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4083 - val_loss: 0.5414\n",
      "Epoch 181/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4131 - val_loss: 0.5780\n",
      "Epoch 182/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4154 - val_loss: 0.6097\n",
      "Epoch 183/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4191 - val_loss: 0.5899\n",
      "Epoch 184/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4230 - val_loss: 0.6266\n",
      "Epoch 185/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4259 - val_loss: 0.6178\n",
      "Epoch 186/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4264 - val_loss: 0.6048\n",
      "Epoch 187/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4279 - val_loss: 0.6717\n",
      "Epoch 188/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4316 - val_loss: 0.6496\n",
      "Epoch 189/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4349 - val_loss: 0.6785\n",
      "Epoch 190/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4392 - val_loss: 0.6708\n",
      "Epoch 191/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4417 - val_loss: 0.6852\n",
      "Epoch 192/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4415 - val_loss: 0.6978\n",
      "Epoch 193/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4444 - val_loss: 0.6451\n",
      "Epoch 194/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4491 - val_loss: 0.7270\n",
      "Epoch 195/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4520 - val_loss: 0.6872\n",
      "Epoch 196/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4536 - val_loss: 0.7013\n",
      "Epoch 197/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4562 - val_loss: 0.7374\n",
      "Epoch 198/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4589 - val_loss: 0.7107\n",
      "Epoch 199/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4604 - val_loss: 0.6993\n",
      "Epoch 200/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4627 - val_loss: 0.7895\n",
      "Epoch 201/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4647 - val_loss: 0.7290\n",
      "Epoch 202/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.4677 - val_loss: 0.7881\n",
      "Epoch 203/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4703 - val_loss: 0.7392\n",
      "Epoch 204/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.4720 - val_loss: 0.7727\n",
      "Epoch 205/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.4740 - val_loss: 0.7708\n",
      "Epoch 206/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.4773 - val_loss: 0.7993\n",
      "Epoch 207/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.4815 - val_loss: 0.7797\n",
      "Epoch 208/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.4812 - val_loss: 0.7860\n",
      "Epoch 209/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.4852 - val_loss: 0.7886\n",
      "Epoch 210/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4856 - val_loss: 0.7964\n",
      "Epoch 211/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.4884 - val_loss: 0.8271\n",
      "Epoch 212/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.4896 - val_loss: 0.8019\n",
      "Epoch 213/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4945 - val_loss: 0.8484\n",
      "Epoch 214/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4947 - val_loss: 0.8310\n",
      "Epoch 215/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.4968 - val_loss: 0.8319\n",
      "Epoch 216/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5002 - val_loss: 0.8436\n",
      "Epoch 217/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5002 - val_loss: 0.8764\n",
      "Epoch 218/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.5070 - val_loss: 0.9271\n",
      "Epoch 219/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5072 - val_loss: 0.9292\n",
      "Epoch 220/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5112 - val_loss: 0.9236\n",
      "Epoch 221/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5114 - val_loss: 0.9284\n",
      "Epoch 222/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5150 - val_loss: 0.8849\n",
      "Epoch 223/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5145 - val_loss: 0.9370\n",
      "Epoch 224/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5173 - val_loss: 0.9191\n",
      "Epoch 225/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5217 - val_loss: 0.9521\n",
      "Epoch 226/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5243 - val_loss: 0.9544\n",
      "Epoch 227/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5240 - val_loss: 0.9322\n",
      "Epoch 228/10000\n",
      "342943/342943 [==============================] - 7s 20us/sample - loss: -0.5249 - val_loss: 0.9647\n",
      "Epoch 229/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5288 - val_loss: 0.9668\n",
      "Epoch 230/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5291 - val_loss: 1.0285\n",
      "Epoch 231/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5336 - val_loss: 0.9886\n",
      "Epoch 232/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5359 - val_loss: 1.0122\n",
      "Epoch 233/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5379 - val_loss: 0.9624\n",
      "Epoch 234/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5378 - val_loss: 0.9939\n",
      "Epoch 235/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5407 - val_loss: 0.9826\n",
      "Epoch 236/10000\n",
      "342943/342943 [==============================] - 7s 21us/sample - loss: -0.5435 - val_loss: 1.0324\n",
      "Epoch 237/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.5465 - val_loss: 1.0150\n",
      "Epoch 238/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.5461 - val_loss: 1.0264\n",
      "Epoch 239/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.5509 - val_loss: 1.0750\n",
      "Epoch 240/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.5514 - val_loss: 1.0734\n",
      "Epoch 241/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.5535 - val_loss: 1.1016\n",
      "Epoch 242/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.5556 - val_loss: 1.0413\n",
      "Epoch 243/10000\n",
      "342943/342943 [==============================] - 7s 22us/sample - loss: -0.5589 - val_loss: 1.1363\n",
      "Epoch 244/10000\n",
      "342943/342943 [==============================] - 8s 22us/sample - loss: -0.5595 - val_loss: 1.0686\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject12.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject12.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11600, 24, 1)\n",
      "y_test.shape:  (11600, 1)\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:21,889 WARNING Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject12\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject12\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject13.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject13.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 34\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10038, 24, 1)\n",
      "y_test.shape:  (10038, 1)\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:27,257 WARNING Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject13\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject13\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject14.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject14.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 16\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11131, 24, 1)\n",
      "y_test.shape:  (11131, 1)\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:32,394 WARNING Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject14\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject14\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject15.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject15.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11731, 24, 1)\n",
      "y_test.shape:  (11731, 1)\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:37,989 WARNING Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject15\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject15\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject16.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject16.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 13\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11488, 24, 1)\n",
      "y_test.shape:  (11488, 1)\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:43,877 WARNING Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject16\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject16\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject17.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject17.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11821, 24, 1)\n",
      "y_test.shape:  (11821, 1)\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:49,459 WARNING Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject17\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject17\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject18.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject18.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11612, 24, 1)\n",
      "y_test.shape:  (11612, 1)\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:38:54,870 WARNING Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject18\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject18\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject19.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject19.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11591, 24, 1)\n",
      "y_test.shape:  (11591, 1)\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:39:00,338 WARNING Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject19\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject19\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject20.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject20.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 19\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11089, 24, 1)\n",
      "y_test.shape:  (11089, 1)\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:39:05,710 WARNING Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject20\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject20\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject21.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject21.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 20\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11046, 24, 1)\n",
      "y_test.shape:  (11046, 1)\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:39:10,841 WARNING Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject21\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject21\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject22.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject22.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11723, 24, 1)\n",
      "y_test.shape:  (11723, 1)\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:39:16,069 WARNING Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject22\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject22\n",
      "2025-01-17 18:39:20,255 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold3_training\\all does not exist.\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold3_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 106\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 34\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 108\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 102\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 25\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 24\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 78\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (349705, 24, 1)\n",
      "y_train.shape:  (349705, 1)\n",
      "x_valid.shape:  (87403, 24, 1)\n",
      "y_valid.shape:  (87403, 1)\n",
      "x_test.shape:  (0, 24, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 18:40:07,800 WARNING Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 18:40:07,895 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 349705 samples, validate on 87403 samples\n",
      "Epoch 1/10000\n",
      "349184/349705 [============================>.] - ETA: 0s - loss: 0.3093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349705/349705 [==============================] - 8s 23us/sample - loss: 0.3090 - val_loss: 0.0507\n",
      "Epoch 2/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: 0.1309 - val_loss: 0.0033\n",
      "Epoch 3/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: 0.0966 - val_loss: -0.0195\n",
      "Epoch 4/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: 0.0677 - val_loss: -0.0029\n",
      "Epoch 5/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: 0.0513 - val_loss: -0.0383\n",
      "Epoch 6/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: 0.0346 - val_loss: -0.0251\n",
      "Epoch 7/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: 0.0235 - val_loss: -0.0392\n",
      "Epoch 8/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: 0.0113 - val_loss: -0.0565\n",
      "Epoch 9/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: 0.0025 - val_loss: -0.0702\n",
      "Epoch 10/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0069 - val_loss: -0.0416\n",
      "Epoch 11/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0129 - val_loss: -0.0591\n",
      "Epoch 12/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0149 - val_loss: -0.0655\n",
      "Epoch 13/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0236 - val_loss: -0.0697\n",
      "Epoch 14/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0292 - val_loss: -0.0691\n",
      "Epoch 15/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0324 - val_loss: -0.0724\n",
      "Epoch 16/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0380 - val_loss: -0.0793\n",
      "Epoch 17/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0432 - val_loss: -0.0732\n",
      "Epoch 18/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0434 - val_loss: -0.0760\n",
      "Epoch 19/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0470 - val_loss: -0.0698\n",
      "Epoch 20/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0535 - val_loss: -0.0677\n",
      "Epoch 21/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0539 - val_loss: -0.0669\n",
      "Epoch 22/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0557 - val_loss: -0.0775\n",
      "Epoch 23/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0582 - val_loss: -0.0764\n",
      "Epoch 24/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0600 - val_loss: -0.0781\n",
      "Epoch 25/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0616 - val_loss: -0.0750\n",
      "Epoch 26/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.0641 - val_loss: -0.0761\n",
      "Epoch 27/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0649 - val_loss: -0.0820\n",
      "Epoch 28/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0659 - val_loss: -0.0793\n",
      "Epoch 29/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0679 - val_loss: -0.0689\n",
      "Epoch 30/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0685 - val_loss: -0.0850\n",
      "Epoch 31/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0679 - val_loss: -0.0837\n",
      "Epoch 32/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0704 - val_loss: -0.0601\n",
      "Epoch 33/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0703 - val_loss: -0.0859\n",
      "Epoch 34/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.0718 - val_loss: -0.0888\n",
      "Epoch 35/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.0731 - val_loss: -0.0835\n",
      "Epoch 36/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0727 - val_loss: -0.0840\n",
      "Epoch 37/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0740 - val_loss: -0.0789\n",
      "Epoch 38/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0747 - val_loss: -0.0696\n",
      "Epoch 39/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0744 - val_loss: -0.0848\n",
      "Epoch 40/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0752 - val_loss: -0.0759\n",
      "Epoch 41/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0769 - val_loss: -0.0824\n",
      "Epoch 42/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0778 - val_loss: -0.0815\n",
      "Epoch 43/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0774 - val_loss: -0.0779\n",
      "Epoch 44/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0773 - val_loss: -0.0872\n",
      "Epoch 45/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0789 - val_loss: -0.0784\n",
      "Epoch 46/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.0793 - val_loss: -0.0895\n",
      "Epoch 47/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.0797 - val_loss: -0.0890\n",
      "Epoch 48/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0807 - val_loss: -0.0834\n",
      "Epoch 49/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0822 - val_loss: -0.0853\n",
      "Epoch 50/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0836 - val_loss: -0.0825\n",
      "Epoch 51/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0839 - val_loss: -0.0895\n",
      "Epoch 52/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0835 - val_loss: -0.0857\n",
      "Epoch 53/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0841 - val_loss: -0.0855\n",
      "Epoch 54/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.0854 - val_loss: -0.0886\n",
      "Epoch 55/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0864 - val_loss: -0.0827\n",
      "Epoch 56/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.0862 - val_loss: -0.0862\n",
      "Epoch 57/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.0889 - val_loss: -0.0906\n",
      "Epoch 58/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.0900 - val_loss: -0.0805\n",
      "Epoch 59/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0907 - val_loss: -0.0857\n",
      "Epoch 60/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0891 - val_loss: -0.0871\n",
      "Epoch 61/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0932 - val_loss: -0.0782\n",
      "Epoch 62/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0934 - val_loss: -0.0833\n",
      "Epoch 63/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0935 - val_loss: -0.0845\n",
      "Epoch 64/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0937 - val_loss: -0.0826\n",
      "Epoch 65/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0960 - val_loss: -0.0702\n",
      "Epoch 66/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0968 - val_loss: -0.0772\n",
      "Epoch 67/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0977 - val_loss: -0.0842\n",
      "Epoch 68/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.0989 - val_loss: -0.0803\n",
      "Epoch 69/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.0997 - val_loss: -0.0796\n",
      "Epoch 70/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1018 - val_loss: -0.0829\n",
      "Epoch 71/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1032 - val_loss: -0.0755\n",
      "Epoch 72/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1014 - val_loss: -0.0772\n",
      "Epoch 73/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1051 - val_loss: -0.0731\n",
      "Epoch 74/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1048 - val_loss: -0.0780\n",
      "Epoch 75/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1075 - val_loss: -0.0757\n",
      "Epoch 76/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1090 - val_loss: -0.0769\n",
      "Epoch 77/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1104 - val_loss: -0.0770\n",
      "Epoch 78/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1116 - val_loss: -0.0717\n",
      "Epoch 79/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.1118 - val_loss: -0.0743\n",
      "Epoch 80/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1149 - val_loss: -0.0606\n",
      "Epoch 81/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1157 - val_loss: -0.0694\n",
      "Epoch 82/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1177 - val_loss: -0.0548\n",
      "Epoch 83/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1196 - val_loss: -0.0643\n",
      "Epoch 84/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1223 - val_loss: -0.0623\n",
      "Epoch 85/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1227 - val_loss: -0.0578\n",
      "Epoch 86/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1242 - val_loss: -0.0615\n",
      "Epoch 87/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1265 - val_loss: -0.0596\n",
      "Epoch 88/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.1296 - val_loss: -0.0542\n",
      "Epoch 89/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1306 - val_loss: -0.0580\n",
      "Epoch 90/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1325 - val_loss: -0.0577\n",
      "Epoch 91/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1357 - val_loss: -0.0481\n",
      "Epoch 92/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1383 - val_loss: -0.0455\n",
      "Epoch 93/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1389 - val_loss: -0.0359\n",
      "Epoch 94/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1423 - val_loss: -0.0450\n",
      "Epoch 95/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1450 - val_loss: -0.0370\n",
      "Epoch 96/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1475 - val_loss: -0.0297\n",
      "Epoch 97/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.1491 - val_loss: -0.0342\n",
      "Epoch 98/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.1520 - val_loss: -0.0336\n",
      "Epoch 99/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1542 - val_loss: -0.0257\n",
      "Epoch 100/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1592 - val_loss: -0.0182\n",
      "Epoch 101/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1595 - val_loss: -0.0152\n",
      "Epoch 102/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1629 - val_loss: -0.0207\n",
      "Epoch 103/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1664 - val_loss: -0.0055\n",
      "Epoch 104/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1686 - val_loss: -0.0175\n",
      "Epoch 105/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1720 - val_loss: -0.0111\n",
      "Epoch 106/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1758 - val_loss: -0.0087\n",
      "Epoch 107/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.1798 - val_loss: 0.0033\n",
      "Epoch 108/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.1812 - val_loss: -0.0044\n",
      "Epoch 109/10000\n",
      "349705/349705 [==============================] - 8s 24us/sample - loss: -0.1855 - val_loss: 0.0084\n",
      "Epoch 110/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1876 - val_loss: 0.0283\n",
      "Epoch 111/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1931 - val_loss: 0.0336\n",
      "Epoch 112/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1958 - val_loss: 0.0277\n",
      "Epoch 113/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.1999 - val_loss: 0.0193\n",
      "Epoch 114/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2012 - val_loss: 0.0389\n",
      "Epoch 115/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2060 - val_loss: 0.0246\n",
      "Epoch 116/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2079 - val_loss: 0.0357\n",
      "Epoch 117/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2115 - val_loss: 0.0563\n",
      "Epoch 118/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2148 - val_loss: 0.0404\n",
      "Epoch 119/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2206 - val_loss: 0.0442\n",
      "Epoch 120/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2237 - val_loss: 0.0559\n",
      "Epoch 121/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2266 - val_loss: 0.0865\n",
      "Epoch 122/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2305 - val_loss: 0.0872\n",
      "Epoch 123/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2346 - val_loss: 0.0873\n",
      "Epoch 124/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.2382 - val_loss: 0.0634\n",
      "Epoch 125/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2418 - val_loss: 0.0946\n",
      "Epoch 126/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.2443 - val_loss: 0.1126\n",
      "Epoch 127/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2495 - val_loss: 0.1078\n",
      "Epoch 128/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2523 - val_loss: 0.1166\n",
      "Epoch 129/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2557 - val_loss: 0.1208\n",
      "Epoch 130/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2593 - val_loss: 0.1138\n",
      "Epoch 131/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2633 - val_loss: 0.1474\n",
      "Epoch 132/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.2658 - val_loss: 0.1204\n",
      "Epoch 133/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2713 - val_loss: 0.1427\n",
      "Epoch 134/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2726 - val_loss: 0.1680\n",
      "Epoch 135/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2790 - val_loss: 0.1837\n",
      "Epoch 136/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2817 - val_loss: 0.1809\n",
      "Epoch 137/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2850 - val_loss: 0.1731\n",
      "Epoch 138/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.2887 - val_loss: 0.1863\n",
      "Epoch 139/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2929 - val_loss: 0.2056\n",
      "Epoch 140/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.2970 - val_loss: 0.2082\n",
      "Epoch 141/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.3016 - val_loss: 0.1912\n",
      "Epoch 142/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3034 - val_loss: 0.2049\n",
      "Epoch 143/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3056 - val_loss: 0.2161\n",
      "Epoch 144/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3105 - val_loss: 0.2560\n",
      "Epoch 145/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3148 - val_loss: 0.2702\n",
      "Epoch 146/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3163 - val_loss: 0.2944\n",
      "Epoch 147/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3214 - val_loss: 0.2575\n",
      "Epoch 148/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3240 - val_loss: 0.2444\n",
      "Epoch 149/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3280 - val_loss: 0.2587\n",
      "Epoch 150/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3300 - val_loss: 0.3071\n",
      "Epoch 151/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3348 - val_loss: 0.2880\n",
      "Epoch 152/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3390 - val_loss: 0.3264\n",
      "Epoch 153/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3423 - val_loss: 0.2843\n",
      "Epoch 154/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3457 - val_loss: 0.3098\n",
      "Epoch 155/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3501 - val_loss: 0.3527\n",
      "Epoch 156/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3531 - val_loss: 0.3255\n",
      "Epoch 157/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3558 - val_loss: 0.3542\n",
      "Epoch 158/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3611 - val_loss: 0.3697\n",
      "Epoch 159/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3625 - val_loss: 0.3733\n",
      "Epoch 160/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3657 - val_loss: 0.3613\n",
      "Epoch 161/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3685 - val_loss: 0.4127\n",
      "Epoch 162/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3724 - val_loss: 0.3823\n",
      "Epoch 163/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3768 - val_loss: 0.4213\n",
      "Epoch 164/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3803 - val_loss: 0.4147\n",
      "Epoch 165/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.3830 - val_loss: 0.4327\n",
      "Epoch 166/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3883 - val_loss: 0.4402\n",
      "Epoch 167/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3895 - val_loss: 0.4078\n",
      "Epoch 168/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.3934 - val_loss: 0.4420\n",
      "Epoch 169/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3977 - val_loss: 0.4348\n",
      "Epoch 170/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.3980 - val_loss: 0.4354\n",
      "Epoch 171/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4023 - val_loss: 0.4691\n",
      "Epoch 172/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4045 - val_loss: 0.4959\n",
      "Epoch 173/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4084 - val_loss: 0.4183\n",
      "Epoch 174/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4107 - val_loss: 0.5114\n",
      "Epoch 175/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4147 - val_loss: 0.5155\n",
      "Epoch 176/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4198 - val_loss: 0.5276\n",
      "Epoch 177/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4195 - val_loss: 0.5206\n",
      "Epoch 178/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4221 - val_loss: 0.4884\n",
      "Epoch 179/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4258 - val_loss: 0.4953\n",
      "Epoch 180/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4271 - val_loss: 0.5633\n",
      "Epoch 181/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4317 - val_loss: 0.5308\n",
      "Epoch 182/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4339 - val_loss: 0.5664\n",
      "Epoch 183/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4367 - val_loss: 0.5690\n",
      "Epoch 184/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4385 - val_loss: 0.5490\n",
      "Epoch 185/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4438 - val_loss: 0.5568\n",
      "Epoch 186/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4448 - val_loss: 0.5847\n",
      "Epoch 187/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4487 - val_loss: 0.6221\n",
      "Epoch 188/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4515 - val_loss: 0.5909\n",
      "Epoch 189/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4539 - val_loss: 0.5999\n",
      "Epoch 190/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4553 - val_loss: 0.6425\n",
      "Epoch 191/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4601 - val_loss: 0.6143\n",
      "Epoch 192/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4615 - val_loss: 0.6377\n",
      "Epoch 193/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4640 - val_loss: 0.6456\n",
      "Epoch 194/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4673 - val_loss: 0.6699\n",
      "Epoch 195/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4702 - val_loss: 0.6860\n",
      "Epoch 196/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4730 - val_loss: 0.6614\n",
      "Epoch 197/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4775 - val_loss: 0.6971\n",
      "Epoch 198/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4766 - val_loss: 0.7106\n",
      "Epoch 199/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.4825 - val_loss: 0.6839\n",
      "Epoch 200/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4833 - val_loss: 0.6768\n",
      "Epoch 201/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4849 - val_loss: 0.6809\n",
      "Epoch 202/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4883 - val_loss: 0.7347\n",
      "Epoch 203/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4889 - val_loss: 0.6968\n",
      "Epoch 204/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4918 - val_loss: 0.7485\n",
      "Epoch 205/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.4950 - val_loss: 0.7432\n",
      "Epoch 206/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.4966 - val_loss: 0.7748\n",
      "Epoch 207/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.4997 - val_loss: 0.7037\n",
      "Epoch 208/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5017 - val_loss: 0.8145\n",
      "Epoch 209/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.5031 - val_loss: 0.7661\n",
      "Epoch 210/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5062 - val_loss: 0.8057\n",
      "Epoch 211/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5090 - val_loss: 0.7833\n",
      "Epoch 212/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5100 - val_loss: 0.7953\n",
      "Epoch 213/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.5119 - val_loss: 0.8577\n",
      "Epoch 214/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5147 - val_loss: 0.8310\n",
      "Epoch 215/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5167 - val_loss: 0.8403\n",
      "Epoch 216/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5227 - val_loss: 0.8256\n",
      "Epoch 217/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5227 - val_loss: 0.8701\n",
      "Epoch 218/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5254 - val_loss: 0.8788\n",
      "Epoch 219/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5269 - val_loss: 0.8166\n",
      "Epoch 220/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5302 - val_loss: 0.8597\n",
      "Epoch 221/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5311 - val_loss: 0.8807\n",
      "Epoch 222/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5364 - val_loss: 0.8579\n",
      "Epoch 223/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5376 - val_loss: 0.9171\n",
      "Epoch 224/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.5395 - val_loss: 0.9014\n",
      "Epoch 225/10000\n",
      "349705/349705 [==============================] - 7s 20us/sample - loss: -0.5397 - val_loss: 0.8769\n",
      "Epoch 226/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5440 - val_loss: 0.9105\n",
      "Epoch 227/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5456 - val_loss: 0.9270\n",
      "Epoch 228/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5475 - val_loss: 0.8899\n",
      "Epoch 229/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5487 - val_loss: 0.9581\n",
      "Epoch 230/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5509 - val_loss: 0.9593\n",
      "Epoch 231/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5544 - val_loss: 0.8915\n",
      "Epoch 232/10000\n",
      "349705/349705 [==============================] - 8s 21us/sample - loss: -0.5567 - val_loss: 0.9413\n",
      "Epoch 233/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5598 - val_loss: 0.9548\n",
      "Epoch 234/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5610 - val_loss: 0.9110\n",
      "Epoch 235/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5625 - val_loss: 0.9714\n",
      "Epoch 236/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5651 - val_loss: 1.0244\n",
      "Epoch 237/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5667 - val_loss: 1.0021\n",
      "Epoch 238/10000\n",
      "349705/349705 [==============================] - 8s 23us/sample - loss: -0.5668 - val_loss: 0.9925\n",
      "Epoch 239/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5702 - val_loss: 0.9915\n",
      "Epoch 240/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5722 - val_loss: 0.9841\n",
      "Epoch 241/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5731 - val_loss: 1.0618\n",
      "Epoch 242/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5751 - val_loss: 0.9823\n",
      "Epoch 243/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5779 - val_loss: 1.0367\n",
      "Epoch 244/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5779 - val_loss: 1.0233\n",
      "Epoch 245/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5803 - val_loss: 1.0451\n",
      "Epoch 246/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5841 - val_loss: 1.1021\n",
      "Epoch 247/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5862 - val_loss: 1.0296\n",
      "Epoch 248/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5855 - val_loss: 1.0810\n",
      "Epoch 249/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5896 - val_loss: 1.0681\n",
      "Epoch 250/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5906 - val_loss: 1.1050\n",
      "Epoch 251/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5964 - val_loss: 1.1262\n",
      "Epoch 252/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5952 - val_loss: 1.1798\n",
      "Epoch 253/10000\n",
      "349705/349705 [==============================] - 8s 22us/sample - loss: -0.5978 - val_loss: 1.0734\n",
      "Epoch 254/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5985 - val_loss: 1.0824\n",
      "Epoch 255/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.5986 - val_loss: 1.0806\n",
      "Epoch 256/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.6033 - val_loss: 1.1603\n",
      "Epoch 257/10000\n",
      "349705/349705 [==============================] - 7s 21us/sample - loss: -0.6057 - val_loss: 1.1588\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject23.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject23.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 16\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11297, 24, 1)\n",
      "y_test.shape:  (11297, 1)\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:13,608 WARNING Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject23\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject23\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject24.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject24.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 46\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (9064, 24, 1)\n",
      "y_test.shape:  (9064, 1)\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:18,755 WARNING Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject24\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject24\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject25.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject25.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11652, 24, 1)\n",
      "y_test.shape:  (11652, 1)\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:23,473 WARNING Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject25\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject25\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject26.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject26.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11457, 24, 1)\n",
      "y_test.shape:  (11457, 1)\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:29,224 WARNING Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject26\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject26\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject27.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject27.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11735, 24, 1)\n",
      "y_test.shape:  (11735, 1)\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:34,714 WARNING Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject27\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject27\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject28.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject28.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11666, 24, 1)\n",
      "y_test.shape:  (11666, 1)\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:40,387 WARNING Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject28\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject28\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject29.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject29.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 112\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (3151, 24, 1)\n",
      "y_test.shape:  (3151, 1)\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:45,872 WARNING Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject29\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject29\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject30.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject30.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11592, 24, 1)\n",
      "y_test.shape:  (11592, 1)\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:49,026 WARNING Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject30\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject30\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject31.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject31.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11851, 24, 1)\n",
      "y_test.shape:  (11851, 1)\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:12:54,881 WARNING Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject31\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject31\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject32.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject32.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 14\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11439, 24, 1)\n",
      "y_test.shape:  (11439, 1)\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:13:00,559 WARNING Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject32\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject32\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject33.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject33.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11513, 24, 1)\n",
      "y_test.shape:  (11513, 1)\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:13:06,149 WARNING Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject33\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject33\n",
      "2025-01-17 19:13:10,550 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold4_training\\all does not exist.\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold4_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 106\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 34\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 108\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 46\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 112\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 102\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 78\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (345487, 24, 1)\n",
      "y_train.shape:  (345487, 1)\n",
      "x_valid.shape:  (86351, 24, 1)\n",
      "y_valid.shape:  (86351, 1)\n",
      "x_test.shape:  (0, 24, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:13:58,320 WARNING Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 19:13:58,442 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 345487 samples, validate on 86351 samples\n",
      "Epoch 1/10000\n",
      "345487/345487 [==============================] - ETA: 0s - loss: 0.3493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345487/345487 [==============================] - 9s 26us/sample - loss: 0.3493 - val_loss: 0.0554\n",
      "Epoch 2/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: 0.1525 - val_loss: 0.0100\n",
      "Epoch 3/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: 0.1118 - val_loss: 0.0206\n",
      "Epoch 4/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: 0.0860 - val_loss: -0.0167\n",
      "Epoch 5/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: 0.0651 - val_loss: -0.0227\n",
      "Epoch 6/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: 0.0502 - val_loss: -0.0332\n",
      "Epoch 7/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: 0.0368 - val_loss: -0.0500\n",
      "Epoch 8/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: 0.0274 - val_loss: -0.0369\n",
      "Epoch 9/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: 0.0181 - val_loss: -0.0464\n",
      "Epoch 10/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: 0.0073 - val_loss: -0.0512\n",
      "Epoch 11/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: 0.0057 - val_loss: -0.0526\n",
      "Epoch 12/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0041 - val_loss: -0.0564\n",
      "Epoch 13/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0077 - val_loss: -0.0461\n",
      "Epoch 14/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0122 - val_loss: -0.0474\n",
      "Epoch 15/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0172 - val_loss: -0.0359\n",
      "Epoch 16/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0231 - val_loss: -0.0481\n",
      "Epoch 17/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0259 - val_loss: -0.0718\n",
      "Epoch 18/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0301 - val_loss: -0.0495\n",
      "Epoch 19/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0320 - val_loss: -0.0762\n",
      "Epoch 20/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0353 - val_loss: -0.0449\n",
      "Epoch 21/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0392 - val_loss: -0.0827\n",
      "Epoch 22/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0415 - val_loss: -0.0735\n",
      "Epoch 23/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0446 - val_loss: -0.0700\n",
      "Epoch 24/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0470 - val_loss: -0.0682\n",
      "Epoch 25/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0462 - val_loss: -0.0832\n",
      "Epoch 26/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0491 - val_loss: -0.0768\n",
      "Epoch 27/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0499 - val_loss: -0.0769\n",
      "Epoch 28/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0520 - val_loss: -0.0701\n",
      "Epoch 29/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0541 - val_loss: -0.0765\n",
      "Epoch 30/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0540 - val_loss: -0.0801\n",
      "Epoch 31/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0565 - val_loss: -0.0821\n",
      "Epoch 32/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0560 - val_loss: -0.0852\n",
      "Epoch 33/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0573 - val_loss: -0.0798\n",
      "Epoch 34/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0591 - val_loss: -0.0898\n",
      "Epoch 35/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0602 - val_loss: -0.0861\n",
      "Epoch 36/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.0606 - val_loss: -0.0855\n",
      "Epoch 37/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0608 - val_loss: -0.0816\n",
      "Epoch 38/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0624 - val_loss: -0.0879\n",
      "Epoch 39/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0633 - val_loss: -0.0814\n",
      "Epoch 40/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0621 - val_loss: -0.0801\n",
      "Epoch 41/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0636 - val_loss: -0.0797\n",
      "Epoch 42/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0649 - val_loss: -0.0837\n",
      "Epoch 43/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0651 - val_loss: -0.0833\n",
      "Epoch 44/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0645 - val_loss: -0.0839\n",
      "Epoch 45/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0675 - val_loss: -0.0849\n",
      "Epoch 46/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0674 - val_loss: -0.0764\n",
      "Epoch 47/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0678 - val_loss: -0.0853\n",
      "Epoch 48/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0699 - val_loss: -0.0808\n",
      "Epoch 49/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0710 - val_loss: -0.0876\n",
      "Epoch 50/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0691 - val_loss: -0.0880\n",
      "Epoch 51/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0705 - val_loss: -0.0785\n",
      "Epoch 52/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0719 - val_loss: -0.0846\n",
      "Epoch 53/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0733 - val_loss: -0.0879\n",
      "Epoch 54/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0730 - val_loss: -0.0877\n",
      "Epoch 55/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0732 - val_loss: -0.0797\n",
      "Epoch 56/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0736 - val_loss: -0.0843\n",
      "Epoch 57/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0748 - val_loss: -0.0785\n",
      "Epoch 58/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0758 - val_loss: -0.0813\n",
      "Epoch 59/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0770 - val_loss: -0.0863\n",
      "Epoch 60/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0765 - val_loss: -0.0845\n",
      "Epoch 61/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0776 - val_loss: -0.0870\n",
      "Epoch 62/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0785 - val_loss: -0.0888\n",
      "Epoch 63/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0798 - val_loss: -0.0846\n",
      "Epoch 64/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0814 - val_loss: -0.0868\n",
      "Epoch 65/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0801 - val_loss: -0.0865\n",
      "Epoch 66/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0810 - val_loss: -0.0813\n",
      "Epoch 67/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0826 - val_loss: -0.0839\n",
      "Epoch 68/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.0843 - val_loss: -0.0814\n",
      "Epoch 69/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.0836 - val_loss: -0.0847\n",
      "Epoch 70/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0862 - val_loss: -0.0783\n",
      "Epoch 71/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0871 - val_loss: -0.0798\n",
      "Epoch 72/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0874 - val_loss: -0.0817\n",
      "Epoch 73/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0882 - val_loss: -0.0827\n",
      "Epoch 74/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0901 - val_loss: -0.0785\n",
      "Epoch 75/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0897 - val_loss: -0.0829\n",
      "Epoch 76/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0914 - val_loss: -0.0765\n",
      "Epoch 77/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0924 - val_loss: -0.0773\n",
      "Epoch 78/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0942 - val_loss: -0.0720\n",
      "Epoch 79/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0951 - val_loss: -0.0713\n",
      "Epoch 80/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0969 - val_loss: -0.0822\n",
      "Epoch 81/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.0968 - val_loss: -0.0782\n",
      "Epoch 82/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0988 - val_loss: -0.0766\n",
      "Epoch 83/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.0984 - val_loss: -0.0743\n",
      "Epoch 84/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1016 - val_loss: -0.0725\n",
      "Epoch 85/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1007 - val_loss: -0.0746\n",
      "Epoch 86/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1035 - val_loss: -0.0683\n",
      "Epoch 87/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1055 - val_loss: -0.0749\n",
      "Epoch 88/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1065 - val_loss: -0.0729\n",
      "Epoch 89/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1078 - val_loss: -0.0710\n",
      "Epoch 90/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1101 - val_loss: -0.0728\n",
      "Epoch 91/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.1115 - val_loss: -0.0665\n",
      "Epoch 92/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.1135 - val_loss: -0.0553\n",
      "Epoch 93/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1129 - val_loss: -0.0581\n",
      "Epoch 94/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1162 - val_loss: -0.0602\n",
      "Epoch 95/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.1185 - val_loss: -0.0678\n",
      "Epoch 96/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1192 - val_loss: -0.0536\n",
      "Epoch 97/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1215 - val_loss: -0.0671\n",
      "Epoch 98/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1241 - val_loss: -0.0645\n",
      "Epoch 99/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.1261 - val_loss: -0.0491\n",
      "Epoch 100/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.1285 - val_loss: -0.0547\n",
      "Epoch 101/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1302 - val_loss: -0.0543\n",
      "Epoch 102/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.1317 - val_loss: -0.0384\n",
      "Epoch 103/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1364 - val_loss: -0.0526\n",
      "Epoch 104/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1372 - val_loss: -0.0420\n",
      "Epoch 105/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1394 - val_loss: -0.0449\n",
      "Epoch 106/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1412 - val_loss: -0.0367\n",
      "Epoch 107/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1445 - val_loss: -0.0460\n",
      "Epoch 108/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1478 - val_loss: -0.0431\n",
      "Epoch 109/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1500 - val_loss: -0.0445\n",
      "Epoch 110/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1512 - val_loss: -0.0312\n",
      "Epoch 111/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1537 - val_loss: -0.0391\n",
      "Epoch 112/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1593 - val_loss: -0.0204\n",
      "Epoch 113/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1606 - val_loss: -0.0279\n",
      "Epoch 114/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1619 - val_loss: -0.0145\n",
      "Epoch 115/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1661 - val_loss: -0.0160\n",
      "Epoch 116/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1689 - val_loss: -0.0065\n",
      "Epoch 117/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1724 - val_loss: -0.0117\n",
      "Epoch 118/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1738 - val_loss: -0.0072\n",
      "Epoch 119/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1780 - val_loss: 0.0093\n",
      "Epoch 120/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1818 - val_loss: 0.0130\n",
      "Epoch 121/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1836 - val_loss: 0.0031\n",
      "Epoch 122/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.1852 - val_loss: 0.0126\n",
      "Epoch 123/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1901 - val_loss: 0.0104\n",
      "Epoch 124/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1942 - val_loss: 0.0271\n",
      "Epoch 125/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.1983 - val_loss: 0.0307\n",
      "Epoch 126/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.2003 - val_loss: 0.0194\n",
      "Epoch 127/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.2020 - val_loss: 0.0378\n",
      "Epoch 128/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.2071 - val_loss: 0.0314\n",
      "Epoch 129/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.2096 - val_loss: 0.0595\n",
      "Epoch 130/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.2141 - val_loss: 0.0598\n",
      "Epoch 131/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.2167 - val_loss: 0.0520\n",
      "Epoch 132/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.2205 - val_loss: 0.0411\n",
      "Epoch 133/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.2251 - val_loss: 0.0595\n",
      "Epoch 134/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.2278 - val_loss: 0.0757\n",
      "Epoch 135/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.2318 - val_loss: 0.0726\n",
      "Epoch 136/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.2331 - val_loss: 0.0950\n",
      "Epoch 137/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2372 - val_loss: 0.0810\n",
      "Epoch 138/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.2430 - val_loss: 0.0910\n",
      "Epoch 139/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2459 - val_loss: 0.0769\n",
      "Epoch 140/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2485 - val_loss: 0.1157\n",
      "Epoch 141/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2522 - val_loss: 0.1037\n",
      "Epoch 142/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2553 - val_loss: 0.1130\n",
      "Epoch 143/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2579 - val_loss: 0.1206\n",
      "Epoch 144/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2630 - val_loss: 0.1395\n",
      "Epoch 145/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2668 - val_loss: 0.1577\n",
      "Epoch 146/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2708 - val_loss: 0.1454\n",
      "Epoch 147/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2736 - val_loss: 0.1485\n",
      "Epoch 148/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2775 - val_loss: 0.1685\n",
      "Epoch 149/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2782 - val_loss: 0.1663\n",
      "Epoch 150/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2833 - val_loss: 0.1663\n",
      "Epoch 151/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2861 - val_loss: 0.1776\n",
      "Epoch 152/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2910 - val_loss: 0.1934\n",
      "Epoch 153/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2936 - val_loss: 0.2086\n",
      "Epoch 154/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.2970 - val_loss: 0.1966\n",
      "Epoch 155/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3011 - val_loss: 0.2178\n",
      "Epoch 156/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3038 - val_loss: 0.2063\n",
      "Epoch 157/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3084 - val_loss: 0.2287\n",
      "Epoch 158/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3116 - val_loss: 0.2571\n",
      "Epoch 159/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.3138 - val_loss: 0.2351\n",
      "Epoch 160/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3176 - val_loss: 0.2518\n",
      "Epoch 161/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.3198 - val_loss: 0.2402\n",
      "Epoch 162/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.3246 - val_loss: 0.2485\n",
      "Epoch 163/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3284 - val_loss: 0.2716\n",
      "Epoch 164/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3303 - val_loss: 0.2858\n",
      "Epoch 165/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3336 - val_loss: 0.2746\n",
      "Epoch 166/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3367 - val_loss: 0.2803\n",
      "Epoch 167/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3420 - val_loss: 0.2921\n",
      "Epoch 168/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.3459 - val_loss: 0.3104\n",
      "Epoch 169/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.3481 - val_loss: 0.3399\n",
      "Epoch 170/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3512 - val_loss: 0.3267\n",
      "Epoch 171/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3512 - val_loss: 0.3287\n",
      "Epoch 172/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3558 - val_loss: 0.3348\n",
      "Epoch 173/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3621 - val_loss: 0.3877\n",
      "Epoch 174/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3632 - val_loss: 0.3827\n",
      "Epoch 175/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3668 - val_loss: 0.3544\n",
      "Epoch 176/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3694 - val_loss: 0.3467\n",
      "Epoch 177/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3726 - val_loss: 0.3699\n",
      "Epoch 178/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3759 - val_loss: 0.4043\n",
      "Epoch 179/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3795 - val_loss: 0.3443\n",
      "Epoch 180/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3813 - val_loss: 0.3963\n",
      "Epoch 181/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3860 - val_loss: 0.4044\n",
      "Epoch 182/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3879 - val_loss: 0.3924\n",
      "Epoch 183/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.3900 - val_loss: 0.4570\n",
      "Epoch 184/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.3938 - val_loss: 0.4229\n",
      "Epoch 185/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3964 - val_loss: 0.4369\n",
      "Epoch 186/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.3972 - val_loss: 0.4409\n",
      "Epoch 187/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4022 - val_loss: 0.4535\n",
      "Epoch 188/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4056 - val_loss: 0.4761\n",
      "Epoch 189/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4056 - val_loss: 0.4489\n",
      "Epoch 190/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4115 - val_loss: 0.4945\n",
      "Epoch 191/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4113 - val_loss: 0.4705\n",
      "Epoch 192/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.4163 - val_loss: 0.4691\n",
      "Epoch 193/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.4197 - val_loss: 0.4993\n",
      "Epoch 194/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4234 - val_loss: 0.5012\n",
      "Epoch 195/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4254 - val_loss: 0.5013\n",
      "Epoch 196/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4277 - val_loss: 0.4996\n",
      "Epoch 197/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4281 - val_loss: 0.5353\n",
      "Epoch 198/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4330 - val_loss: 0.5143\n",
      "Epoch 199/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4359 - val_loss: 0.5442\n",
      "Epoch 200/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4379 - val_loss: 0.5155\n",
      "Epoch 201/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4389 - val_loss: 0.5225\n",
      "Epoch 202/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4466 - val_loss: 0.5450\n",
      "Epoch 203/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4460 - val_loss: 0.5831\n",
      "Epoch 204/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4473 - val_loss: 0.5776\n",
      "Epoch 205/10000\n",
      "345487/345487 [==============================] - 7s 20us/sample - loss: -0.4514 - val_loss: 0.5878\n",
      "Epoch 206/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4540 - val_loss: 0.5574\n",
      "Epoch 207/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4567 - val_loss: 0.6211\n",
      "Epoch 208/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4588 - val_loss: 0.5951\n",
      "Epoch 209/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4634 - val_loss: 0.6281\n",
      "Epoch 210/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4628 - val_loss: 0.6051\n",
      "Epoch 211/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4655 - val_loss: 0.6339\n",
      "Epoch 212/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4710 - val_loss: 0.5737\n",
      "Epoch 213/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4730 - val_loss: 0.6931\n",
      "Epoch 214/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4752 - val_loss: 0.5884\n",
      "Epoch 215/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4774 - val_loss: 0.6365\n",
      "Epoch 216/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4765 - val_loss: 0.6410\n",
      "Epoch 217/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4809 - val_loss: 0.6660\n",
      "Epoch 218/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.4852 - val_loss: 0.7217\n",
      "Epoch 219/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4872 - val_loss: 0.6963\n",
      "Epoch 220/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4876 - val_loss: 0.7091\n",
      "Epoch 221/10000\n",
      "345487/345487 [==============================] - 8s 23us/sample - loss: -0.4908 - val_loss: 0.6722\n",
      "Epoch 222/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.4926 - val_loss: 0.6818\n",
      "Epoch 223/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4958 - val_loss: 0.7191\n",
      "Epoch 224/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4967 - val_loss: 0.7220\n",
      "Epoch 225/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.4988 - val_loss: 0.7006\n",
      "Epoch 226/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.5031 - val_loss: 0.7316\n",
      "Epoch 227/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.5053 - val_loss: 0.7518\n",
      "Epoch 228/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.5059 - val_loss: 0.7403\n",
      "Epoch 229/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.5094 - val_loss: 0.7260\n",
      "Epoch 230/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.5118 - val_loss: 0.7248\n",
      "Epoch 231/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.5141 - val_loss: 0.7537\n",
      "Epoch 232/10000\n",
      "345487/345487 [==============================] - 7s 21us/sample - loss: -0.5148 - val_loss: 0.7386\n",
      "Epoch 233/10000\n",
      "345487/345487 [==============================] - 7s 22us/sample - loss: -0.5188 - val_loss: 0.7972\n",
      "Epoch 234/10000\n",
      "345487/345487 [==============================] - 8s 22us/sample - loss: -0.5200 - val_loss: 0.7513\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject34.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject34.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11361, 24, 1)\n",
      "y_test.shape:  (11361, 1)\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:00,034 WARNING Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject34\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject34\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject35.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject35.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11608, 24, 1)\n",
      "y_test.shape:  (11608, 1)\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:05,831 WARNING Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject35\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject35\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject36.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject36.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 25\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10847, 24, 1)\n",
      "y_test.shape:  (10847, 1)\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:11,476 WARNING Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject36\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject36\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject37.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject37.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 14\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11329, 24, 1)\n",
      "y_test.shape:  (11329, 1)\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:17,021 WARNING Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject37\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject37\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject38.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject38.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11351, 24, 1)\n",
      "y_test.shape:  (11351, 1)\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:22,701 WARNING Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject38\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject38\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject39.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject39.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10627, 24, 1)\n",
      "y_test.shape:  (10627, 1)\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:28,457 WARNING Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject39\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject39\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject40.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject40.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 21\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11169, 24, 1)\n",
      "y_test.shape:  (11169, 1)\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:34,401 WARNING Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject40\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject40\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject41.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject41.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 24\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11214, 24, 1)\n",
      "y_test.shape:  (11214, 1)\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:40,380 WARNING Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject41\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject41\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject42.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject42.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11123, 24, 1)\n",
      "y_test.shape:  (11123, 1)\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:46,398 WARNING Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject42\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject42\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject43.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject43.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 16\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11189, 24, 1)\n",
      "y_test.shape:  (11189, 1)\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:52,383 WARNING Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject43\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject43\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject44.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject44.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 16\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (9869, 24, 1)\n",
      "y_test.shape:  (9869, 1)\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:43:58,128 WARNING Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject44\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject44\n",
      "2025-01-17 19:44:02,351 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold5_training\\all does not exist.\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold5_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 106\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 34\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 108\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 46\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 112\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 102\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 25\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 24\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (374848, 24, 1)\n",
      "y_train.shape:  (374848, 1)\n",
      "x_valid.shape:  (93687, 24, 1)\n",
      "y_valid.shape:  (93687, 1)\n",
      "x_test.shape:  (0, 24, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 19:44:52,918 WARNING Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 19:44:53,034 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 374848 samples, validate on 93687 samples\n",
      "Epoch 1/10000\n",
      "374784/374848 [============================>.] - ETA: 0s - loss: 0.3472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374848/374848 [==============================] - 10s 26us/sample - loss: 0.3471 - val_loss: 0.2077\n",
      "Epoch 2/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.1539 - val_loss: 0.0348\n",
      "Epoch 3/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.1069 - val_loss: 0.0046\n",
      "Epoch 4/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0844 - val_loss: 0.0228\n",
      "Epoch 5/10000\n",
      "374848/374848 [==============================] - 9s 25us/sample - loss: 0.0622 - val_loss: -0.0096\n",
      "Epoch 6/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0468 - val_loss: -0.0167\n",
      "Epoch 7/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0346 - val_loss: -0.0300\n",
      "Epoch 8/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0219 - val_loss: 0.0067\n",
      "Epoch 9/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0121 - val_loss: -0.0212\n",
      "Epoch 10/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: 0.0071 - val_loss: -0.0453\n",
      "Epoch 11/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0022 - val_loss: -0.0402\n",
      "Epoch 12/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0074 - val_loss: -0.0529\n",
      "Epoch 13/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0134 - val_loss: -0.0477\n",
      "Epoch 14/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0182 - val_loss: -0.0185\n",
      "Epoch 15/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0216 - val_loss: -0.0568\n",
      "Epoch 16/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0287 - val_loss: -0.0366\n",
      "Epoch 17/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0316 - val_loss: -0.0484\n",
      "Epoch 18/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0347 - val_loss: -0.0381\n",
      "Epoch 19/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0394 - val_loss: -0.0498\n",
      "Epoch 20/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0425 - val_loss: -0.0128\n",
      "Epoch 21/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0426 - val_loss: -0.0489\n",
      "Epoch 22/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0453 - val_loss: -0.0561\n",
      "Epoch 23/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0469 - val_loss: -0.0378\n",
      "Epoch 24/10000\n",
      "374848/374848 [==============================] - 8s 20us/sample - loss: -0.0493 - val_loss: -0.0407\n",
      "Epoch 25/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0517 - val_loss: -0.0601\n",
      "Epoch 26/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0530 - val_loss: -0.0662\n",
      "Epoch 27/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0549 - val_loss: -0.0647\n",
      "Epoch 28/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0556 - val_loss: -0.0557\n",
      "Epoch 29/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0573 - val_loss: -0.0382\n",
      "Epoch 30/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0556 - val_loss: -0.0553\n",
      "Epoch 31/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0592 - val_loss: -0.0671\n",
      "Epoch 32/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0610 - val_loss: -0.0648\n",
      "Epoch 33/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0602 - val_loss: -0.0609\n",
      "Epoch 34/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0615 - val_loss: -0.0684\n",
      "Epoch 35/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.0617 - val_loss: -0.0470\n",
      "Epoch 36/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.0616 - val_loss: -0.0706\n",
      "Epoch 37/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.0648 - val_loss: -0.0719\n",
      "Epoch 38/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0654 - val_loss: -0.0746\n",
      "Epoch 39/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0665 - val_loss: -0.0278\n",
      "Epoch 40/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0660 - val_loss: -0.0611\n",
      "Epoch 41/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0674 - val_loss: -0.0550\n",
      "Epoch 42/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0686 - val_loss: -0.0640\n",
      "Epoch 43/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0674 - val_loss: -0.0560\n",
      "Epoch 44/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0686 - val_loss: -0.0511\n",
      "Epoch 45/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0689 - val_loss: -0.0699\n",
      "Epoch 46/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0717 - val_loss: -0.0669\n",
      "Epoch 47/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0718 - val_loss: -0.0684\n",
      "Epoch 48/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0719 - val_loss: -0.0579\n",
      "Epoch 49/10000\n",
      "374848/374848 [==============================] - 9s 23us/sample - loss: -0.0728 - val_loss: -0.0690\n",
      "Epoch 50/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0732 - val_loss: -0.0574\n",
      "Epoch 51/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0721 - val_loss: -0.0630\n",
      "Epoch 52/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0742 - val_loss: -0.0707\n",
      "Epoch 53/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0751 - val_loss: -0.0581\n",
      "Epoch 54/10000\n",
      "374848/374848 [==============================] - 8s 20us/sample - loss: -0.0755 - val_loss: -0.0653\n",
      "Epoch 55/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0763 - val_loss: -0.0633\n",
      "Epoch 56/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0755 - val_loss: -0.0596\n",
      "Epoch 57/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0782 - val_loss: -0.0658\n",
      "Epoch 58/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0789 - val_loss: -0.0689\n",
      "Epoch 59/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0795 - val_loss: -0.0342\n",
      "Epoch 60/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0792 - val_loss: -0.0448\n",
      "Epoch 61/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0805 - val_loss: -0.0697\n",
      "Epoch 62/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0816 - val_loss: -0.0462\n",
      "Epoch 63/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0823 - val_loss: -0.0499\n",
      "Epoch 64/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0815 - val_loss: -0.0509\n",
      "Epoch 65/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0831 - val_loss: -0.0675\n",
      "Epoch 66/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0849 - val_loss: -0.0600\n",
      "Epoch 67/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0854 - val_loss: -0.0660\n",
      "Epoch 68/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0864 - val_loss: -0.0409\n",
      "Epoch 69/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0875 - val_loss: -0.0465\n",
      "Epoch 70/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0886 - val_loss: -0.0461\n",
      "Epoch 71/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0881 - val_loss: -0.0552\n",
      "Epoch 72/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0900 - val_loss: -0.0565\n",
      "Epoch 73/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0908 - val_loss: -0.0541\n",
      "Epoch 74/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0925 - val_loss: -0.0594\n",
      "Epoch 75/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0940 - val_loss: -0.0607\n",
      "Epoch 76/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0940 - val_loss: -0.0439\n",
      "Epoch 77/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.0960 - val_loss: -0.0561\n",
      "Epoch 78/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0970 - val_loss: -0.0590\n",
      "Epoch 79/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0978 - val_loss: -0.0571\n",
      "Epoch 80/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1001 - val_loss: -0.0509\n",
      "Epoch 81/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.0998 - val_loss: -0.0517\n",
      "Epoch 82/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1015 - val_loss: -0.0515\n",
      "Epoch 83/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1031 - val_loss: -0.0538\n",
      "Epoch 84/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1049 - val_loss: -0.0448\n",
      "Epoch 85/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1059 - val_loss: -0.0482\n",
      "Epoch 86/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1093 - val_loss: -0.0504\n",
      "Epoch 87/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1099 - val_loss: -0.0471\n",
      "Epoch 88/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1140 - val_loss: -0.0450\n",
      "Epoch 89/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1135 - val_loss: -0.0420\n",
      "Epoch 90/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1171 - val_loss: -0.0373\n",
      "Epoch 91/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1183 - val_loss: -0.0445\n",
      "Epoch 92/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1209 - val_loss: -0.0400\n",
      "Epoch 93/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1221 - val_loss: -0.0256\n",
      "Epoch 94/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1232 - val_loss: -0.0182\n",
      "Epoch 95/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1261 - val_loss: -0.0241\n",
      "Epoch 96/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1288 - val_loss: -0.0214\n",
      "Epoch 97/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1307 - val_loss: -0.0239\n",
      "Epoch 98/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1345 - val_loss: -0.0174\n",
      "Epoch 99/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1354 - val_loss: -0.0196\n",
      "Epoch 100/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1396 - val_loss: -0.0109\n",
      "Epoch 101/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1411 - val_loss: -0.0115\n",
      "Epoch 102/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1428 - val_loss: -0.0084\n",
      "Epoch 103/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1477 - val_loss: 0.0073\n",
      "Epoch 104/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1490 - val_loss: 0.0064\n",
      "Epoch 105/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1498 - val_loss: 0.0270\n",
      "Epoch 106/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1536 - val_loss: -0.0078\n",
      "Epoch 107/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1523 - val_loss: 0.0163\n",
      "Epoch 108/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1600 - val_loss: 0.0223\n",
      "Epoch 109/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1602 - val_loss: 0.0214\n",
      "Epoch 110/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1625 - val_loss: 0.0274\n",
      "Epoch 111/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1693 - val_loss: 0.0171\n",
      "Epoch 112/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1715 - val_loss: 0.0265\n",
      "Epoch 113/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1750 - val_loss: 0.0530\n",
      "Epoch 114/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1770 - val_loss: 0.0675\n",
      "Epoch 115/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1794 - val_loss: 0.0596\n",
      "Epoch 116/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1861 - val_loss: 0.0657\n",
      "Epoch 117/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1860 - val_loss: 0.0747\n",
      "Epoch 118/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.1890 - val_loss: 0.0689\n",
      "Epoch 119/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1943 - val_loss: 0.0637\n",
      "Epoch 120/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1958 - val_loss: 0.0767\n",
      "Epoch 121/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.1907 - val_loss: 0.0930\n",
      "Epoch 122/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2036 - val_loss: 0.1023\n",
      "Epoch 123/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2053 - val_loss: 0.1118\n",
      "Epoch 124/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.2104 - val_loss: 0.1148\n",
      "Epoch 125/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.2126 - val_loss: 0.0949\n",
      "Epoch 126/10000\n",
      "374848/374848 [==============================] - 9s 23us/sample - loss: -0.2180 - val_loss: 0.1267\n",
      "Epoch 127/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.2203 - val_loss: 0.1125\n",
      "Epoch 128/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2233 - val_loss: 0.1132\n",
      "Epoch 129/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2272 - val_loss: 0.1485\n",
      "Epoch 130/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2308 - val_loss: 0.1539\n",
      "Epoch 131/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2309 - val_loss: 0.1780\n",
      "Epoch 132/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2375 - val_loss: 0.1658\n",
      "Epoch 133/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2408 - val_loss: 0.1585\n",
      "Epoch 134/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2435 - val_loss: 0.1938\n",
      "Epoch 135/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2479 - val_loss: 0.1924\n",
      "Epoch 136/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2494 - val_loss: 0.1744\n",
      "Epoch 137/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2533 - val_loss: 0.2069\n",
      "Epoch 138/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2572 - val_loss: 0.2118\n",
      "Epoch 139/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2606 - val_loss: 0.1991\n",
      "Epoch 140/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2624 - val_loss: 0.2250\n",
      "Epoch 141/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2677 - val_loss: 0.2278\n",
      "Epoch 142/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2685 - val_loss: 0.2397\n",
      "Epoch 143/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2709 - val_loss: 0.2076\n",
      "Epoch 144/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2755 - val_loss: 0.2531\n",
      "Epoch 145/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2823 - val_loss: 0.2696\n",
      "Epoch 146/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2840 - val_loss: 0.2367\n",
      "Epoch 147/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2854 - val_loss: 0.2529\n",
      "Epoch 148/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.2917 - val_loss: 0.3409\n",
      "Epoch 149/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2954 - val_loss: 0.2737\n",
      "Epoch 150/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2969 - val_loss: 0.2844\n",
      "Epoch 151/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.2995 - val_loss: 0.3237\n",
      "Epoch 152/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3026 - val_loss: 0.2981\n",
      "Epoch 153/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3058 - val_loss: 0.3647\n",
      "Epoch 154/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3081 - val_loss: 0.3326\n",
      "Epoch 155/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3138 - val_loss: 0.3457\n",
      "Epoch 156/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3162 - val_loss: 0.3527\n",
      "Epoch 157/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3206 - val_loss: 0.3820\n",
      "Epoch 158/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3209 - val_loss: 0.3790\n",
      "Epoch 159/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3250 - val_loss: 0.3667\n",
      "Epoch 160/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3283 - val_loss: 0.3689\n",
      "Epoch 161/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3306 - val_loss: 0.4020\n",
      "Epoch 162/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3334 - val_loss: 0.4025\n",
      "Epoch 163/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3364 - val_loss: 0.4245\n",
      "Epoch 164/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3410 - val_loss: 0.4308\n",
      "Epoch 165/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3444 - val_loss: 0.4488\n",
      "Epoch 166/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3464 - val_loss: 0.4418\n",
      "Epoch 167/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3523 - val_loss: 0.4745\n",
      "Epoch 168/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3510 - val_loss: 0.4650\n",
      "Epoch 169/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3576 - val_loss: 0.4256\n",
      "Epoch 170/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3591 - val_loss: 0.4431\n",
      "Epoch 171/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3613 - val_loss: 0.4897\n",
      "Epoch 172/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3666 - val_loss: 0.5102\n",
      "Epoch 173/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3700 - val_loss: 0.5413\n",
      "Epoch 174/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3695 - val_loss: 0.4344\n",
      "Epoch 175/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3746 - val_loss: 0.4786\n",
      "Epoch 176/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3781 - val_loss: 0.5231\n",
      "Epoch 177/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3778 - val_loss: 0.5323\n",
      "Epoch 178/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.3816 - val_loss: 0.5435\n",
      "Epoch 179/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3868 - val_loss: 0.5124\n",
      "Epoch 180/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3877 - val_loss: 0.5580\n",
      "Epoch 181/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3932 - val_loss: 0.5762\n",
      "Epoch 182/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3925 - val_loss: 0.5645\n",
      "Epoch 183/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3957 - val_loss: 0.5407\n",
      "Epoch 184/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.3980 - val_loss: 0.5699\n",
      "Epoch 185/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4012 - val_loss: 0.6294\n",
      "Epoch 186/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4040 - val_loss: 0.6072\n",
      "Epoch 187/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4034 - val_loss: 0.5898\n",
      "Epoch 188/10000\n",
      "374848/374848 [==============================] - 9s 23us/sample - loss: -0.4100 - val_loss: 0.6367\n",
      "Epoch 189/10000\n",
      "374848/374848 [==============================] - 8s 23us/sample - loss: -0.4101 - val_loss: 0.6432\n",
      "Epoch 190/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4174 - val_loss: 0.6086\n",
      "Epoch 191/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4150 - val_loss: 0.6125\n",
      "Epoch 192/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4201 - val_loss: 0.6627\n",
      "Epoch 193/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4232 - val_loss: 0.6626\n",
      "Epoch 194/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4248 - val_loss: 0.6343\n",
      "Epoch 195/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4295 - val_loss: 0.6026\n",
      "Epoch 196/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4287 - val_loss: 0.6550\n",
      "Epoch 197/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4330 - val_loss: 0.6767\n",
      "Epoch 198/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4388 - val_loss: 0.7102\n",
      "Epoch 199/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4369 - val_loss: 0.6522\n",
      "Epoch 200/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4408 - val_loss: 0.7181\n",
      "Epoch 201/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4437 - val_loss: 0.6774\n",
      "Epoch 202/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4465 - val_loss: 0.7063\n",
      "Epoch 203/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4511 - val_loss: 0.7854\n",
      "Epoch 204/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4509 - val_loss: 0.7482\n",
      "Epoch 205/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4520 - val_loss: 0.7786\n",
      "Epoch 206/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4579 - val_loss: 0.7837\n",
      "Epoch 207/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4561 - val_loss: 0.7615\n",
      "Epoch 208/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4545 - val_loss: 0.7537\n",
      "Epoch 209/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4631 - val_loss: 0.8430\n",
      "Epoch 210/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4646 - val_loss: 0.7961\n",
      "Epoch 211/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4718 - val_loss: 0.8163\n",
      "Epoch 212/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4684 - val_loss: 0.7515\n",
      "Epoch 213/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4705 - val_loss: 0.7911\n",
      "Epoch 214/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4760 - val_loss: 0.8108\n",
      "Epoch 215/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4786 - val_loss: 0.8563\n",
      "Epoch 216/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4757 - val_loss: 0.8408\n",
      "Epoch 217/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4807 - val_loss: 0.8473\n",
      "Epoch 218/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4837 - val_loss: 0.8263\n",
      "Epoch 219/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4849 - val_loss: 0.8622\n",
      "Epoch 220/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4866 - val_loss: 0.8900\n",
      "Epoch 221/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4910 - val_loss: 0.9248\n",
      "Epoch 222/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4954 - val_loss: 0.8927\n",
      "Epoch 223/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4946 - val_loss: 0.8890\n",
      "Epoch 224/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4989 - val_loss: 0.9206\n",
      "Epoch 225/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.4989 - val_loss: 0.9191\n",
      "Epoch 226/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.4974 - val_loss: 0.9370\n",
      "Epoch 227/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5018 - val_loss: 0.8558\n",
      "Epoch 228/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5061 - val_loss: 0.9257\n",
      "Epoch 229/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5062 - val_loss: 0.8785\n",
      "Epoch 230/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5094 - val_loss: 0.9915\n",
      "Epoch 231/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5094 - val_loss: 0.9435\n",
      "Epoch 232/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5108 - val_loss: 0.9708\n",
      "Epoch 233/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5136 - val_loss: 1.0075\n",
      "Epoch 234/10000\n",
      "374848/374848 [==============================] - 8s 21us/sample - loss: -0.5150 - val_loss: 0.9618\n",
      "Epoch 235/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.5191 - val_loss: 0.9862\n",
      "Epoch 236/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.5203 - val_loss: 0.9574\n",
      "Epoch 237/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.5228 - val_loss: 0.9519\n",
      "Epoch 238/10000\n",
      "374848/374848 [==============================] - 8s 22us/sample - loss: -0.5269 - val_loss: 0.9813\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject45.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject45.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10685, 24, 1)\n",
      "y_test.shape:  (10685, 1)\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:06,364 WARNING Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject45\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject45\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject46.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject46.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 17\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11191, 24, 1)\n",
      "y_test.shape:  (11191, 1)\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:12,453 WARNING Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject46\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject46\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject47.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject47.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11535, 24, 1)\n",
      "y_test.shape:  (11535, 1)\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:18,539 WARNING Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject47\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject47\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject48.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject48.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11666, 24, 1)\n",
      "y_test.shape:  (11666, 1)\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:24,710 WARNING Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject48\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject48\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject49.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject49.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 6\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10635, 24, 1)\n",
      "y_test.shape:  (10635, 1)\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:30,805 WARNING Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject49\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject49\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject50.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject50.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 78\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (4413, 24, 1)\n",
      "y_test.shape:  (4413, 1)\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:37,206 WARNING Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject50\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject50\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject51.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject51.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (8549, 24, 1)\n",
      "y_test.shape:  (8549, 1)\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:41,262 WARNING Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject51\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject51\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject53.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject53.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (8763, 24, 1)\n",
      "y_test.shape:  (8763, 1)\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:46,887 WARNING Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject53\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject53\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject54.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 24,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_24sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject54.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "x_train.shape:  (0, 24, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 24, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7553, 24, 1)\n",
      "y_test.shape:  (7553, 1)\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 20:17:52,662 WARNING Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject54\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_24sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject54\n"
     ]
    }
   ],
   "source": [
    "for fold_number in range(1, 6):\n",
    "    yaml_filepath = f\"./original_diatrend_experiments_120min/all_final_experiment_fold{fold_number}.yaml\"\n",
    "    mode = \"train\"\n",
    "\n",
    "    cfgs = load_cfgs(yaml_filepath)\n",
    "    print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "    for cfg in cfgs:\n",
    "        seed = int(cfg['train']['seed'])\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Print the configuration - just to make sure that you loaded what you\n",
    "        # wanted to load\n",
    "\n",
    "        module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "        module_model         = load_module(cfg['model']['script_path'])\n",
    "        module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "        module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "        module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(cfg)\n",
    "\n",
    "        #print(\"loading dataset ...\")\n",
    "        #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "        #nb_past_steps_tmp = 36\n",
    "        #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "        #x_train = x_train[:,-nb_past_steps:,:]\n",
    "        #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "        #x_test = x_test[:,-nb_past_steps:,:]\n",
    "        print(\"x_train.shape: \", x_train.shape)\n",
    "        print(\"y_train.shape: \", y_train.shape)\n",
    "        print(\"x_valid.shape: \", x_valid.shape)\n",
    "        print(\"y_valid.shape: \", y_valid.shape)\n",
    "        print(\"x_test.shape: \", x_test.shape)\n",
    "        print(\"y_test.shape: \", y_test.shape)\n",
    "        \n",
    "        #print(\"loading optimizer ...\")\n",
    "        optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "\n",
    "        #print(\"loading loss function ...\")\n",
    "        loss_function = module_loss_function.load()\n",
    "        #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "        #print(\"loading model ...\")\n",
    "        if 'tf_nll' in loss_function.__name__:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1]*2,\n",
    "                cfg['model']\n",
    "            )\n",
    "        else:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1],\n",
    "                cfg['model']\n",
    "            )\n",
    "\n",
    "        if 'initial_weights_path' in cfg['train']:\n",
    "            #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "            model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_function\n",
    "        )\n",
    "\n",
    "        #print(model.summary())\n",
    "\n",
    "        # training mode\n",
    "        if mode == 'train':\n",
    "            #print(\"training model ...\")\n",
    "            train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "        if mode == 'plot_nll':\n",
    "            plot_nll(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_noise_experiment':\n",
    "            plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_seg':\n",
    "            plot_seg(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_dist':\n",
    "            plot_target_distribution(y_test, cfg)\n",
    "\n",
    "        # evaluation mode\n",
    "        if mode == 'evaluate':\n",
    "            evaluate(model, x_test, y_test, cfg)\n",
    "\n",
    "\n",
    "    # Get all yaml files in the directory\n",
    "    yaml_files = glob.glob(f\"./original_diatrend_experiments_120min/fold{fold_number}_eval/*.yaml\")\n",
    "    mode = \"evaluate\"\n",
    "    for yaml_filepath in yaml_files:\n",
    "        cfgs = load_cfgs(yaml_filepath)\n",
    "        print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "        for cfg in cfgs:\n",
    "            seed = int(cfg['train']['seed'])\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            # Print the configuration - just to make sure that you loaded what you\n",
    "            # wanted to load\n",
    "\n",
    "            module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "            module_model         = load_module(cfg['model']['script_path'])\n",
    "            module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "            module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "            module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "            pp = pprint.PrettyPrinter(indent=4)\n",
    "            pp.pprint(cfg)\n",
    "\n",
    "            #print(\"loading dataset ...\")\n",
    "            #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "            #nb_past_steps_tmp = 36\n",
    "            #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "            x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "            #x_train = x_train[:,-nb_past_steps:,:]\n",
    "            #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "            #x_test = x_test[:,-nb_past_steps:,:]\n",
    "            print(\"x_train.shape: \", x_train.shape)\n",
    "            print(\"y_train.shape: \", y_train.shape)\n",
    "            print(\"x_valid.shape: \", x_valid.shape)\n",
    "            print(\"y_valid.shape: \", y_valid.shape)\n",
    "            print(\"x_test.shape: \", x_test.shape)\n",
    "            print(\"y_test.shape: \", y_test.shape)\n",
    "            #print(\"loading optimizer ...\")\n",
    "            optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "            #print(\"loading loss function ...\")\n",
    "            loss_function = module_loss_function.load()\n",
    "            #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "            #print(\"loading model ...\")\n",
    "            if 'tf_nll' in loss_function.__name__:\n",
    "                model = module_model.load(\n",
    "                    x_train.shape[1:],\n",
    "                    y_train.shape[1]*2,\n",
    "                    cfg['model']\n",
    "                )\n",
    "            else:\n",
    "                model = module_model.load(\n",
    "                    x_train.shape[1:],\n",
    "                    y_train.shape[1],\n",
    "                    cfg['model']\n",
    "                )\n",
    "\n",
    "            if 'initial_weights_path' in cfg['train']:\n",
    "                #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "                model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss_function\n",
    "            )\n",
    "\n",
    "            #print(model.summary())\n",
    "\n",
    "            # training mode\n",
    "            if mode == 'train':\n",
    "                #print(\"training model ...\")\n",
    "                train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "            if mode == 'plot_nll':\n",
    "                plot_nll(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_noise_experiment':\n",
    "                plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_seg':\n",
    "                plot_seg(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_dist':\n",
    "                plot_target_distribution(y_test, cfg)\n",
    "\n",
    "            # evaluation mode\n",
    "            if mode == 'evaluate':\n",
    "                evaluate(model, x_test, y_test, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-17 09:30:11,588 ERROR C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\fold3_training\\all does not exist.\n",
      "Running 1 experiments.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-01-17 09:30:11,593 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold3_training\\\\all',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "nb_future_steps  6\n",
      "Total segments found: 209\n",
      "Segment lengths: [10, 1, 83, 37, 260, 29, 171, 63, 109, 98, 109, 14, 159, 48, 22, 12, 12, 9, 6, 27, 6, 106, 8, 24, 20, 28, 79, 71, 1, 58, 46, 5, 109, 107, 67, 17, 69, 28, 46, 53, 7, 13, 6, 11, 33, 138, 1, 6, 64, 71, 7, 2, 91, 3, 12, 2, 141, 2, 12, 39, 32, 57, 69, 12, 1, 1, 220, 19, 37, 1, 25, 209, 6, 2, 1, 169, 4, 42, 169, 48, 42, 5, 1, 2, 122, 26, 35, 10, 25, 5, 117, 19, 21, 14, 20, 2, 13, 16, 108, 18, 1, 68, 7, 12, 4, 26, 8, 128, 23, 3, 2, 21, 25, 10, 192, 6, 58, 154, 74, 58, 139, 111, 95, 34, 7, 58, 207, 41, 37, 4, 2, 1, 20, 136, 62, 13, 7, 1, 121, 65, 58, 164, 46, 73, 185, 36, 105, 139, 224, 51, 74, 12, 34, 3, 90, 50, 4, 35, 1, 40, 15, 8, 88, 43, 4, 54, 147, 75, 1, 2, 14, 2, 53, 1, 89, 6, 127, 50, 47, 13, 19, 87, 50, 90, 46, 52, 76, 43, 23, 28, 4, 120, 56, 45, 30, 111, 49, 121, 14, 136, 1, 1, 48, 11, 24, 213, 25, 16, 32]\n",
      "Segments after filtering: 150\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2408, 312, 1051, 1352, 1728, 2000, 46, 405, 2394, 243]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [61, 1571, 6, 60, 5, 800, 1411, 81, 1812, 752, 469, 330, 1145, 2, 35, 132, 82, 24, 2752, 5, 57, 247]\n",
      "Segments after filtering: 18\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [30, 1827, 283, 14, 1809, 1883, 1987, 1154, 1, 109, 1189, 1619]\n",
      "Segments after filtering: 11\n",
      "nb_future_steps  6\n",
      "Total segments found: 48\n",
      "Segment lengths: [394, 455, 803, 241, 843, 205, 155, 54, 764, 42, 282, 443, 53, 56, 466, 104, 126, 54, 650, 85, 126, 128, 1440, 161, 259, 4, 27, 15, 47, 121, 14, 4, 14, 1940, 1, 4, 1, 2, 47, 1, 181, 3, 93, 17, 48, 17, 60, 98]\n",
      "Segments after filtering: 40\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [14, 532, 491, 1427, 17, 1662, 892, 64, 2211, 166, 60, 67, 101, 1451, 233, 622, 175, 1441]\n",
      "Segments after filtering: 18\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1986, 2282, 1, 556, 2855, 2844, 521, 890]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 18\n",
      "Segment lengths: [1587, 1375, 840, 548, 7, 6, 25, 1196, 520, 1, 875, 7, 68, 153, 2368, 330, 842, 1163]\n",
      "Segments after filtering: 14\n",
      "nb_future_steps  6\n",
      "Total segments found: 6\n",
      "Segment lengths: [417, 2298, 2856, 2703, 2236, 1485]\n",
      "Segments after filtering: 6\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [421, 2161, 78, 26, 2597, 1307, 1311, 2856, 1113]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [2747, 2617, 136, 89, 2077, 469, 5, 156, 71, 2846, 673]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 418\n",
      "Segment lengths: [0, 3, 51, 4, 3, 1, 16, 23, 20, 1, 1, 38, 1, 98, 21, 12, 1, 1, 19, 10, 11, 26, 2, 19, 26, 27, 83, 12, 2, 23, 15, 1, 9, 30, 42, 83, 27, 9, 9, 12, 9, 9, 1, 2, 6, 5, 3, 5, 3, 3, 1, 23, 42, 10, 50, 20, 1, 1, 92, 1, 35, 17, 2, 23, 84, 17, 1, 5, 30, 1, 3, 9, 5, 33, 5, 4, 5, 19, 11, 92, 2, 20, 29, 109, 70, 72, 11, 128, 4, 7, 17, 2, 252, 11, 154, 40, 7, 5, 8, 61, 1, 3, 50, 63, 4, 11, 47, 29, 9, 79, 62, 3, 6, 53, 46, 22, 133, 26, 51, 5, 14, 27, 29, 87, 91, 26, 31, 1, 2, 2, 11, 41, 3, 46, 10, 1, 5, 8, 4, 9, 2, 10, 43, 18, 12, 71, 34, 2, 13, 12, 13, 2, 11, 2, 3, 7, 89, 6, 5, 11, 35, 25, 9, 9, 4, 3, 1, 7, 5, 38, 4, 11, 217, 232, 55, 8, 12, 23, 13, 5, 2, 5, 12, 3, 9, 1, 43, 1, 1, 2, 17, 1, 2, 1, 191, 20, 9, 21, 25, 231, 7, 127, 28, 6, 63, 141, 53, 11, 27, 5, 56, 18, 159, 29, 5, 79, 154, 61, 43, 1, 175, 3, 54, 49, 4, 8, 10, 42, 2, 7, 1, 32, 62, 29, 45, 4, 7, 14, 16, 10, 1, 5, 6, 1, 1, 8, 1, 11, 2, 5, 3, 27, 64, 27, 12, 4, 14, 2, 21, 1, 6, 4, 43, 17, 6, 9, 1, 2, 12, 84, 49, 6, 18, 55, 29, 8, 18, 14, 7, 54, 17, 3, 4, 37, 67, 1, 46, 5, 22, 4, 13, 29, 34, 10, 37, 36, 12, 9, 4, 5, 3, 9, 8, 1, 16, 35, 59, 24, 1, 13, 45, 38, 1, 73, 1, 1, 1, 9, 24, 15, 65, 45, 1, 1, 1, 37, 1, 5, 12, 6, 108, 10, 5, 1, 16, 51, 10, 6, 43, 17, 13, 1, 12, 92, 6, 35, 7, 9, 3, 13, 28, 27, 32, 83, 11, 3, 2, 2, 11, 1, 2, 33, 22, 1, 16, 75, 1, 16, 21, 24, 2, 3, 2, 1, 120, 14, 57, 24, 4, 59, 7, 13, 133, 13, 13, 26, 38, 51, 12, 12, 13, 37, 12, 12, 34, 17, 2, 10, 11, 53, 2, 36, 13, 12, 13, 8, 15, 10, 11, 5, 24, 12, 40, 12, 7, 209, 17, 61]\n",
      "Segments after filtering: 214\n",
      "nb_future_steps  6\n",
      "Total segments found: 25\n",
      "Segment lengths: [842, 337, 1, 1291, 452, 1, 8, 60, 49, 17, 41, 223, 2, 2755, 39, 2606, 306, 3, 250, 248, 829, 539, 269, 218, 286]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 27\n",
      "Segment lengths: [40, 326, 326, 28, 2856, 2402, 347, 93, 1450, 48, 33, 12, 328, 2, 272, 285, 8, 201, 1, 3, 361, 32, 168, 1439, 327, 19, 292]\n",
      "Segments after filtering: 23\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [2177, 390, 12, 2, 2472, 349, 2591, 2741, 96, 1139]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 346\n",
      "Segment lengths: [81, 14, 7, 2, 2, 39, 3, 18, 38, 1, 1, 165, 6, 39, 14, 2, 23, 234, 30, 13, 8, 22, 119, 35, 1, 9, 24, 18, 1, 11, 9, 179, 20, 2, 5, 17, 22, 169, 61, 28, 25, 116, 66, 14, 43, 3, 7, 10, 16, 71, 34, 45, 23, 1, 1, 1, 1, 3, 3, 149, 27, 20, 23, 1, 29, 44, 9, 63, 11, 55, 23, 9, 19, 1, 2, 53, 14, 106, 99, 26, 1, 16, 101, 13, 40, 10, 1, 22, 1, 4, 1, 10, 4, 1, 106, 20, 2, 21, 1, 97, 5, 6, 16, 144, 1, 50, 14, 16, 27, 35, 143, 2, 3, 49, 39, 1, 1, 2, 2, 16, 8, 1, 119, 41, 33, 7, 4, 3, 133, 3, 87, 11, 18, 32, 26, 121, 10, 30, 39, 1, 1, 25, 145, 7, 1, 13, 30, 3, 10, 3, 17, 1, 2, 2, 1, 25, 4, 7, 3, 119, 1, 1, 47, 54, 15, 6, 4, 6, 2, 14, 146, 52, 24, 4, 3, 20, 3, 9, 97, 13, 128, 6, 1, 41, 128, 81, 8, 4, 1, 30, 6, 3, 11, 102, 1, 1, 85, 67, 5, 49, 97, 5, 4, 1, 11, 23, 7, 1, 21, 130, 71, 15, 10, 13, 202, 14, 12, 3, 2, 2, 7, 165, 53, 26, 35, 3, 1, 152, 2, 14, 1, 9, 2, 56, 4, 23, 3, 122, 15, 14, 22, 17, 19, 20, 8, 58, 92, 9, 19, 8, 15, 92, 5, 37, 55, 52, 22, 1, 30, 7, 2, 24, 1, 1, 3, 150, 1, 1, 2, 1, 45, 41, 18, 24, 21, 124, 21, 58, 6, 1, 11, 9, 9, 6, 6, 3, 11, 96, 87, 27, 32, 22, 17, 29, 82, 63, 48, 122, 141, 1, 8, 10, 1, 130, 47, 12, 2, 2, 1, 1, 11, 1, 57, 3, 90, 3, 3, 95, 19, 2, 3, 11, 18, 22, 110, 15, 49, 20, 7, 5, 2, 1, 3, 17, 2, 114, 34, 1, 16, 161, 10, 4, 22, 90, 14, 13]\n",
      "Segments after filtering: 185\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [766, 1, 1900, 331, 491, 855, 523, 1348, 2856, 2552]\n",
      "Segments after filtering: 9\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [1, 727, 2803, 2592, 2712, 108, 2592, 11, 277]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [473, 305, 57, 86, 1639, 575, 184, 175, 560, 27, 79, 320, 1286, 59, 1278, 9, 56, 691, 31, 328, 2, 145, 578, 54, 1769, 126, 158, 560]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [2781, 640, 37, 740, 2852, 1918, 315, 80, 144, 119, 42, 2, 5, 20, 17, 37, 46, 10, 2, 4, 1, 1984]\n",
      "Segments after filtering: 16\n",
      "nb_future_steps  6\n",
      "Total segments found: 15\n",
      "Segment lengths: [1331, 37, 1584, 143, 2004, 733, 688, 157, 927, 1085, 1292, 591, 102, 73, 1039]\n",
      "Segments after filtering: 15\n",
      "nb_future_steps  6\n",
      "Total segments found: 38\n",
      "Segment lengths: [71, 470, 279, 145, 145, 306, 553, 849, 145, 290, 140, 338, 336, 873, 145, 145, 37, 139, 764, 145, 125, 510, 37, 826, 3, 40, 908, 283, 145, 278, 296, 86, 295, 284, 271, 145, 188, 668]\n",
      "Segments after filtering: 37\n",
      "nb_future_steps  6\n",
      "Total segments found: 20\n",
      "Segment lengths: [1919, 354, 470, 5, 18, 420, 1991, 751, 40, 3, 471, 77, 10, 1098, 118, 685, 925, 677, 1307, 315]\n",
      "Segments after filtering: 17\n",
      "nb_future_steps  6\n",
      "Total segments found: 31\n",
      "Segment lengths: [940, 279, 134, 1577, 2, 286, 65, 271, 7, 69, 138, 10, 1, 74, 270, 410, 551, 1438, 439, 77, 841, 1, 1, 2, 27, 5, 2, 1041, 502, 71, 2305]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 29\n",
      "Segment lengths: [40, 330, 58, 903, 41, 925, 533, 3, 129, 384, 656, 857, 812, 4, 8, 856, 480, 321, 789, 393, 249, 813, 19, 1508, 81, 28, 113, 33, 606]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 28\n",
      "Segment lengths: [568, 145, 703, 266, 30, 117, 1313, 4, 222, 6, 1440, 751, 398, 273, 565, 446, 332, 228, 401, 276, 285, 443, 145, 253, 518, 1186, 141, 432]\n",
      "Segments after filtering: 26\n",
      "nb_future_steps  6\n",
      "Total segments found: 39\n",
      "Segment lengths: [2836, 1464, 287, 823, 2631, 4, 2, 3, 2, 3, 3, 1, 118, 52, 1484, 3, 3, 7, 3, 8, 1, 21, 145, 91, 4, 17, 34, 6, 181, 8, 3, 107, 3, 217, 5, 15, 28, 299, 884]\n",
      "Segments after filtering: 20\n",
      "nb_future_steps  6\n",
      "Total segments found: 34\n",
      "Segment lengths: [2402, 4, 248, 2115, 441, 90, 3, 23, 5, 97, 1636, 232, 46, 285, 271, 3, 4, 14, 1610, 5, 19, 81, 4, 204, 1, 1, 4, 2, 4, 2, 4, 127, 1, 448]\n",
      "Segments after filtering: 19\n",
      "nb_future_steps  6\n",
      "Total segments found: 35\n",
      "Segment lengths: [132, 726, 418, 145, 150, 1655, 292, 55, 108, 823, 145, 448, 95, 31, 322, 59, 448, 259, 37, 508, 400, 88, 102, 1813, 33, 76, 278, 275, 327, 190, 196, 64, 223, 592, 187]\n",
      "Segments after filtering: 35\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [2196, 1, 7, 90, 77, 166, 578, 2854, 1315, 115, 9, 385, 321, 13, 1, 33, 146, 4, 120, 376, 1, 2397, 275, 240]\n",
      "Segments after filtering: 18\n",
      "nb_future_steps  6\n",
      "Total segments found: 10\n",
      "Segment lengths: [1150, 1991, 224, 1896, 2011, 1782, 232, 1206, 190, 1143]\n",
      "Segments after filtering: 10\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [2831, 2858, 2856, 2856, 410]\n",
      "Segments after filtering: 5\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [178, 32, 15, 6, 2857, 2856, 2856, 2030]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 44\n",
      "Segment lengths: [398, 268, 104, 152, 269, 300, 375, 657, 93, 189, 129, 282, 202, 37, 144, 248, 102, 449, 239, 419, 404, 268, 900, 72, 470, 82, 159, 165, 206, 106, 318, 144, 144, 225, 135, 141, 138, 649, 325, 201, 232, 174, 395, 128]\n",
      "Segments after filtering: 44\n",
      "nb_future_steps  6\n",
      "Total segments found: 395\n",
      "Segment lengths: [6, 18, 4, 50, 81, 8, 127, 1, 2, 2, 8, 3, 12, 5, 11, 3, 14, 30, 29, 34, 13, 61, 18, 3, 7, 1, 17, 7, 4, 9, 4, 1, 1, 16, 2, 3, 2, 1, 47, 119, 5, 2, 14, 11, 9, 3, 5, 2, 2, 5, 6, 6, 8, 2, 2, 1, 40, 54, 32, 39, 2, 24, 5, 10, 6, 19, 11, 4, 6, 1, 3, 6, 48, 75, 5, 5, 36, 1, 12, 3, 7, 2, 3, 2, 1, 1, 1, 8, 12, 14, 9, 106, 9, 5, 7, 5, 2, 2, 1, 2, 1, 1, 2, 1, 12, 1, 6, 4, 2, 47, 11, 3, 1, 154, 4, 14, 22, 2, 1, 1, 6, 5, 1, 7, 4, 1, 1, 10, 77, 13, 3, 1, 1, 3, 8, 33, 13, 1, 3, 1, 142, 1, 1, 1, 9, 1, 8, 42, 10, 7, 6, 3, 1, 5, 196, 80, 144, 2, 8, 12, 2, 1, 5, 18, 1, 1, 1, 1, 5, 12, 86, 1, 1, 18, 15, 20, 12, 1, 7, 7, 1, 3, 2, 1, 2, 3, 6, 10, 46, 108, 15, 3, 2, 5, 1, 1, 2, 2, 1, 2, 13, 1, 1, 2, 1, 2, 3, 2, 19, 15, 1, 5, 1, 14, 133, 39, 1, 8, 2, 2, 3, 9, 1, 1, 19, 141, 46, 8, 5, 5, 27, 16, 158, 18, 7, 24, 62, 6, 21, 137, 2, 15, 18, 32, 2, 11, 2, 9, 5, 2, 16, 2, 13, 3, 12, 142, 5, 6, 8, 19, 10, 46, 7, 148, 2, 81, 159, 22, 8, 69, 3, 4, 39, 2, 14, 201, 4, 11, 17, 6, 2, 40, 93, 3, 2, 17, 18, 14, 5, 62, 5, 3, 2, 9, 166, 6, 7, 29, 6, 8, 15, 11, 137, 12, 7, 147, 103, 12, 10, 5, 37, 30, 4, 2, 16, 14, 183, 75, 45, 116, 10, 286, 58, 28, 32, 29, 3, 3, 134, 34, 16, 69, 4, 2, 18, 147, 8, 11, 21, 15, 21, 65, 86, 5, 9, 21, 2, 32, 45, 8, 90, 9, 21, 5, 12, 14, 4, 14, 24, 9, 9, 4, 14, 73, 17, 55, 5, 11, 143, 40, 7, 12, 4, 9, 3, 26, 43, 7, 3, 6, 4, 14, 99, 48, 1, 1, 6, 41, 17, 2, 54, 27, 1, 18, 11]\n",
      "Segments after filtering: 154\n",
      "nb_future_steps  6\n",
      "Total segments found: 22\n",
      "Segment lengths: [269, 231, 264, 78, 379, 36, 644, 774, 509, 699, 556, 538, 153, 278, 268, 602, 831, 165, 283, 509, 576, 545]\n",
      "Segments after filtering: 22\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [1773, 51, 109, 2569, 2039, 2304, 8, 121]\n",
      "Segments after filtering: 7\n",
      "nb_future_steps  6\n",
      "Total segments found: 30\n",
      "Segment lengths: [416, 77, 340, 263, 145, 428, 145, 400, 134, 37, 376, 281, 271, 274, 282, 408, 425, 280, 145, 426, 406, 145, 93, 421, 1140, 145, 145, 81, 117, 177]\n",
      "Segments after filtering: 30\n",
      "nb_future_steps  6\n",
      "Total segments found: 24\n",
      "Segment lengths: [1039, 787, 1555, 87, 107, 16, 1, 50, 320, 1362, 148, 262, 1, 2, 284, 32, 71, 1953, 611, 212, 800, 395, 528, 1153]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [152, 108, 288, 1078, 288, 556, 1931, 1078, 499, 1714, 1885, 1944]\n",
      "Segments after filtering: 12\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [512, 1411, 27, 201, 847, 46, 1431, 476, 213, 237, 122, 140, 254, 272, 367, 1068, 563, 1372, 896, 15, 1101]\n",
      "Segments after filtering: 21\n",
      "nb_future_steps  6\n",
      "Total segments found: 11\n",
      "Segment lengths: [0, 2658, 74, 2589, 165, 2199, 623, 150, 2687, 187, 523]\n",
      "Segments after filtering: 10\n",
      "x_train.shape:  (366707, 6, 1)\n",
      "y_train.shape:  (366707, 1)\n",
      "x_valid.shape:  (91655, 6, 1)\n",
      "y_valid.shape:  (91655, 1)\n",
      "x_test.shape:  (0, 6, 1)\n",
      "y_test.shape:  (0, 1)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:30:58,619 WARNING Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-01-17 09:30:58,828 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-01-17 09:30:58,828 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-01-17 09:30:58,849 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 366707 samples, validate on 91655 samples\n",
      "Epoch 1/10000\n",
      "364544/366707 [============================>.] - ETA: 0s - loss: 0.3418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366707/366707 [==============================] - 4s 10us/sample - loss: 0.3408 - val_loss: 0.1451\n",
      "Epoch 2/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.1443 - val_loss: 0.0236\n",
      "Epoch 3/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.1057 - val_loss: 0.0141\n",
      "Epoch 4/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0863 - val_loss: 0.0388\n",
      "Epoch 5/10000\n",
      "364544/366707 [============================>.] - ETA: 0s - loss: 0.06572025-01-17 09:31:13,127 DEBUG Creating converter from 5 to 3\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0656 - val_loss: -0.0162\n",
      "Epoch 6/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0494 - val_loss: -0.0169\n",
      "Epoch 7/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0405 - val_loss: -0.0301\n",
      "Epoch 8/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0310 - val_loss: -0.0196\n",
      "Epoch 9/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0268 - val_loss: -0.0318\n",
      "Epoch 10/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0191 - val_loss: -0.0249\n",
      "Epoch 11/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0111 - val_loss: -0.0042\n",
      "Epoch 12/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0063 - val_loss: -0.0151\n",
      "Epoch 13/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: 0.0022 - val_loss: -0.0115\n",
      "Epoch 14/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0037 - val_loss: -0.0562\n",
      "Epoch 15/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0095 - val_loss: -0.0366\n",
      "Epoch 16/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0145 - val_loss: -0.0472\n",
      "Epoch 17/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0190 - val_loss: -0.0503\n",
      "Epoch 18/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0198 - val_loss: -0.0276\n",
      "Epoch 19/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0236 - val_loss: -0.0516\n",
      "Epoch 20/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0257 - val_loss: -0.0525\n",
      "Epoch 21/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0286 - val_loss: -0.0549\n",
      "Epoch 22/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0309 - val_loss: -0.0520\n",
      "Epoch 23/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0301 - val_loss: -0.0552\n",
      "Epoch 24/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0328 - val_loss: -0.0429\n",
      "Epoch 25/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0338 - val_loss: -0.0564\n",
      "Epoch 26/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0340 - val_loss: -0.0563\n",
      "Epoch 27/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0353 - val_loss: -0.0556\n",
      "Epoch 28/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0350 - val_loss: -0.0575\n",
      "Epoch 29/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0381 - val_loss: -0.0651\n",
      "Epoch 30/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0395 - val_loss: -0.0606\n",
      "Epoch 31/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0384 - val_loss: -0.0603\n",
      "Epoch 32/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0406 - val_loss: -0.0489\n",
      "Epoch 33/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0401 - val_loss: -0.0470\n",
      "Epoch 34/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0418 - val_loss: -0.0626\n",
      "Epoch 35/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0387 - val_loss: -0.0432\n",
      "Epoch 36/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0422 - val_loss: -0.0342\n",
      "Epoch 37/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0420 - val_loss: -0.0511\n",
      "Epoch 38/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0426 - val_loss: -0.0486\n",
      "Epoch 39/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0424 - val_loss: -0.0567\n",
      "Epoch 40/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0435 - val_loss: -0.0658\n",
      "Epoch 41/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0442 - val_loss: -0.0645\n",
      "Epoch 42/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0456 - val_loss: -0.0601\n",
      "Epoch 43/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0446 - val_loss: -0.0549\n",
      "Epoch 44/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0461 - val_loss: -0.0642\n",
      "Epoch 45/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0472 - val_loss: -0.0678\n",
      "Epoch 46/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0468 - val_loss: -0.0540\n",
      "Epoch 47/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0482 - val_loss: -0.0562\n",
      "Epoch 48/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0473 - val_loss: -0.0660\n",
      "Epoch 49/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0474 - val_loss: -0.0681\n",
      "Epoch 50/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0472 - val_loss: -0.0620\n",
      "Epoch 51/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0474 - val_loss: -0.0631\n",
      "Epoch 52/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0484 - val_loss: -0.0663\n",
      "Epoch 53/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0503 - val_loss: -0.0676\n",
      "Epoch 54/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0476 - val_loss: -0.0698\n",
      "Epoch 55/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0501 - val_loss: -0.0648\n",
      "Epoch 56/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0490 - val_loss: -0.0652\n",
      "Epoch 57/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0500 - val_loss: -0.0615\n",
      "Epoch 58/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0491 - val_loss: -0.0645\n",
      "Epoch 59/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0504 - val_loss: -0.0607\n",
      "Epoch 60/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0497 - val_loss: -0.0611\n",
      "Epoch 61/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0513 - val_loss: -0.0658\n",
      "Epoch 62/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0500 - val_loss: -0.0648\n",
      "Epoch 63/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0506 - val_loss: -0.0696\n",
      "Epoch 64/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0501 - val_loss: -0.0680\n",
      "Epoch 65/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0511 - val_loss: -0.0740\n",
      "Epoch 66/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0504 - val_loss: -0.0679\n",
      "Epoch 67/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0511 - val_loss: -0.0691\n",
      "Epoch 68/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0516 - val_loss: -0.0716\n",
      "Epoch 69/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0521 - val_loss: -0.0723\n",
      "Epoch 70/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0525 - val_loss: -0.0639\n",
      "Epoch 71/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0515 - val_loss: -0.0698\n",
      "Epoch 72/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0521 - val_loss: -0.0707\n",
      "Epoch 73/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0526 - val_loss: -0.0701\n",
      "Epoch 74/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0523 - val_loss: -0.0675\n",
      "Epoch 75/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0527 - val_loss: -0.0687\n",
      "Epoch 76/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0531 - val_loss: -0.0660\n",
      "Epoch 77/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0531 - val_loss: -0.0700\n",
      "Epoch 78/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0514 - val_loss: -0.0676\n",
      "Epoch 79/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0529 - val_loss: -0.0731\n",
      "Epoch 80/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0520 - val_loss: -0.0645\n",
      "Epoch 81/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0530 - val_loss: -0.0674\n",
      "Epoch 82/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0535 - val_loss: -0.0695\n",
      "Epoch 83/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0532 - val_loss: -0.0669\n",
      "Epoch 84/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0530 - val_loss: -0.0688\n",
      "Epoch 85/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0540 - val_loss: -0.0715\n",
      "Epoch 86/10000\n",
      "366707/366707 [==============================] - 3s 9us/sample - loss: -0.0539 - val_loss: -0.0705\n",
      "Epoch 87/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0535 - val_loss: -0.0680\n",
      "Epoch 88/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0538 - val_loss: -0.0718\n",
      "Epoch 89/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0545 - val_loss: -0.0743\n",
      "Epoch 90/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0537 - val_loss: -0.0613\n",
      "Epoch 91/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0533 - val_loss: -0.0700\n",
      "Epoch 92/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0544 - val_loss: -0.0724\n",
      "Epoch 93/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0539 - val_loss: -0.0752\n",
      "Epoch 94/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0546 - val_loss: -0.0703\n",
      "Epoch 95/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0560 - val_loss: -0.0540\n",
      "Epoch 96/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0549 - val_loss: -0.0706\n",
      "Epoch 97/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0543 - val_loss: -0.0682\n",
      "Epoch 98/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0554 - val_loss: -0.0707\n",
      "Epoch 99/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0556 - val_loss: -0.0751\n",
      "Epoch 100/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0546 - val_loss: -0.0710\n",
      "Epoch 101/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0567 - val_loss: -0.0771\n",
      "Epoch 102/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0555 - val_loss: -0.0670\n",
      "Epoch 103/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0564 - val_loss: -0.0704\n",
      "Epoch 104/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0559 - val_loss: -0.0648\n",
      "Epoch 105/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0566 - val_loss: -0.0664\n",
      "Epoch 106/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0563 - val_loss: -0.0725\n",
      "Epoch 107/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0548 - val_loss: -0.0710\n",
      "Epoch 108/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0557 - val_loss: -0.0682\n",
      "Epoch 109/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0571 - val_loss: -0.0702\n",
      "Epoch 110/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0560 - val_loss: -0.0665\n",
      "Epoch 111/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0567 - val_loss: -0.0661\n",
      "Epoch 112/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0559 - val_loss: -0.0727\n",
      "Epoch 113/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0562 - val_loss: -0.0741\n",
      "Epoch 114/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0563 - val_loss: -0.0618\n",
      "Epoch 115/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0569 - val_loss: -0.0725\n",
      "Epoch 116/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0553 - val_loss: -0.0704\n",
      "Epoch 117/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0568 - val_loss: -0.0673\n",
      "Epoch 118/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0560 - val_loss: -0.0742\n",
      "Epoch 119/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0567 - val_loss: -0.0681\n",
      "Epoch 120/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0573 - val_loss: -0.0716\n",
      "Epoch 121/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0568 - val_loss: -0.0547\n",
      "Epoch 122/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0570 - val_loss: -0.0550\n",
      "Epoch 123/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0561 - val_loss: -0.0692\n",
      "Epoch 124/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0567 - val_loss: -0.0681\n",
      "Epoch 125/10000\n",
      "366707/366707 [==============================] - 2s 7us/sample - loss: -0.0572 - val_loss: -0.0726\n",
      "Epoch 126/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0573 - val_loss: -0.0611\n",
      "Epoch 127/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0584 - val_loss: -0.0723\n",
      "Epoch 128/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0582 - val_loss: -0.0738\n",
      "Epoch 129/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0564 - val_loss: -0.0720\n",
      "Epoch 130/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0568 - val_loss: -0.0696\n",
      "Epoch 131/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0574 - val_loss: -0.0736\n",
      "Epoch 132/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0588 - val_loss: -0.0670\n",
      "Epoch 133/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0571 - val_loss: -0.0718\n",
      "Epoch 134/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0584 - val_loss: -0.0692\n",
      "Epoch 135/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0580 - val_loss: -0.0717\n",
      "Epoch 136/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0582 - val_loss: -0.0667\n",
      "Epoch 137/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0579 - val_loss: -0.0607\n",
      "Epoch 138/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0580 - val_loss: -0.0641\n",
      "Epoch 139/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0596 - val_loss: -0.0684\n",
      "Epoch 140/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0591 - val_loss: -0.0714\n",
      "Epoch 141/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0585 - val_loss: -0.0720\n",
      "Epoch 142/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0582 - val_loss: -0.0664\n",
      "Epoch 143/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0584 - val_loss: -0.0685\n",
      "Epoch 144/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0588 - val_loss: -0.0688\n",
      "Epoch 145/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0576 - val_loss: -0.0664\n",
      "Epoch 146/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0592 - val_loss: -0.0698\n",
      "Epoch 147/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0593 - val_loss: -0.0672\n",
      "Epoch 148/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0580 - val_loss: -0.0643\n",
      "Epoch 149/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0581 - val_loss: -0.0746\n",
      "Epoch 150/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0582 - val_loss: -0.0756\n",
      "Epoch 151/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0595 - val_loss: -0.0708\n",
      "Epoch 152/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0581 - val_loss: -0.0706\n",
      "Epoch 153/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0589 - val_loss: -0.0698\n",
      "Epoch 154/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0598 - val_loss: -0.0721\n",
      "Epoch 155/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0593 - val_loss: -0.0674\n",
      "Epoch 156/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0589 - val_loss: -0.0567\n",
      "Epoch 157/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0590 - val_loss: -0.0732\n",
      "Epoch 158/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0589 - val_loss: -0.0745\n",
      "Epoch 159/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0593 - val_loss: -0.0742\n",
      "Epoch 160/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0590 - val_loss: -0.0692\n",
      "Epoch 161/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0595 - val_loss: -0.0743\n",
      "Epoch 162/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0600 - val_loss: -0.0643\n",
      "Epoch 163/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0588 - val_loss: -0.0659\n",
      "Epoch 164/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0597 - val_loss: -0.0616\n",
      "Epoch 165/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0590 - val_loss: -0.0726\n",
      "Epoch 166/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0592 - val_loss: -0.0685\n",
      "Epoch 167/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0589 - val_loss: -0.0691\n",
      "Epoch 168/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0597 - val_loss: -0.0645\n",
      "Epoch 169/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0609 - val_loss: -0.0672\n",
      "Epoch 170/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0596 - val_loss: -0.0648\n",
      "Epoch 171/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0594 - val_loss: -0.0697\n",
      "Epoch 172/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0613 - val_loss: -0.0713\n",
      "Epoch 173/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0607 - val_loss: -0.0670\n",
      "Epoch 174/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0608 - val_loss: -0.0735\n",
      "Epoch 175/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0601 - val_loss: -0.0716\n",
      "Epoch 176/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0606 - val_loss: -0.0717\n",
      "Epoch 177/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0598 - val_loss: -0.0648\n",
      "Epoch 178/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0601 - val_loss: -0.0721\n",
      "Epoch 179/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0599 - val_loss: -0.0728\n",
      "Epoch 180/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0614 - val_loss: -0.0668\n",
      "Epoch 181/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0602 - val_loss: -0.0706\n",
      "Epoch 182/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0607 - val_loss: -0.0743\n",
      "Epoch 183/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0609 - val_loss: -0.0481\n",
      "Epoch 184/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0603 - val_loss: -0.0742\n",
      "Epoch 185/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0611 - val_loss: -0.0735\n",
      "Epoch 186/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0619 - val_loss: -0.0589\n",
      "Epoch 187/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0604 - val_loss: -0.0708\n",
      "Epoch 188/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0615 - val_loss: -0.0652\n",
      "Epoch 189/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0617 - val_loss: -0.0677\n",
      "Epoch 190/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0598 - val_loss: -0.0734\n",
      "Epoch 191/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0617 - val_loss: -0.0775\n",
      "Epoch 192/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0615 - val_loss: -0.0767\n",
      "Epoch 193/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0617 - val_loss: -0.0725\n",
      "Epoch 194/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0607 - val_loss: -0.0666\n",
      "Epoch 195/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0631 - val_loss: -0.0666\n",
      "Epoch 196/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0609 - val_loss: -0.0636\n",
      "Epoch 197/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0607 - val_loss: -0.0709\n",
      "Epoch 198/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0618 - val_loss: -0.0689\n",
      "Epoch 199/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0617 - val_loss: -0.0704\n",
      "Epoch 200/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0624 - val_loss: -0.0730\n",
      "Epoch 201/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0620 - val_loss: -0.0738\n",
      "Epoch 202/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0615 - val_loss: -0.0648\n",
      "Epoch 203/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0600 - val_loss: -0.0684\n",
      "Epoch 204/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0628 - val_loss: -0.0726\n",
      "Epoch 205/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0622 - val_loss: -0.0669\n",
      "Epoch 206/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0628 - val_loss: -0.0685\n",
      "Epoch 207/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0620 - val_loss: -0.0728\n",
      "Epoch 208/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0623 - val_loss: -0.0741\n",
      "Epoch 209/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0618 - val_loss: -0.0751\n",
      "Epoch 210/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0622 - val_loss: -0.0719\n",
      "Epoch 211/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0625 - val_loss: -0.0735\n",
      "Epoch 212/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0629 - val_loss: -0.0614\n",
      "Epoch 213/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0615 - val_loss: -0.0677\n",
      "Epoch 214/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0614 - val_loss: -0.0710\n",
      "Epoch 215/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0621 - val_loss: -0.0749\n",
      "Epoch 216/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0625 - val_loss: -0.0678\n",
      "Epoch 217/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0621 - val_loss: -0.0674\n",
      "Epoch 218/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0619 - val_loss: -0.0674\n",
      "Epoch 219/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0627 - val_loss: -0.0675\n",
      "Epoch 220/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0637 - val_loss: -0.0698\n",
      "Epoch 221/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0620 - val_loss: -0.0745\n",
      "Epoch 222/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0629 - val_loss: -0.0671\n",
      "Epoch 223/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0630 - val_loss: -0.0754\n",
      "Epoch 224/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0620 - val_loss: -0.0759\n",
      "Epoch 225/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0618 - val_loss: -0.0764\n",
      "Epoch 226/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0629 - val_loss: -0.0695\n",
      "Epoch 227/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0629 - val_loss: -0.0631\n",
      "Epoch 228/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0622 - val_loss: -0.0748\n",
      "Epoch 229/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0619 - val_loss: -0.0699\n",
      "Epoch 230/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0632 - val_loss: -0.0694\n",
      "Epoch 231/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0628 - val_loss: -0.0636\n",
      "Epoch 232/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0633 - val_loss: -0.0709\n",
      "Epoch 233/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0635 - val_loss: -0.0709\n",
      "Epoch 234/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0630 - val_loss: -0.0709\n",
      "Epoch 235/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0632 - val_loss: -0.0680\n",
      "Epoch 236/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0642 - val_loss: -0.0732\n",
      "Epoch 237/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0644 - val_loss: -0.0744\n",
      "Epoch 238/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0638 - val_loss: -0.0742\n",
      "Epoch 239/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0639 - val_loss: -0.0673\n",
      "Epoch 240/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0633 - val_loss: -0.0704\n",
      "Epoch 241/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0647 - val_loss: -0.0579\n",
      "Epoch 242/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0631 - val_loss: -0.0720\n",
      "Epoch 243/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0648 - val_loss: -0.0764\n",
      "Epoch 244/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0626 - val_loss: -0.0723\n",
      "Epoch 245/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0632 - val_loss: -0.0773\n",
      "Epoch 246/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0636 - val_loss: -0.0730\n",
      "Epoch 247/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0636 - val_loss: -0.0747\n",
      "Epoch 248/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0638 - val_loss: -0.0685\n",
      "Epoch 249/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0634 - val_loss: -0.0715\n",
      "Epoch 250/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0627 - val_loss: -0.0619\n",
      "Epoch 251/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0649 - val_loss: -0.0718\n",
      "Epoch 252/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0642 - val_loss: -0.0697\n",
      "Epoch 253/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0651 - val_loss: -0.0683\n",
      "Epoch 254/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0640 - val_loss: -0.0718\n",
      "Epoch 255/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0643 - val_loss: -0.0605\n",
      "Epoch 256/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0655 - val_loss: -0.0751\n",
      "Epoch 257/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0648 - val_loss: -0.0667\n",
      "Epoch 258/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0645 - val_loss: -0.0751\n",
      "Epoch 259/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0642 - val_loss: -0.0622\n",
      "Epoch 260/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0641 - val_loss: -0.0727\n",
      "Epoch 261/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0647 - val_loss: -0.0551\n",
      "Epoch 262/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0638 - val_loss: -0.0755\n",
      "Epoch 263/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0648 - val_loss: -0.0626\n",
      "Epoch 264/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0642 - val_loss: -0.0668\n",
      "Epoch 265/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0645 - val_loss: -0.0736\n",
      "Epoch 266/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0651 - val_loss: -0.0681\n",
      "Epoch 267/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0649 - val_loss: -0.0740\n",
      "Epoch 268/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0646 - val_loss: -0.0755\n",
      "Epoch 269/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0657 - val_loss: -0.0696\n",
      "Epoch 270/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0652 - val_loss: -0.0643\n",
      "Epoch 271/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0752\n",
      "Epoch 272/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0659 - val_loss: -0.0736\n",
      "Epoch 273/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0687\n",
      "Epoch 274/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0645 - val_loss: -0.0648\n",
      "Epoch 275/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0650 - val_loss: -0.0678\n",
      "Epoch 276/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0657 - val_loss: -0.0750\n",
      "Epoch 277/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0686\n",
      "Epoch 278/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0652 - val_loss: -0.0721\n",
      "Epoch 279/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0653 - val_loss: -0.0699\n",
      "Epoch 280/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0611\n",
      "Epoch 281/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0655 - val_loss: -0.0657\n",
      "Epoch 282/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0655 - val_loss: -0.0695\n",
      "Epoch 283/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0659 - val_loss: -0.0705\n",
      "Epoch 284/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0651 - val_loss: -0.0620\n",
      "Epoch 285/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0661 - val_loss: -0.0726\n",
      "Epoch 286/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0663 - val_loss: -0.0700\n",
      "Epoch 287/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0653 - val_loss: -0.0709\n",
      "Epoch 288/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0658 - val_loss: -0.0716\n",
      "Epoch 289/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0661 - val_loss: -0.0651\n",
      "Epoch 290/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0662 - val_loss: -0.0674\n",
      "Epoch 291/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0723\n",
      "Epoch 292/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0656 - val_loss: -0.0474\n",
      "Epoch 293/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0660 - val_loss: -0.0605\n",
      "Epoch 294/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0663 - val_loss: -0.0750\n",
      "Epoch 295/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0650 - val_loss: -0.0709\n",
      "Epoch 296/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0668 - val_loss: -0.0733\n",
      "Epoch 297/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0654 - val_loss: -0.0582\n",
      "Epoch 298/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0664 - val_loss: -0.0688\n",
      "Epoch 299/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0662 - val_loss: -0.0724\n",
      "Epoch 300/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0663 - val_loss: -0.0729\n",
      "Epoch 301/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0663 - val_loss: -0.0742\n",
      "Epoch 302/10000\n",
      "366707/366707 [==============================] - 2s 7us/sample - loss: -0.0657 - val_loss: -0.0654\n",
      "Epoch 303/10000\n",
      "366707/366707 [==============================] - 2s 7us/sample - loss: -0.0659 - val_loss: -0.0721\n",
      "Epoch 304/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0662 - val_loss: -0.0687\n",
      "Epoch 305/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0667 - val_loss: -0.0716\n",
      "Epoch 306/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0669 - val_loss: -0.0678\n",
      "Epoch 307/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0670 - val_loss: -0.0590\n",
      "Epoch 308/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0661 - val_loss: -0.0655\n",
      "Epoch 309/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0677 - val_loss: -0.0690\n",
      "Epoch 310/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0669 - val_loss: -0.0715\n",
      "Epoch 311/10000\n",
      "366707/366707 [==============================] - 2s 7us/sample - loss: -0.0668 - val_loss: -0.0686\n",
      "Epoch 312/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0673 - val_loss: -0.0633\n",
      "Epoch 313/10000\n",
      "366707/366707 [==============================] - 2s 7us/sample - loss: -0.0670 - val_loss: -0.0628\n",
      "Epoch 314/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0679 - val_loss: -0.0643\n",
      "Epoch 315/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0669 - val_loss: -0.0674\n",
      "Epoch 316/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0669 - val_loss: -0.0677\n",
      "Epoch 317/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0674 - val_loss: -0.0619\n",
      "Epoch 318/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0677 - val_loss: -0.0692\n",
      "Epoch 319/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0660 - val_loss: -0.0726\n",
      "Epoch 320/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0671 - val_loss: -0.0704\n",
      "Epoch 321/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0659 - val_loss: -0.0696\n",
      "Epoch 322/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0672 - val_loss: -0.0664\n",
      "Epoch 323/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0676 - val_loss: -0.0683\n",
      "Epoch 324/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0672 - val_loss: -0.0663\n",
      "Epoch 325/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0667 - val_loss: -0.0705\n",
      "Epoch 326/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0674 - val_loss: -0.0554\n",
      "Epoch 327/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0670 - val_loss: -0.0696\n",
      "Epoch 328/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0678 - val_loss: -0.0707\n",
      "Epoch 329/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0680 - val_loss: -0.0663\n",
      "Epoch 330/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0672 - val_loss: -0.0743\n",
      "Epoch 331/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0676 - val_loss: -0.0642\n",
      "Epoch 332/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0679 - val_loss: -0.0686\n",
      "Epoch 333/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0686 - val_loss: -0.0535\n",
      "Epoch 334/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0684 - val_loss: -0.0709\n",
      "Epoch 335/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0668 - val_loss: -0.0692\n",
      "Epoch 336/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0684 - val_loss: -0.0631\n",
      "Epoch 337/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0687 - val_loss: -0.0554\n",
      "Epoch 338/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0679 - val_loss: -0.0679\n",
      "Epoch 339/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0674 - val_loss: -0.0691\n",
      "Epoch 340/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0673 - val_loss: -0.0679\n",
      "Epoch 341/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0669 - val_loss: -0.0660\n",
      "Epoch 342/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0691 - val_loss: -0.0729\n",
      "Epoch 343/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0666 - val_loss: -0.0676\n",
      "Epoch 344/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0675 - val_loss: -0.0644\n",
      "Epoch 345/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0682 - val_loss: -0.0710\n",
      "Epoch 346/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0679 - val_loss: -0.0700\n",
      "Epoch 347/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0682 - val_loss: -0.0730\n",
      "Epoch 348/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0661 - val_loss: -0.0730\n",
      "Epoch 349/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0677 - val_loss: -0.0673\n",
      "Epoch 350/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0684 - val_loss: -0.0632\n",
      "Epoch 351/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0683 - val_loss: -0.0687\n",
      "Epoch 352/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0697 - val_loss: -0.0663\n",
      "Epoch 353/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0699 - val_loss: -0.0674\n",
      "Epoch 354/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0684 - val_loss: -0.0723\n",
      "Epoch 355/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0690 - val_loss: -0.0724\n",
      "Epoch 356/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0686 - val_loss: -0.0613\n",
      "Epoch 357/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0687 - val_loss: -0.0705\n",
      "Epoch 358/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0679 - val_loss: -0.0649\n",
      "Epoch 359/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0687 - val_loss: -0.0585\n",
      "Epoch 360/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0676 - val_loss: -0.0655\n",
      "Epoch 361/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0683 - val_loss: -0.0738\n",
      "Epoch 362/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0694 - val_loss: -0.0736\n",
      "Epoch 363/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0685 - val_loss: -0.0682\n",
      "Epoch 364/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0691 - val_loss: -0.0667\n",
      "Epoch 365/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0684 - val_loss: -0.0672\n",
      "Epoch 366/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0687 - val_loss: -0.0655\n",
      "Epoch 367/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0689 - val_loss: -0.0716\n",
      "Epoch 368/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0688 - val_loss: -0.0668\n",
      "Epoch 369/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0693 - val_loss: -0.0726\n",
      "Epoch 370/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0700 - val_loss: -0.0703\n",
      "Epoch 371/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0689 - val_loss: -0.0681\n",
      "Epoch 372/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0699 - val_loss: -0.0697\n",
      "Epoch 373/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0695 - val_loss: -0.0700\n",
      "Epoch 374/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0699 - val_loss: -0.0716\n",
      "Epoch 375/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0688 - val_loss: -0.0628\n",
      "Epoch 376/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0703 - val_loss: -0.0698\n",
      "Epoch 377/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0690 - val_loss: -0.0740\n",
      "Epoch 378/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0689 - val_loss: -0.0656\n",
      "Epoch 379/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0694 - val_loss: -0.0668\n",
      "Epoch 380/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0689 - val_loss: -0.0674\n",
      "Epoch 381/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0697 - val_loss: -0.0692\n",
      "Epoch 382/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0700 - val_loss: -0.0705\n",
      "Epoch 383/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0691 - val_loss: -0.0720\n",
      "Epoch 384/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0700 - val_loss: -0.0605\n",
      "Epoch 385/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0704 - val_loss: -0.0526\n",
      "Epoch 386/10000\n",
      "366707/366707 [==============================] - 3s 8us/sample - loss: -0.0692 - val_loss: -0.0650\n",
      "Epoch 387/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0699 - val_loss: -0.0670\n",
      "Epoch 388/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0705 - val_loss: -0.0624\n",
      "Epoch 389/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0699 - val_loss: -0.0650\n",
      "Epoch 390/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0707 - val_loss: -0.0632\n",
      "Epoch 391/10000\n",
      "366707/366707 [==============================] - 3s 7us/sample - loss: -0.0698 - val_loss: -0.0643\n"
     ]
    }
   ],
   "source": [
    "cfgs = load_cfgs(yaml_filepath)\n",
    "print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "for cfg in cfgs:\n",
    "    seed = int(cfg['train']['seed'])\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Print the configuration - just to make sure that you loaded what you\n",
    "    # wanted to load\n",
    "\n",
    "    module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "    module_model         = load_module(cfg['model']['script_path'])\n",
    "    module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "    module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "    module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(cfg)\n",
    "\n",
    "    #print(\"loading dataset ...\")\n",
    "    #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "    #nb_past_steps_tmp = 36\n",
    "    #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "    #x_train = x_train[:,-nb_past_steps:,:]\n",
    "    #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "    #x_test = x_test[:,-nb_past_steps:,:]\n",
    "    print(\"x_train.shape: \", x_train.shape)\n",
    "    print(\"y_train.shape: \", y_train.shape)\n",
    "    print(\"x_valid.shape: \", x_valid.shape)\n",
    "    print(\"y_valid.shape: \", y_valid.shape)\n",
    "    print(\"x_test.shape: \", x_test.shape)\n",
    "    print(\"y_test.shape: \", y_test.shape)\n",
    "    \n",
    "    #print(\"loading optimizer ...\")\n",
    "    optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "\n",
    "    #print(\"loading loss function ...\")\n",
    "    loss_function = module_loss_function.load()\n",
    "    #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "    #print(\"loading model ...\")\n",
    "    if 'tf_nll' in loss_function.__name__:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1]*2,\n",
    "            cfg['model']\n",
    "        )\n",
    "    else:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1],\n",
    "            cfg['model']\n",
    "        )\n",
    "\n",
    "    if 'initial_weights_path' in cfg['train']:\n",
    "        #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "        model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_function\n",
    "    )\n",
    "\n",
    "    #print(model.summary())\n",
    "\n",
    "    # training mode\n",
    "    if mode == 'train':\n",
    "        #print(\"training model ...\")\n",
    "        train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "    if mode == 'plot_nll':\n",
    "        plot_nll(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_noise_experiment':\n",
    "        plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_seg':\n",
    "        plot_seg(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_dist':\n",
    "        plot_target_distribution(y_test, cfg)\n",
    "\n",
    "    # evaluation mode\n",
    "    if mode == 'evaluate':\n",
    "        evaluate(model, x_test, y_test, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject23_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject24_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject25_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject26_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject27_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject28_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject29_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject30_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject31_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject32_evaluation.yaml',\n",
       " './original_diatrend_experiments_30min/fold3_eval\\\\processed_cgm_data_Subject33_evaluation.yaml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all yaml files in the directory\n",
    "yaml_files = glob.glob(\"./original_diatrend_experiments_30min/fold3_eval/*.yaml\")\n",
    "\n",
    "yaml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject23.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject23.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 21\n",
      "Segment lengths: [27, 1276, 577, 695, 71, 2759, 44, 15, 23, 802, 1760, 136, 44, 925, 632, 1, 3, 414, 547, 74, 1005]\n",
      "Segments after filtering: 19\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11617, 6, 1)\n",
      "y_test.shape:  (11617, 1)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:47:57,217 WARNING Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject23\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n",
      "2025-01-17 09:47:57,321 DEBUG Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject23\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject24.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject24.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 59\n",
      "Segment lengths: [23, 1038, 71, 18, 124, 75, 28, 103, 112, 43, 12, 174, 74, 5, 92, 32, 348, 152, 728, 122, 106, 939, 212, 241, 76, 164, 576, 37, 240, 23, 181, 201, 104, 175, 46, 214, 21, 21, 2, 3, 2, 388, 537, 484, 500, 64, 6, 111, 136, 2, 50, 100, 214, 210, 205, 59, 294, 160, 86]\n",
      "Segments after filtering: 53\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (9961, 6, 1)\n",
      "y_test.shape:  (9961, 1)\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:47:59,875 WARNING Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject24\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject24\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject25.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject25.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 9\n",
      "Segment lengths: [2806, 1050, 1627, 170, 1, 35, 2802, 2792, 602]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11796, 6, 1)\n",
      "y_test.shape:  (11796, 1)\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:02,750 WARNING Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject25\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject25\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject26.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject26.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 14\n",
      "Segment lengths: [33, 656, 43, 666, 1346, 524, 1238, 1404, 2824, 3, 1720, 734, 305, 341]\n",
      "Segments after filtering: 13\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11691, 6, 1)\n",
      "y_test.shape:  (11691, 1)\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:05,654 WARNING Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject26\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject26\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject27.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject27.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [2433, 2324, 502, 1057, 1281, 485, 2856, 1029]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11879, 6, 1)\n",
      "y_test.shape:  (11879, 1)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:08,546 WARNING Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject27\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject27\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject28.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject28.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 8\n",
      "Segment lengths: [289, 1376, 2189, 515, 439, 2360, 2856, 1874]\n",
      "Segments after filtering: 8\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11810, 6, 1)\n",
      "y_test.shape:  (11810, 1)\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:11,341 WARNING Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject28\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject28\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject29.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject29.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 548\n",
      "Segment lengths: [10, 17, 24, 3, 8, 1, 3, 4, 1, 58, 1, 3, 171, 2, 19, 2, 1, 25, 96, 8, 37, 25, 19, 20, 46, 26, 27, 18, 20, 9, 1, 2, 1, 2, 6, 5, 2, 2, 1, 7, 4, 9, 13, 2, 1, 4, 1, 3, 2, 8, 13, 1, 28, 17, 5, 23, 7, 3, 23, 20, 42, 32, 5, 1, 20, 18, 37, 16, 16, 1, 1, 11, 11, 3, 2, 4, 3, 2, 3, 1, 15, 2, 12, 19, 30, 23, 10, 5, 5, 9, 10, 1, 45, 21, 11, 3, 22, 21, 16, 6, 38, 1, 16, 42, 1, 10, 43, 8, 2, 18, 4, 30, 8, 1, 50, 65, 11, 7, 13, 2, 20, 27, 110, 1, 15, 1, 3, 3, 5, 25, 1, 67, 8, 21, 3, 2, 1, 12, 18, 21, 1, 6, 10, 10, 57, 12, 9, 14, 1, 9, 2, 11, 10, 11, 12, 5, 17, 7, 5, 8, 10, 26, 19, 4, 57, 39, 2, 47, 19, 12, 13, 13, 8, 1, 8, 2, 5, 9, 7, 3, 7, 7, 31, 4, 2, 11, 1, 9, 46, 1, 15, 49, 6, 110, 13, 10, 2, 1, 14, 15, 10, 6, 4, 5, 50, 35, 20, 8, 65, 46, 3, 3, 16, 9, 7, 67, 1, 19, 23, 25, 4, 26, 2, 1, 11, 12, 10, 6, 20, 4, 29, 5, 25, 34, 13, 54, 34, 6, 3, 2, 25, 1, 6, 12, 9, 4, 28, 1, 2, 23, 18, 21, 3, 37, 19, 18, 69, 8, 48, 16, 3, 19, 133, 16, 1, 23, 9, 69, 5, 40, 1, 7, 30, 22, 11, 267, 11, 30, 63, 9, 18, 24, 38, 29, 2, 24, 8, 7, 9, 1, 17, 13, 4, 13, 4, 47, 30, 3, 14, 9, 43, 18, 14, 50, 1, 5, 19, 18, 25, 22, 20, 21, 39, 24, 5, 1, 18, 6, 23, 22, 21, 1, 28, 27, 21, 3, 2, 16, 13, 27, 12, 169, 10, 27, 15, 16, 12, 2, 24, 33, 5, 48, 25, 155, 47, 35, 10, 25, 10, 19, 5, 14, 32, 8, 95, 7, 29, 44, 21, 38, 14, 14, 27, 3, 1, 42, 3, 34, 20, 23, 7, 73, 7, 43, 11, 33, 1, 21, 8, 51, 61, 1, 50, 3, 31, 6, 14, 8, 126, 1, 1, 3, 5, 65, 48, 25, 37, 10, 9, 59, 37, 1, 12, 19, 23, 17, 2, 74, 43, 3, 8, 26, 2, 28, 10, 65, 21, 7, 135, 6, 28, 17, 21, 1, 73, 13, 1, 38, 4, 29, 22, 30, 80, 3, 17, 21, 1, 2, 16, 45, 73, 12, 7, 83, 14, 5, 1, 27, 7, 21, 53, 23, 7, 1, 2, 30, 26, 31, 116, 1, 40, 38, 7, 4, 2, 1, 1, 36, 3, 43, 23, 6, 1, 45, 10, 26, 8, 7, 32, 10, 9, 32, 44, 8, 2, 12, 3, 7, 53, 43, 6, 3, 9, 30, 2, 1, 7, 7, 11, 15, 59, 46, 22, 18, 4, 26, 4, 8, 1, 2, 7, 11, 2, 6, 4, 19, 53, 47, 17, 14, 13, 70, 3, 13, 21, 6, 2, 5, 17, 41, 9, 1, 10, 32, 22, 14, 81, 15, 1, 1, 73, 55, 4, 7, 27, 9, 12, 58]\n",
      "Segments after filtering: 279\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (6579, 6, 1)\n",
      "y_test.shape:  (6579, 1)\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:14,167 WARNING Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject29\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject29\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject30.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject30.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 13\n",
      "Segment lengths: [2015, 72, 1, 11, 49, 45, 622, 1728, 2851, 2847, 78, 1473, 131]\n",
      "Segments after filtering: 11\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11790, 6, 1)\n",
      "y_test.shape:  (11790, 1)\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:16,479 WARNING Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject30\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject30\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject31.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject31.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 5\n",
      "Segment lengths: [1345, 2518, 2856, 2854, 2423]\n",
      "Segments after filtering: 5\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11941, 6, 1)\n",
      "y_test.shape:  (11941, 1)\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:19,355 WARNING Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject31\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject31\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject32.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject32.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 19\n",
      "Segment lengths: [1016, 17, 53, 508, 96, 1291, 257, 690, 14, 1706, 1440, 17, 2291, 6, 45, 8, 447, 312, 1693]\n",
      "Segments after filtering: 17\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11706, 6, 1)\n",
      "y_test.shape:  (11706, 1)\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:22,340 WARNING Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject32\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject32\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject33.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\martinsson_diatrend_experiment_6sh\\\\nb_future_steps_6_seed_20_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [20],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 20,\n",
      "                 'shuffle': True}}\n",
      "C:\\Users\\baiyi\\OneDrive\\Desktop\\Modify_GenBG\\modified_diatrend_subset\\processed_cgm_data_Subject33.csv\n",
      "nb_future_steps  6\n",
      "Total segments found: 12\n",
      "Segment lengths: [67, 23, 106, 2606, 305, 2, 1363, 2856, 576, 1440, 749, 1735]\n",
      "Segments after filtering: 11\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11705, 6, 1)\n",
      "y_test.shape:  (11705, 1)\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-17 09:48:25,393 WARNING Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject33\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\martinsson_diatrend_experiment_6sh\\nb_future_steps_6_seed_20_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject33\n"
     ]
    }
   ],
   "source": [
    "mode = \"evaluate\"\n",
    "for yaml_filepath in yaml_files:\n",
    "    cfgs = load_cfgs(yaml_filepath)\n",
    "    print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "    for cfg in cfgs:\n",
    "        seed = int(cfg['train']['seed'])\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Print the configuration - just to make sure that you loaded what you\n",
    "        # wanted to load\n",
    "\n",
    "        module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "        module_model         = load_module(cfg['model']['script_path'])\n",
    "        module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "        module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "        module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(cfg)\n",
    "\n",
    "        #print(\"loading dataset ...\")\n",
    "        #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "        #nb_past_steps_tmp = 36\n",
    "        #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "        #x_train = x_train[:,-nb_past_steps:,:]\n",
    "        #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "        #x_test = x_test[:,-nb_past_steps:,:]\n",
    "        print(\"x_train.shape: \", x_train.shape)\n",
    "        print(\"y_train.shape: \", y_train.shape)\n",
    "        print(\"x_valid.shape: \", x_valid.shape)\n",
    "        print(\"y_valid.shape: \", y_valid.shape)\n",
    "        print(\"x_test.shape: \", x_test.shape)\n",
    "        print(\"y_test.shape: \", y_test.shape)\n",
    "        #print(\"loading optimizer ...\")\n",
    "        optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "        #print(\"loading loss function ...\")\n",
    "        loss_function = module_loss_function.load()\n",
    "        #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "        #print(\"loading model ...\")\n",
    "        if 'tf_nll' in loss_function.__name__:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1]*2,\n",
    "                cfg['model']\n",
    "            )\n",
    "        else:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1],\n",
    "                cfg['model']\n",
    "            )\n",
    "\n",
    "        if 'initial_weights_path' in cfg['train']:\n",
    "            #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "            model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_function\n",
    "        )\n",
    "\n",
    "        #print(model.summary())\n",
    "\n",
    "        # training mode\n",
    "        if mode == 'train':\n",
    "            #print(\"training model ...\")\n",
    "            train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "        if mode == 'plot_nll':\n",
    "            plot_nll(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_noise_experiment':\n",
    "            plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_seg':\n",
    "            plot_seg(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_dist':\n",
    "            plot_target_distribution(y_test, cfg)\n",
    "\n",
    "        # evaluation mode\n",
    "        if mode == 'evaluate':\n",
    "            evaluate(model, x_test, y_test, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject1.csv',\n",
       " 'nb_past_steps': 6,\n",
       " 'param_nb_future_steps': [6],\n",
       " 'scale': 0.01,\n",
       " 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
       " 'test_fraction': 1.0,\n",
       " 'train_fraction': 0.0,\n",
       " 'valid_fraction': 0.0,\n",
       " 'nb_future_steps': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a similar function to construct the Diatrend dataset\n",
    "def load_diatrend_series(path):\n",
    "    subject = pd.read_csv(path)\n",
    "\n",
    "    # Lists to store the results\n",
    "    parsed_dates = []\n",
    "    values = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in subject.iterrows():\n",
    "        # Parse the date using the custom function\n",
    "        parsed_date = parse_date(row['date'])\n",
    "        \n",
    "        # Append the parsed date and corresponding value to the lists\n",
    "        parsed_dates.append(parsed_date)\n",
    "        values.append(float(row['mg/dl']))\n",
    "\n",
    "    # Now 'parsed_dates' and 'values' contain your data\n",
    "    # print(parsed_dates)\n",
    "    # print(values)\n",
    "    index = pd.DatetimeIndex(parsed_dates)\n",
    "    series = pd.Series(values, index=index)\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(cfg):\n",
    "    if os.path.basename(cfg['csv_path']) == 'all':\n",
    "        print(\"loading training data for all patients ...\")\n",
    "        csvs = os.path.join(os.path.dirname(cfg['csv_path']), \"*.csv\")\n",
    "        csv_paths = glob.glob(csvs)\n",
    "        tups = []\n",
    "        for csv_path in csv_paths:\n",
    "            cfg['csv_path'] = csv_path\n",
    "            tups.append(load_data(cfg))\n",
    "        x_train = np.concatenate([t[0] for t in tups], axis=0)\n",
    "        y_train = np.concatenate([t[1] for t in tups], axis=0)\n",
    "        \n",
    "        x_valid = np.concatenate([t[2] for t in tups], axis=0)\n",
    "        y_valid = np.concatenate([t[3] for t in tups], axis=0)\n",
    "        x_test = np.concatenate([t[4] for t in tups], axis=0)\n",
    "        y_test = np.concatenate([t[5] for t in tups], axis=0)\n",
    "\n",
    "        cfg['csv_path'] = 'all'\n",
    "        return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "    else:\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(cfg)\n",
    "        return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "\n",
    "def load_data(cfg):\n",
    "    csv_path        = cfg['csv_path']\n",
    "    nb_past_steps   = int(cfg['nb_past_steps'])\n",
    "    nb_future_steps = int(cfg['nb_future_steps'])\n",
    "    train_fraction  = float(cfg['train_fraction'])\n",
    "    valid_fraction  = float(cfg['valid_fraction'])\n",
    "    test_fraction   = float(cfg['test_fraction'])\n",
    "    print(\"nb_future_steps \", nb_future_steps)\n",
    "\n",
    "    xs, ys = load_glucose_data(csv_path, nb_past_steps, nb_future_steps)\n",
    "    ys = np.expand_dims(ys, axis=1)\n",
    "\n",
    "    x_train, x_valid, x_test = utils.split_data(xs, train_fraction,\n",
    "            valid_fraction, test_fraction)\n",
    "    y_train, y_valid, y_test = utils.split_data(ys, train_fraction,\n",
    "            valid_fraction, test_fraction)\n",
    "\n",
    "    # scale data\n",
    "    scale = float(cfg['scale'])\n",
    "    x_train *= scale\n",
    "    y_train *= scale\n",
    "    x_valid *= scale\n",
    "    y_valid *= scale\n",
    "    x_test  *= scale\n",
    "    y_test  *= scale\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "\n",
    "def load_glucose_data(csv_path, nb_past_steps, nb_future_steps):\n",
    "    df_glucose_level = load_diatrend_series(csv_path)\n",
    "    dt = df_glucose_level.index.to_series().diff().dropna()\n",
    "    # print(dt.size)\n",
    "    idx_breaks = np.argwhere(dt!=pd.Timedelta(6, 'm'))\n",
    "    # print(dt.size)\n",
    "\n",
    "    # It would be possible to load more features here\n",
    "    nd_glucose_level = df_glucose_level.values\n",
    "    consecutive_segments = np.split(nd_glucose_level, idx_breaks.flatten())\n",
    "\n",
    "    consecutive_segments = [c for c in consecutive_segments if len(c) >=\n",
    "            nb_past_steps+nb_future_steps]\n",
    "    print(len(consecutive_segments))\n",
    "\n",
    "    sups = [utils.sequence_to_supervised(c, nb_past_steps, nb_future_steps) for\n",
    "            c in consecutive_segments]\n",
    "\n",
    "    xss = [sup[0] for sup in sups]\n",
    "    yss = [sup[1] for sup in sups]\n",
    "\n",
    "    xs = np.concatenate(xss)\n",
    "    ys = np.concatenate(yss)\n",
    "\n",
    "    return np.expand_dims(xs, axis=2), ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
