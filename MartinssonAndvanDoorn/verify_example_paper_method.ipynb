{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-27 16:48:10,027 DEBUG matplotlib data path: c:\\Users\\username\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\matplotlib\\mpl-data\n",
      "2024-08-27 16:48:10,027 DEBUG CONFIGDIR=C:\\Users\\username\\.matplotlib\n",
      "2024-08-27 16:48:10,027 DEBUG interactive is False\n",
      "2024-08-27 16:48:10,027 DEBUG platform is win32\n",
      "2024-08-27 16:48:10,078 DEBUG CACHEDIR=C:\\Users\\username\\.matplotlib\n",
      "2024-08-27 16:48:10,078 DEBUG Using fontManager instance from C:\\Users\\username\\.matplotlib\\fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pprint\n",
    "import importlib.util\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import copy\n",
    "import datetime\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "import numpy as np\n",
    "import metrics\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_filepath = f\"./experiments/all_final_experiment.yaml\"\n",
    "mode = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_module(script_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"module.name\", script_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "def load_cfg(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load a YAML configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream)\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "    return cfg\n",
    "\n",
    "def load_cfgs(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load YAML configuration files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfgs : [dict]\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream, Loader=yaml.SafeLoader)\n",
    "\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "\n",
    "    hyperparameters = []\n",
    "    hyperparameter_names = []\n",
    "    hyperparameter_values = []\n",
    "    # TODO: ugly, should handle arbitrary depth\n",
    "    for k1 in cfg.keys():\n",
    "        for k2 in cfg[k1].keys():\n",
    "            if k2.startswith(\"param_\"):\n",
    "                hyperparameters.append((k1, k2))\n",
    "                hyperparameter_names.append((k1, k2[6:]))\n",
    "                hyperparameter_values.append(cfg[k1][k2])\n",
    "\n",
    "    hyperparameter_valuess = itertools.product(*hyperparameter_values)\n",
    "\n",
    "\n",
    "    artifacts_path = cfg['train']['artifacts_path']\n",
    "\n",
    "    cfgs = []\n",
    "    for hyperparameter_values in hyperparameter_valuess:\n",
    "        configuration_name = \"\"\n",
    "        for ((k1, k2), value) in zip(hyperparameter_names, hyperparameter_values):\n",
    "            #print(k1, k2, value)\n",
    "            cfg[k1][k2] = value\n",
    "            configuration_name += \"{}_{}_\".format(k2, str(value))\n",
    "\n",
    "        cfg['train']['artifacts_path'] = os.path.join(artifacts_path, configuration_name)\n",
    "\n",
    "        cfgs.append(copy.deepcopy(cfg))\n",
    "\n",
    "    return cfgs\n",
    "\n",
    "\n",
    "\n",
    "def make_paths_absolute(dir_, cfg):\n",
    "    \"\"\"\n",
    "    Make all values for keys ending with `_path` absolute to dir_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_ : str\n",
    "    cfg : dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    for key in cfg.keys():\n",
    "        if key.endswith(\"_path\"):\n",
    "            cfg[key] = os.path.join(dir_, cfg[key])\n",
    "            cfg[key] = os.path.abspath(cfg[key])\n",
    "            if not os.path.exists(cfg[key]):\n",
    "                logging.error(\"%s does not exist.\", cfg[key])\n",
    "        if type(cfg[key]) is dict:\n",
    "            cfg[key] = make_paths_absolute(dir_, cfg[key])\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test, y_test, cfg):\n",
    "    if 'xml_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['xml_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    weights_path = os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\")\n",
    "    print(\"loading weights: {}\".format(weights_path))\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    y_pred = model.predict(x_test)[:,1].flatten()/scale\n",
    "    y_std  = model.predict(x_test)[:,0].flatten()/scale\n",
    "    y_test = y_test.flatten()/scale\n",
    "    t0 = x_test[:,-1,0]/scale\n",
    "\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    print(\"patient id: \", patient_id)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(rmse))\n",
    "\n",
    "    seg = metrics.surveillance_error(y_test, y_pred)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(seg))\n",
    "\n",
    "    t0_rmse = metrics.root_mean_squared_error(y_test, t0)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(t0_rmse))\n",
    "\n",
    "    t0_seg = metrics.surveillance_error(y_test, t0)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(t0_seg))\n",
    "\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mean_std.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(np.mean(y_std)))\n",
    "\n",
    "    print(\"RMSE: \", rmse)\n",
    "    print(\"t0 RMSE: \", t0_rmse)\n",
    "    print(\"SEG: \", seg)\n",
    "    print(\"t0 SEG: \", t0_seg)\n",
    "\n",
    "def train(model, module_train, x_train, y_train, x_valid, y_valid, cfg):\n",
    "    model = module_train.train(\n",
    "        model          = model,\n",
    "        x_train        = x_train,\n",
    "        y_train        = y_train,\n",
    "        x_valid        = x_valid,\n",
    "        y_valid        = y_valid,\n",
    "        batch_size     = int(cfg['train']['batch_size']),\n",
    "        epochs         = int(cfg['train']['epochs']),\n",
    "        patience       = int(cfg['train']['patience']),\n",
    "        shuffle        = cfg['train']['shuffle'],\n",
    "        artifacts_path = cfg['train']['artifacts_path']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_target_distribution(y_test, cfg):\n",
    "    if 'xml_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['xml_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    plt.figure()\n",
    "    sns.distplot(y_test.flatten()/scale, kde=False, norm_hist=True)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_dist_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_nll(model, x_test, y_test, cfg):\n",
    "    if 'xml_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['xml_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    for i in range(5):\n",
    "        start_index = i*to_plot\n",
    "        y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]/scale\n",
    "        y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]/scale\n",
    "        y_true      = y_test[:,0][start_index:start_index+to_plot]/scale\n",
    "\n",
    "        xs = np.arange(len(y_true))\n",
    "        plt.clf()\n",
    "        plt.ylim([0, 400])\n",
    "        #plt.ylim([-2, 2])\n",
    "        plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "        plt.plot(xs, y_pred_mean, label='prediction')\n",
    "        plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "                alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "        plt.xlabel(\"Time [h]\")\n",
    "        plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "        plt.legend(loc='upper right')\n",
    "        #plt.xlabel(\"y\")\n",
    "        #plt.ylabel(\"x\")\n",
    "        plt.xticks(ticks, ticks_labels)\n",
    "        save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_nll_plot_{}.pdf\".format(patient_id, i))\n",
    "        print(\"saving plot to: \", save_path)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_noise_experiment(model, x_test, y_test, cfg):\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    start_index = 0\n",
    "    y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]\n",
    "    y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]\n",
    "    y_true      = y_test[:,0][start_index:start_index+to_plot]\n",
    "\n",
    "    xs = np.arange(len(y_true))\n",
    "    plt.clf()\n",
    "    #plt.ylim([0, 400])\n",
    "    plt.ylim([-3, 3])\n",
    "    plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "    plt.plot(xs, y_pred_mean, label='prediction')\n",
    "    plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "            alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "    #plt.xlabel(\"Time [h]\")\n",
    "    #plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xticks(ticks, ticks_labels)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"noise_experiment_plot.pdf\")\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "def plot_seg(model, x_test, y_test, cfg):\n",
    "    if 'xml_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['xml_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "    y_pred_std  = y_pred[:,0][:]/scale\n",
    "    y_pred_mean = y_pred[:,1][:]/scale\n",
    "    y_true      = y_test[:,0][:]/scale\n",
    "\n",
    "    data = np.loadtxt('seg.csv')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Patient {} SEG'.format(patient_id))\n",
    "    ax.set_xlabel('Reference Concentration [mg/dl]')\n",
    "    ax.set_ylabel('Predicted Concentration [mg/dl]')\n",
    "    cax = ax.imshow(np.transpose(data), origin='lower', interpolation='nearest')\n",
    "    cbar = fig.colorbar(cax, ticks=[0.25, 1.0, 2.0, 3.0, 3.75], orientation='vertical')\n",
    "    cbar.ax.set_yticklabels(['None', 'Mild', 'Moderate', 'High', 'Extreme'],\n",
    "            rotation=90, va='center')\n",
    "\n",
    "    plt.scatter(y_true, y_pred_mean, s=25, facecolors='white', edgecolors='black')\n",
    "\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_seg_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = load_cfgs(yaml_filepath)\n",
    "print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "for cfg in cfgs:\n",
    "    seed = int(cfg['train']['seed'])\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Print the configuration - just to make sure that you loaded what you\n",
    "    # wanted to load\n",
    "\n",
    "    module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "    module_model         = load_module(cfg['model']['script_path'])\n",
    "    module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "    module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "    module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(cfg)\n",
    "\n",
    "    #print(\"loading dataset ...\")\n",
    "    #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "    #nb_past_steps_tmp = 36\n",
    "    #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "    #x_train = x_train[:,-nb_past_steps:,:]\n",
    "    #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "    #x_test = x_test[:,-nb_past_steps:,:]\n",
    "    print(\"x_train.shape: \", x_train.shape)\n",
    "    print(\"y_train.shape: \", y_train.shape)\n",
    "    print(\"x_valid.shape: \", x_valid.shape)\n",
    "    print(\"y_valid.shape: \", y_valid.shape)\n",
    "    print(\"x_test.shape: \", x_test.shape)\n",
    "    print(\"y_test.shape: \", y_test.shape)\n",
    "    #print(\"loading optimizer ...\")\n",
    "    optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "    #print(\"loading loss function ...\")\n",
    "    loss_function = module_loss_function.load()\n",
    "    #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "    #print(\"loading model ...\")\n",
    "    if 'tf_nll' in loss_function.__name__:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1]*2,\n",
    "            cfg['model']\n",
    "        )\n",
    "    else:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1],\n",
    "            cfg['model']\n",
    "        )\n",
    "\n",
    "    if 'initial_weights_path' in cfg['train']:\n",
    "        #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "        model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_function\n",
    "    )\n",
    "\n",
    "    #print(model.summary())\n",
    "\n",
    "    # training mode\n",
    "    if mode == 'train':\n",
    "        #print(\"training model ...\")\n",
    "        train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "    if mode == 'plot_nll':\n",
    "        plot_nll(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_noise_experiment':\n",
    "        plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_seg':\n",
    "        plot_seg(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_dist':\n",
    "        plot_target_distribution(y_test, cfg)\n",
    "\n",
    "    # evaluation mode\n",
    "    if mode == 'evaluate':\n",
    "        evaluate(model, x_test, y_test, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yaml_filepath = f\"./experiments/559_all_final_evaluation.yaml\" # Replace the yaml\n",
    "mode = \"evaluate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10 experiments.\n",
      "WARNING:tensorflow:From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2024-04-29 21:59:08,432 WARNING From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_6_seed_1_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 1,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2310, 12, 1)\n",
      "y_test.shape:  (2310, 1)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:08,869 WARNING Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2024-04-29 21:59:09,027 WARNING From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2024-04-29 21:59:09,029 WARNING From C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_6_seed_1_\\model.hdf5\n",
      "2024-04-29 21:59:09,043 DEBUG Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\username\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  559\n",
      "RMSE:  20.227814750199414\n",
      "t0 RMSE:  23.400956431410275\n",
      "SEG:  (0.21978004842222393, 0.2558415569663708)\n",
      "t0 SEG:  (0.22420962530334088, 0.26318405237688214)\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_6_seed_5_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 5,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2310, 12, 1)\n",
      "y_test.shape:  (2310, 1)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:18,166 WARNING Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_6_seed_5_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  19.61504560202516\n",
      "t0 RMSE:  23.400956431410275\n",
      "SEG:  (0.19655599800396484, 0.24477569334724703)\n",
      "t0 SEG:  (0.22420962530334088, 0.26318405237688214)\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2310, 12, 1)\n",
      "y_test.shape:  (2310, 1)\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:19,164 WARNING Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  20.127054296473233\n",
      "t0 RMSE:  23.400956431410275\n",
      "SEG:  (0.22169142609824255, 0.2572181869919903)\n",
      "t0 SEG:  (0.22420962530334088, 0.26318405237688214)\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_6_seed_25_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 25,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2310, 12, 1)\n",
      "y_test.shape:  (2310, 1)\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:20,252 WARNING Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_6_seed_25_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  20.164865961712486\n",
      "t0 RMSE:  23.400956431410275\n",
      "SEG:  (0.19451031672783914, 0.24733744537139546)\n",
      "t0 SEG:  (0.22420962530334088, 0.26318405237688214)\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_6_seed_50_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 50,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2310, 12, 1)\n",
      "y_test.shape:  (2310, 1)\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:21,391 WARNING Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_6_seed_50_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  19.771312961805148\n",
      "t0 RMSE:  23.400956431410275\n",
      "SEG:  (0.2047075975182698, 0.25225132344795287)\n",
      "t0 SEG:  (0.22420962530334088, 0.26318405237688214)\n",
      "{   'dataset': {   'nb_future_steps': 12,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_12_seed_1_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 1,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  12\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2238, 12, 1)\n",
      "y_test.shape:  (2238, 1)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:22,428 WARNING Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_12_seed_1_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  34.230485928807816\n",
      "t0 RMSE:  39.404248715090546\n",
      "SEG:  (0.3517027876816812, 0.38164950361248406)\n",
      "t0 SEG:  (0.38563892613092354, 0.3924092545292145)\n",
      "{   'dataset': {   'nb_future_steps': 12,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_12_seed_5_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 5,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  12\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2238, 12, 1)\n",
      "y_test.shape:  (2238, 1)\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:23,535 WARNING Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_12_seed_5_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  34.408795692544835\n",
      "t0 RMSE:  39.404248715090546\n",
      "SEG:  (0.355789135141727, 0.38795279329961596)\n",
      "t0 SEG:  (0.38563892613092354, 0.3924092545292145)\n",
      "{   'dataset': {   'nb_future_steps': 12,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_12_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  12\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2238, 12, 1)\n",
      "y_test.shape:  (2238, 1)\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:24,625 WARNING Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_12_seed_10_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  34.29846022299652\n",
      "t0 RMSE:  39.404248715090546\n",
      "SEG:  (0.36647044735827555, 0.3963401073176972)\n",
      "t0 SEG:  (0.38563892613092354, 0.3924092545292145)\n",
      "{   'dataset': {   'nb_future_steps': 12,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_12_seed_25_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 25,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  12\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2238, 12, 1)\n",
      "y_test.shape:  (2238, 1)\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:25,747 WARNING Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_12_seed_25_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  34.65518049352933\n",
      "t0 RMSE:  39.404248715090546\n",
      "SEG:  (0.356752165080915, 0.38438423352441287)\n",
      "t0 SEG:  (0.38563892613092354, 0.3924092545292145)\n",
      "{   'dataset': {   'nb_future_steps': 12,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6, 12],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\OhioT1DM\\\\2018\\\\test\\\\559-ws-testing.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\artifacts\\\\all_final_experiment\\\\nb_future_steps_12_seed_50_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 100000,\n",
      "                 'param_seed': [1, 5, 10, 25, 50],\n",
      "                 'patience': 1000,\n",
      "                 'script_path': 'c:\\\\Users\\\\username\\\\OneDrive\\\\Desktop\\\\BGprediction\\\\Method1\\\\blood-glucose-prediction\\\\train\\\\train_keras.py',\n",
      "                 'seed': 50,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  12\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (2238, 12, 1)\n",
      "y_test.shape:  (2238, 1)\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2024-04-29 21:59:26,924 WARNING Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "loading weights: c:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\Method1\\blood-glucose-prediction\\artifacts\\all_final_experiment\\nb_future_steps_12_seed_50_\\model.hdf5\n",
      "patient id:  559\n",
      "RMSE:  34.466755918111\n",
      "t0 RMSE:  39.404248715090546\n",
      "SEG:  (0.3642315167207139, 0.39228702124292597)\n",
      "t0 SEG:  (0.38563892613092354, 0.3924092545292145)\n"
     ]
    }
   ],
   "source": [
    "cfgs = load_cfgs(yaml_filepath)\n",
    "print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "for cfg in cfgs:\n",
    "    seed = int(cfg['train']['seed'])\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Print the configuration - just to make sure that you loaded what you\n",
    "    # wanted to load\n",
    "\n",
    "    module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "    module_model         = load_module(cfg['model']['script_path'])\n",
    "    module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "    module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "    module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(cfg)\n",
    "\n",
    "    #print(\"loading dataset ...\")\n",
    "    #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "    #nb_past_steps_tmp = 36\n",
    "    #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "    #x_train = x_train[:,-nb_past_steps:,:]\n",
    "    #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "    #x_test = x_test[:,-nb_past_steps:,:]\n",
    "    print(\"x_train.shape: \", x_train.shape)\n",
    "    print(\"y_train.shape: \", y_train.shape)\n",
    "    print(\"x_valid.shape: \", x_valid.shape)\n",
    "    print(\"y_valid.shape: \", y_valid.shape)\n",
    "    print(\"x_test.shape: \", x_test.shape)\n",
    "    print(\"y_test.shape: \", y_test.shape)\n",
    "    #print(\"loading optimizer ...\")\n",
    "    optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "    #print(\"loading loss function ...\")\n",
    "    loss_function = module_loss_function.load()\n",
    "    #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "    #print(\"loading model ...\")\n",
    "    if 'tf_nll' in loss_function.__name__:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1]*2,\n",
    "            cfg['model']\n",
    "        )\n",
    "    else:\n",
    "        model = module_model.load(\n",
    "            x_train.shape[1:],\n",
    "            y_train.shape[1],\n",
    "            cfg['model']\n",
    "        )\n",
    "\n",
    "    if 'initial_weights_path' in cfg['train']:\n",
    "        #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "        model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_function\n",
    "    )\n",
    "\n",
    "    #print(model.summary())\n",
    "\n",
    "    # training mode\n",
    "    if mode == 'train':\n",
    "        #print(\"training model ...\")\n",
    "        train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "    if mode == 'plot_nll':\n",
    "        plot_nll(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_noise_experiment':\n",
    "        plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_seg':\n",
    "        plot_seg(model, x_test, y_test, cfg)\n",
    "    if mode == 'plot_dist':\n",
    "        plot_target_distribution(y_test, cfg)\n",
    "\n",
    "    # evaluation mode\n",
    "    if mode == 'evaluate':\n",
    "        evaluate(model, x_test, y_test, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
