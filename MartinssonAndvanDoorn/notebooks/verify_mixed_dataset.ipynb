{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all libraries and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:16:27,940 DEBUG matplotlib data path: c:\\Users\\baiyi\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\matplotlib\\mpl-data\n",
      "2025-02-02 22:16:27,956 DEBUG CONFIGDIR=C:\\Users\\baiyi\\.matplotlib\n",
      "2025-02-02 22:16:27,956 DEBUG interactive is False\n",
      "2025-02-02 22:16:27,956 DEBUG platform is win32\n",
      "2025-02-02 22:16:28,009 DEBUG CACHEDIR=C:\\Users\\baiyi\\.matplotlib\n",
      "2025-02-02 22:16:28,010 DEBUG Using fontManager instance from C:\\Users\\baiyi\\.matplotlib\\fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pprint\n",
    "import importlib.util\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import copy\n",
    "import datetime\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "import numpy as np\n",
    "import metrics\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "# Look at the output of ohio data loader\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_module(script_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"module.name\", script_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "def load_cfg(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load a YAML configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream)\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "    return cfg\n",
    "\n",
    "def load_cfgs(yaml_filepath):\n",
    "    \"\"\"\n",
    "    Load YAML configuration files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_filepath : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfgs : [dict]\n",
    "    \"\"\"\n",
    "    # Read YAML experiment definition file\n",
    "    with open(yaml_filepath, 'r') as stream:\n",
    "        cfg = yaml.load(stream, Loader=yaml.SafeLoader)\n",
    "\n",
    "    cfg = make_paths_absolute(os.path.dirname(yaml_filepath), cfg)\n",
    "\n",
    "    hyperparameters = []\n",
    "    hyperparameter_names = []\n",
    "    hyperparameter_values = []\n",
    "    # TODO: ugly, should handle arbitrary depth\n",
    "    for k1 in cfg.keys():\n",
    "        for k2 in cfg[k1].keys():\n",
    "            if k2.startswith(\"param_\"):\n",
    "                hyperparameters.append((k1, k2))\n",
    "                hyperparameter_names.append((k1, k2[6:]))\n",
    "                hyperparameter_values.append(cfg[k1][k2])\n",
    "\n",
    "    hyperparameter_valuess = itertools.product(*hyperparameter_values)\n",
    "\n",
    "\n",
    "    artifacts_path = cfg['train']['artifacts_path']\n",
    "\n",
    "    cfgs = []\n",
    "    for hyperparameter_values in hyperparameter_valuess:\n",
    "        configuration_name = \"\"\n",
    "        for ((k1, k2), value) in zip(hyperparameter_names, hyperparameter_values):\n",
    "            #print(k1, k2, value)\n",
    "            cfg[k1][k2] = value\n",
    "            configuration_name += \"{}_{}_\".format(k2, str(value))\n",
    "\n",
    "        cfg['train']['artifacts_path'] = os.path.join(artifacts_path, configuration_name)\n",
    "\n",
    "        cfgs.append(copy.deepcopy(cfg))\n",
    "\n",
    "    return cfgs\n",
    "\n",
    "\n",
    "\n",
    "def make_paths_absolute(dir_, cfg):\n",
    "    \"\"\"\n",
    "    Make all values for keys ending with `_path` absolute to dir_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_ : str\n",
    "    cfg : dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : dict\n",
    "    \"\"\"\n",
    "    for key in cfg.keys():\n",
    "        if key.endswith(\"_path\"):\n",
    "            cfg[key] = os.path.join(dir_, cfg[key])\n",
    "            cfg[key] = os.path.abspath(cfg[key])\n",
    "            if not os.path.exists(cfg[key]):\n",
    "                logging.error(\"%s does not exist.\", cfg[key])\n",
    "        if type(cfg[key]) is dict:\n",
    "            cfg[key] = make_paths_absolute(dir_, cfg[key])\n",
    "    return cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('_')[-1].split('.')[0]\n",
    "    else:\n",
    "        basename = os.path.basename(cfg['dataset']['xml_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    print(f\"Evaluating for patient_id: {patient_id}\")\n",
    "    # load the trained weights\n",
    "    weights_path = os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\")\n",
    "    print(\"loading weights: {}\".format(weights_path))\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    y_pred = model.predict(x_test)[:,1].flatten()/scale\n",
    "    y_std  = model.predict(x_test)[:,0].flatten()/scale\n",
    "    y_test = y_test.flatten()/scale\n",
    "    t0 = x_test[:,-1,0]/scale\n",
    "\n",
    "    rmse = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "    print(\"patient id: \", patient_id)\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(rmse))\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mae.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(mae))\n",
    "\n",
    "    # Calculate MSE\n",
    "    # mse = np.mean((y_test - y_pred) ** 2)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(mse))\n",
    "\n",
    "    # Calculate MAPE\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Multiply by 100 for percentage\n",
    "    with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mape.txt\".format(patient_id)), \"w\") as outfile:\n",
    "        outfile.write(\"{}\\n\".format(mape))\n",
    "\n",
    "    # seg = metrics.surveillance_error(y_test, y_pred)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(seg))\n",
    "\n",
    "    # t0_rmse = metrics.root_mean_squared_error(y_test, t0)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_rmse.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(t0_rmse))\n",
    "\n",
    "    # t0_seg = metrics.surveillance_error(y_test, t0)\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_t0_seg.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(t0_seg))\n",
    "\n",
    "    # with open(os.path.join(cfg['train']['artifacts_path'], \"{}_mean_std.txt\".format(patient_id)), \"w\") as outfile:\n",
    "    #     outfile.write(\"{}\\n\".format(np.mean(y_std)))\n",
    "\n",
    "    # print(\"RMSE: \", rmse)\n",
    "    # print(\"t0 RMSE: \", t0_rmse)\n",
    "    # print(\"SEG: \", seg)\n",
    "    # print(\"t0 SEG: \", t0_seg)\n",
    "\n",
    "def train(model, module_train, x_train, y_train, x_valid, y_valid, cfg):\n",
    "    model = module_train.train(\n",
    "        model          = model,\n",
    "        x_train        = x_train,\n",
    "        y_train        = y_train,\n",
    "        x_valid        = x_valid,\n",
    "        y_valid        = y_valid,\n",
    "        batch_size     = int(cfg['train']['batch_size']),\n",
    "        epochs         = int(cfg['train']['epochs']),\n",
    "        patience       = int(cfg['train']['patience']),\n",
    "        shuffle        = cfg['train']['shuffle'],\n",
    "        artifacts_path = cfg['train']['artifacts_path']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_target_distribution(y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    plt.figure()\n",
    "    sns.distplot(y_test.flatten()/scale, kde=False, norm_hist=True)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_dist_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_nll(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    for i in range(5):\n",
    "        start_index = i*to_plot\n",
    "        y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]/scale\n",
    "        y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]/scale\n",
    "        y_true      = y_test[:,0][start_index:start_index+to_plot]/scale\n",
    "\n",
    "        xs = np.arange(len(y_true))\n",
    "        plt.clf()\n",
    "        plt.ylim([0, 400])\n",
    "        #plt.ylim([-2, 2])\n",
    "        plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "        plt.plot(xs, y_pred_mean, label='prediction')\n",
    "        plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "                alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "        plt.xlabel(\"Time [h]\")\n",
    "        plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "        plt.legend(loc='upper right')\n",
    "        #plt.xlabel(\"y\")\n",
    "        #plt.ylabel(\"x\")\n",
    "        plt.xticks(ticks, ticks_labels)\n",
    "        save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_nll_plot_{}.pdf\".format(patient_id, i))\n",
    "        print(\"saving plot to: \", save_path)\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "\n",
    "def plot_noise_experiment(model, x_test, y_test, cfg):\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    #day = (24*60//5)\n",
    "    start_index = 0\n",
    "    hours = 8\n",
    "    to_plot=hours*12\n",
    "    ticks_per_hour = 12\n",
    "    ticks = [i*ticks_per_hour for i in range(hours+1)]\n",
    "    ticks_labels = [str(i) for i in range(hours+1)]\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "\n",
    "    start_index = 0\n",
    "    y_pred_std  = y_pred[:,0][start_index:start_index+to_plot]\n",
    "    y_pred_mean = y_pred[:,1][start_index:start_index+to_plot]\n",
    "    y_true      = y_test[:,0][start_index:start_index+to_plot]\n",
    "\n",
    "    xs = np.arange(len(y_true))\n",
    "    plt.clf()\n",
    "    #plt.ylim([0, 400])\n",
    "    plt.ylim([-3, 3])\n",
    "    plt.plot(xs, y_true, label='ground truth', linestyle='--')\n",
    "    plt.plot(xs, y_pred_mean, label='prediction')\n",
    "    plt.fill_between(xs, y_pred_mean-y_pred_std, y_pred_mean+y_pred_std,\n",
    "            alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "    #plt.xlabel(\"Time [h]\")\n",
    "    #plt.ylabel(\"Glucose Concentration [mg/dl]\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xticks(ticks, ticks_labels)\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"noise_experiment_plot.pdf\")\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "def plot_seg(model, x_test, y_test, cfg):\n",
    "    if 'csv_path' in cfg['dataset']:\n",
    "        basename = os.path.basename(cfg['dataset']['csv_path'])\n",
    "        patient_id = basename.split('-')[0]\n",
    "    else:\n",
    "        patient_id = \"\"\n",
    "    if 'scale' in cfg['dataset']:\n",
    "        scale = float(cfg['dataset']['scale'])\n",
    "    else:\n",
    "        scale = 1.0\n",
    "\n",
    "    # load the trained weights\n",
    "    model.load_weights(os.path.join(cfg['train']['artifacts_path'], \"model.hdf5\"))\n",
    "\n",
    "    y_pred      = model.predict(x_test)\n",
    "    y_pred_std  = y_pred[:,0][:]/scale\n",
    "    y_pred_mean = y_pred[:,1][:]/scale\n",
    "    y_true      = y_test[:,0][:]/scale\n",
    "\n",
    "    data = np.loadtxt('seg.csv')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Patient {} SEG'.format(patient_id))\n",
    "    ax.set_xlabel('Reference Concentration [mg/dl]')\n",
    "    ax.set_ylabel('Predicted Concentration [mg/dl]')\n",
    "    cax = ax.imshow(np.transpose(data), origin='lower', interpolation='nearest')\n",
    "    cbar = fig.colorbar(cax, ticks=[0.25, 1.0, 2.0, 3.0, 3.75], orientation='vertical')\n",
    "    cbar.ax.set_yticklabels(['None', 'Mild', 'Moderate', 'High', 'Extreme'],\n",
    "            rotation=90, va='center')\n",
    "\n",
    "    plt.scatter(y_true, y_pred_mean, s=25, facecolors='white', edgecolors='black')\n",
    "\n",
    "    save_path = os.path.join(cfg['train']['artifacts_path'], \"{}_seg_plot.pdf\".format(patient_id))\n",
    "    print(\"saving plot to: \", save_path)\n",
    "    plt.savefig(save_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-02 22:20:32,150 ERROR c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh does not exist.\n",
      "Running 1 experiments.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-02-02 22:20:32,157 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "{   'dataset': {   'diatrend_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold1_training',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'ohio_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                                '2020\\\\fold1_training',\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\mixed.py',\n",
      "                   't1dexi_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\fold1_training',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 22:22:01,772 WARNING Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-02-02 22:22:01,945 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "2025-02-02 22:22:01,947 WARNING From C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\distributions\\normal.py:149: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-02-02 22:22:01,965 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 770012 samples, validate on 192449 samples\n",
      "Epoch 1/10000\n",
      "769024/770012 [============================>.] - ETA: 0s - loss: 0.1397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770012/770012 [==============================] - 10s 12us/sample - loss: 0.1396 - val_loss: -0.0882\n",
      "Epoch 2/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.0179 - val_loss: -0.1184\n",
      "Epoch 3/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.0595 - val_loss: -0.1483\n",
      "Epoch 4/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.0865 - val_loss: -0.1521\n",
      "Epoch 5/10000\n",
      "770012/770012 [==============================] - ETA: 0s - loss: -0.10412025-02-02 22:22:47,808 DEBUG Creating converter from 5 to 3\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1041 - val_loss: -0.1539\n",
      "Epoch 6/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1173 - val_loss: -0.1668\n",
      "Epoch 7/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1273 - val_loss: -0.1702\n",
      "Epoch 8/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1369 - val_loss: -0.1546\n",
      "Epoch 9/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1441 - val_loss: -0.1778\n",
      "Epoch 10/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1503 - val_loss: -0.1787\n",
      "Epoch 11/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1530 - val_loss: -0.1828\n",
      "Epoch 12/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1566 - val_loss: -0.1865\n",
      "Epoch 13/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1595 - val_loss: -0.1814\n",
      "Epoch 14/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1611 - val_loss: -0.1831\n",
      "Epoch 15/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1632 - val_loss: -0.1855\n",
      "Epoch 16/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1637 - val_loss: -0.1848\n",
      "Epoch 17/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1660 - val_loss: -0.1767\n",
      "Epoch 18/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1666 - val_loss: -0.1872\n",
      "Epoch 19/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1670 - val_loss: -0.1852\n",
      "Epoch 20/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1677 - val_loss: -0.1864\n",
      "Epoch 21/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1697 - val_loss: -0.1919\n",
      "Epoch 22/10000\n",
      "770012/770012 [==============================] - 8s 11us/sample - loss: -0.1699 - val_loss: -0.1926\n",
      "Epoch 23/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1699 - val_loss: -0.1898\n",
      "Epoch 24/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1705 - val_loss: -0.1852\n",
      "Epoch 25/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1707 - val_loss: -0.1841\n",
      "Epoch 26/10000\n",
      "770012/770012 [==============================] - 8s 11us/sample - loss: -0.1722 - val_loss: -0.1942\n",
      "Epoch 27/10000\n",
      "770012/770012 [==============================] - 8s 11us/sample - loss: -0.1725 - val_loss: -0.1886\n",
      "Epoch 28/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1732 - val_loss: -0.1935\n",
      "Epoch 29/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1735 - val_loss: -0.1939\n",
      "Epoch 30/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1743 - val_loss: -0.1917\n",
      "Epoch 31/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1749 - val_loss: -0.1935\n",
      "Epoch 32/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1748 - val_loss: -0.1915\n",
      "Epoch 33/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1750 - val_loss: -0.1970\n",
      "Epoch 34/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1754 - val_loss: -0.1898\n",
      "Epoch 35/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1750 - val_loss: -0.1943\n",
      "Epoch 36/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1763 - val_loss: -0.1871\n",
      "Epoch 37/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1765 - val_loss: -0.1948\n",
      "Epoch 38/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1767 - val_loss: -0.1957\n",
      "Epoch 39/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1770 - val_loss: -0.1955\n",
      "Epoch 40/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1771 - val_loss: -0.1937\n",
      "Epoch 41/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1772 - val_loss: -0.1923\n",
      "Epoch 42/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1786 - val_loss: -0.1962\n",
      "Epoch 43/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1785 - val_loss: -0.1959\n",
      "Epoch 44/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1786 - val_loss: -0.1949\n",
      "Epoch 45/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1789 - val_loss: -0.1978\n",
      "Epoch 46/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1791 - val_loss: -0.1880\n",
      "Epoch 47/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1793 - val_loss: -0.1913\n",
      "Epoch 48/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1796 - val_loss: -0.1941\n",
      "Epoch 49/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1806 - val_loss: -0.1931\n",
      "Epoch 50/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1809 - val_loss: -0.1928\n",
      "Epoch 51/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1810 - val_loss: -0.1932\n",
      "Epoch 52/10000\n",
      "770012/770012 [==============================] - 11s 14us/sample - loss: -0.1810 - val_loss: -0.1960\n",
      "Epoch 53/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1815 - val_loss: -0.1993\n",
      "Epoch 54/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1820 - val_loss: -0.1956\n",
      "Epoch 55/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1815 - val_loss: -0.1945\n",
      "Epoch 56/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1820 - val_loss: -0.1912\n",
      "Epoch 57/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.1831 - val_loss: -0.1994\n",
      "Epoch 58/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1824 - val_loss: -0.1943\n",
      "Epoch 59/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1833 - val_loss: -0.1967\n",
      "Epoch 60/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1822 - val_loss: -0.1972\n",
      "Epoch 61/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1830 - val_loss: -0.1950\n",
      "Epoch 62/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1831 - val_loss: -0.1991\n",
      "Epoch 63/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1840 - val_loss: -0.1978\n",
      "Epoch 64/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1847 - val_loss: -0.1924\n",
      "Epoch 65/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1845 - val_loss: -0.1942\n",
      "Epoch 66/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1834 - val_loss: -0.1888\n",
      "Epoch 67/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1845 - val_loss: -0.1927\n",
      "Epoch 68/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1850 - val_loss: -0.1982\n",
      "Epoch 69/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1857 - val_loss: -0.1938\n",
      "Epoch 70/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1851 - val_loss: -0.1978\n",
      "Epoch 71/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1853 - val_loss: -0.1960\n",
      "Epoch 72/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1852 - val_loss: -0.1940\n",
      "Epoch 73/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.1858 - val_loss: -0.1967\n",
      "Epoch 74/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1861 - val_loss: -0.1973\n",
      "Epoch 75/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1865 - val_loss: -0.1959\n",
      "Epoch 76/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1871 - val_loss: -0.1955\n",
      "Epoch 77/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1867 - val_loss: -0.1951\n",
      "Epoch 78/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1875 - val_loss: -0.1940\n",
      "Epoch 79/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1874 - val_loss: -0.1864\n",
      "Epoch 80/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1873 - val_loss: -0.1798\n",
      "Epoch 81/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1881 - val_loss: -0.1985\n",
      "Epoch 82/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1870 - val_loss: -0.1926\n",
      "Epoch 83/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1889 - val_loss: -0.1906\n",
      "Epoch 84/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1880 - val_loss: -0.1967\n",
      "Epoch 85/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1890 - val_loss: -0.1959\n",
      "Epoch 86/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1884 - val_loss: -0.1945\n",
      "Epoch 87/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1882 - val_loss: -0.1939\n",
      "Epoch 88/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1896 - val_loss: -0.1954\n",
      "Epoch 89/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1899 - val_loss: -0.1934\n",
      "Epoch 90/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1898 - val_loss: -0.1941\n",
      "Epoch 91/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1894 - val_loss: -0.1884\n",
      "Epoch 92/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1903 - val_loss: -0.1963\n",
      "Epoch 93/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1902 - val_loss: -0.1942\n",
      "Epoch 94/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1908 - val_loss: -0.1967\n",
      "Epoch 95/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1919 - val_loss: -0.1970\n",
      "Epoch 96/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1912 - val_loss: -0.1882\n",
      "Epoch 97/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1917 - val_loss: -0.1913\n",
      "Epoch 98/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1914 - val_loss: -0.1981\n",
      "Epoch 99/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1920 - val_loss: -0.1949\n",
      "Epoch 100/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1925 - val_loss: -0.1939\n",
      "Epoch 101/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1925 - val_loss: -0.1974\n",
      "Epoch 102/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1922 - val_loss: -0.1967\n",
      "Epoch 103/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1934 - val_loss: -0.1973\n",
      "Epoch 104/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1934 - val_loss: -0.1939\n",
      "Epoch 105/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1936 - val_loss: -0.1903\n",
      "Epoch 106/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1939 - val_loss: -0.1977\n",
      "Epoch 107/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1944 - val_loss: -0.1952\n",
      "Epoch 108/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1947 - val_loss: -0.1922\n",
      "Epoch 109/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.1948 - val_loss: -0.1959\n",
      "Epoch 110/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1949 - val_loss: -0.1947\n",
      "Epoch 111/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1952 - val_loss: -0.1925\n",
      "Epoch 112/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1955 - val_loss: -0.1869\n",
      "Epoch 113/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1957 - val_loss: -0.1884\n",
      "Epoch 114/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.1956 - val_loss: -0.1896\n",
      "Epoch 115/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1962 - val_loss: -0.1918\n",
      "Epoch 116/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1963 - val_loss: -0.1905\n",
      "Epoch 117/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.1968 - val_loss: -0.1932\n",
      "Epoch 118/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1972 - val_loss: -0.1957\n",
      "Epoch 119/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1980 - val_loss: -0.1929\n",
      "Epoch 120/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1973 - val_loss: -0.1905\n",
      "Epoch 121/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1984 - val_loss: -0.1961\n",
      "Epoch 122/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1989 - val_loss: -0.1904\n",
      "Epoch 123/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1984 - val_loss: -0.1942\n",
      "Epoch 124/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.1993 - val_loss: -0.1836\n",
      "Epoch 125/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2001 - val_loss: -0.1938\n",
      "Epoch 126/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.1997 - val_loss: -0.1910\n",
      "Epoch 127/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.2002 - val_loss: -0.1870\n",
      "Epoch 128/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2003 - val_loss: -0.1895\n",
      "Epoch 129/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2002 - val_loss: -0.1903\n",
      "Epoch 130/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2012 - val_loss: -0.1837\n",
      "Epoch 131/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2010 - val_loss: -0.1789\n",
      "Epoch 132/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2013 - val_loss: -0.1935\n",
      "Epoch 133/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2025 - val_loss: -0.1894\n",
      "Epoch 134/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2021 - val_loss: -0.1862\n",
      "Epoch 135/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2031 - val_loss: -0.1866\n",
      "Epoch 136/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2025 - val_loss: -0.1900\n",
      "Epoch 137/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2036 - val_loss: -0.1874\n",
      "Epoch 138/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2042 - val_loss: -0.1886\n",
      "Epoch 139/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2042 - val_loss: -0.1811\n",
      "Epoch 140/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2044 - val_loss: -0.1899\n",
      "Epoch 141/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2048 - val_loss: -0.1876\n",
      "Epoch 142/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2055 - val_loss: -0.1863\n",
      "Epoch 143/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2055 - val_loss: -0.1872\n",
      "Epoch 144/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2061 - val_loss: -0.1829\n",
      "Epoch 145/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2063 - val_loss: -0.1853\n",
      "Epoch 146/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2067 - val_loss: -0.1835\n",
      "Epoch 147/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2067 - val_loss: -0.1832\n",
      "Epoch 148/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2079 - val_loss: -0.1817\n",
      "Epoch 149/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2082 - val_loss: -0.1876\n",
      "Epoch 150/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2082 - val_loss: -0.1861\n",
      "Epoch 151/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2085 - val_loss: -0.1831\n",
      "Epoch 152/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2090 - val_loss: -0.1847\n",
      "Epoch 153/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2100 - val_loss: -0.1847\n",
      "Epoch 154/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2108 - val_loss: -0.1849\n",
      "Epoch 155/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2114 - val_loss: -0.1777\n",
      "Epoch 156/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2110 - val_loss: -0.1801\n",
      "Epoch 157/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2108 - val_loss: -0.1846\n",
      "Epoch 158/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2117 - val_loss: -0.1826\n",
      "Epoch 159/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2121 - val_loss: -0.1837\n",
      "Epoch 160/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2128 - val_loss: -0.1783\n",
      "Epoch 161/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2123 - val_loss: -0.1732\n",
      "Epoch 162/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2130 - val_loss: -0.1812\n",
      "Epoch 163/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2139 - val_loss: -0.1762\n",
      "Epoch 164/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2142 - val_loss: -0.1783\n",
      "Epoch 165/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2139 - val_loss: -0.1768\n",
      "Epoch 166/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2152 - val_loss: -0.1797\n",
      "Epoch 167/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2163 - val_loss: -0.1808\n",
      "Epoch 168/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2155 - val_loss: -0.1773\n",
      "Epoch 169/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2168 - val_loss: -0.1783\n",
      "Epoch 170/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2175 - val_loss: -0.1781\n",
      "Epoch 171/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2174 - val_loss: -0.1785\n",
      "Epoch 172/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2176 - val_loss: -0.1754\n",
      "Epoch 173/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2185 - val_loss: -0.1734\n",
      "Epoch 174/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2190 - val_loss: -0.1749\n",
      "Epoch 175/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2197 - val_loss: -0.1749\n",
      "Epoch 176/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2197 - val_loss: -0.1751\n",
      "Epoch 177/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2197 - val_loss: -0.1690\n",
      "Epoch 178/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2205 - val_loss: -0.1765\n",
      "Epoch 179/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2199 - val_loss: -0.1742\n",
      "Epoch 180/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2216 - val_loss: -0.1748\n",
      "Epoch 181/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2216 - val_loss: -0.1756\n",
      "Epoch 182/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2217 - val_loss: -0.1706\n",
      "Epoch 183/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2223 - val_loss: -0.1655\n",
      "Epoch 184/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2231 - val_loss: -0.1718\n",
      "Epoch 185/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2234 - val_loss: -0.1718\n",
      "Epoch 186/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2236 - val_loss: -0.1697\n",
      "Epoch 187/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2240 - val_loss: -0.1673\n",
      "Epoch 188/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2248 - val_loss: -0.1688\n",
      "Epoch 189/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2257 - val_loss: -0.1704\n",
      "Epoch 190/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2261 - val_loss: -0.1687\n",
      "Epoch 191/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2269 - val_loss: -0.1685\n",
      "Epoch 192/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2265 - val_loss: -0.1672\n",
      "Epoch 193/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2274 - val_loss: -0.1655\n",
      "Epoch 194/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2278 - val_loss: -0.1590\n",
      "Epoch 195/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2282 - val_loss: -0.1639\n",
      "Epoch 196/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2282 - val_loss: -0.1617\n",
      "Epoch 197/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2286 - val_loss: -0.1640\n",
      "Epoch 198/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2298 - val_loss: -0.1622\n",
      "Epoch 199/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2301 - val_loss: -0.1592\n",
      "Epoch 200/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2306 - val_loss: -0.1592\n",
      "Epoch 201/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2314 - val_loss: -0.1577\n",
      "Epoch 202/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2320 - val_loss: -0.1631\n",
      "Epoch 203/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2320 - val_loss: -0.1591\n",
      "Epoch 204/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2322 - val_loss: -0.1529\n",
      "Epoch 205/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2335 - val_loss: -0.1626\n",
      "Epoch 206/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2332 - val_loss: -0.1589\n",
      "Epoch 207/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2336 - val_loss: -0.1581\n",
      "Epoch 208/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2350 - val_loss: -0.1529\n",
      "Epoch 209/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2342 - val_loss: -0.1491\n",
      "Epoch 210/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2352 - val_loss: -0.1506\n",
      "Epoch 211/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2360 - val_loss: -0.1487\n",
      "Epoch 212/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2360 - val_loss: -0.1547\n",
      "Epoch 213/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2362 - val_loss: -0.1525\n",
      "Epoch 214/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2380 - val_loss: -0.1571\n",
      "Epoch 215/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2382 - val_loss: -0.1511\n",
      "Epoch 216/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2386 - val_loss: -0.1507\n",
      "Epoch 217/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2381 - val_loss: -0.1474\n",
      "Epoch 218/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2392 - val_loss: -0.1440\n",
      "Epoch 219/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2392 - val_loss: -0.1495\n",
      "Epoch 220/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2402 - val_loss: -0.1457\n",
      "Epoch 221/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2393 - val_loss: -0.1460\n",
      "Epoch 222/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2410 - val_loss: -0.1381\n",
      "Epoch 223/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2419 - val_loss: -0.1482\n",
      "Epoch 224/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2417 - val_loss: -0.1522\n",
      "Epoch 225/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2426 - val_loss: -0.1502\n",
      "Epoch 226/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2418 - val_loss: -0.1496\n",
      "Epoch 227/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2428 - val_loss: -0.1483\n",
      "Epoch 228/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2436 - val_loss: -0.1423\n",
      "Epoch 229/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2438 - val_loss: -0.1470\n",
      "Epoch 230/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.2453 - val_loss: -0.1459\n",
      "Epoch 231/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2449 - val_loss: -0.1492\n",
      "Epoch 232/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2454 - val_loss: -0.1359\n",
      "Epoch 233/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2450 - val_loss: -0.1476\n",
      "Epoch 234/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2462 - val_loss: -0.1420\n",
      "Epoch 235/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2473 - val_loss: -0.1414\n",
      "Epoch 236/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2474 - val_loss: -0.1428\n",
      "Epoch 237/10000\n",
      "770012/770012 [==============================] - 10s 12us/sample - loss: -0.2467 - val_loss: -0.1389\n",
      "Epoch 238/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2487 - val_loss: -0.1324\n",
      "Epoch 239/10000\n",
      "770012/770012 [==============================] - 10s 13us/sample - loss: -0.2495 - val_loss: -0.1353\n",
      "Epoch 240/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2496 - val_loss: -0.1364\n",
      "Epoch 241/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2497 - val_loss: -0.1385\n",
      "Epoch 242/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2502 - val_loss: -0.1380\n",
      "Epoch 243/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2503 - val_loss: -0.1367\n",
      "Epoch 244/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2513 - val_loss: -0.1376\n",
      "Epoch 245/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2521 - val_loss: -0.1345\n",
      "Epoch 246/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2523 - val_loss: -0.1374\n",
      "Epoch 247/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2521 - val_loss: -0.1394\n",
      "Epoch 248/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2520 - val_loss: -0.1390\n",
      "Epoch 249/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2525 - val_loss: -0.1319\n",
      "Epoch 250/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2538 - val_loss: -0.1266\n",
      "Epoch 251/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2543 - val_loss: -0.1319\n",
      "Epoch 252/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2541 - val_loss: -0.1346\n",
      "Epoch 253/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2553 - val_loss: -0.1358\n",
      "Epoch 254/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2553 - val_loss: -0.1223\n",
      "Epoch 255/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2550 - val_loss: -0.1341\n",
      "Epoch 256/10000\n",
      "770012/770012 [==============================] - 9s 12us/sample - loss: -0.2560 - val_loss: -0.1221\n",
      "Epoch 257/10000\n",
      "770012/770012 [==============================] - 9s 11us/sample - loss: -0.2567 - val_loss: -0.1249\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\103.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5080, 12, 1)\n",
      "y_test.shape:  (5080, 1)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:25,592 WARNING Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 103\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "2025-02-02 23:01:25,695 DEBUG Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  103\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\114.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7640, 12, 1)\n",
      "y_test.shape:  (7640, 1)\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:27,627 WARNING Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 114\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  114\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\115.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7895, 12, 1)\n",
      "y_test.shape:  (7895, 1)\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:30,146 WARNING Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 115\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  115\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\11.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7952, 12, 1)\n",
      "y_test.shape:  (7952, 1)\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:32,658 WARNING Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 11\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  11\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\144.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7432, 12, 1)\n",
      "y_test.shape:  (7432, 1)\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:35,167 WARNING Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 144\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  144\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\152.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7821, 12, 1)\n",
      "y_test.shape:  (7821, 1)\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:38,068 WARNING Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 152\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  152\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\173.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7746, 12, 1)\n",
      "y_test.shape:  (7746, 1)\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:40,893 WARNING Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 173\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  173\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\187.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7829, 12, 1)\n",
      "y_test.shape:  (7829, 1)\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:43,510 WARNING Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 187\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  187\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\18.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7920, 12, 1)\n",
      "y_test.shape:  (7920, 1)\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:46,160 WARNING Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 18\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  18\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7753, 12, 1)\n",
      "y_test.shape:  (7753, 1)\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:48,883 WARNING Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\248.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (4908, 12, 1)\n",
      "y_test.shape:  (4908, 1)\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:51,424 WARNING Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 248\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  248\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\24.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7606, 12, 1)\n",
      "y_test.shape:  (7606, 1)\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:53,544 WARNING Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 24\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  24\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\25.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7330, 12, 1)\n",
      "y_test.shape:  (7330, 1)\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:56,052 WARNING Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 25\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  25\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\540-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (14126, 12, 1)\n",
      "y_test.shape:  (14126, 1)\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:01:58,721 WARNING Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 540\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  540\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\544-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (12843, 12, 1)\n",
      "y_test.shape:  (12843, 1)\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:02,419 WARNING Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 544\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  544\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject10.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11769, 12, 1)\n",
      "y_test.shape:  (11769, 1)\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:06,344 WARNING Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject10\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject10\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject11.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11515, 12, 1)\n",
      "y_test.shape:  (11515, 1)\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:10,397 WARNING Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject11\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject11\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject1.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7779, 12, 1)\n",
      "y_test.shape:  (7779, 1)\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:13,843 WARNING Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject1\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject1\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject2.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (6325, 12, 1)\n",
      "y_test.shape:  (6325, 1)\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:16,769 WARNING Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject2\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject2\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject3.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7071, 12, 1)\n",
      "y_test.shape:  (7071, 1)\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:19,582 WARNING Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject3\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject3\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject4.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11347, 12, 1)\n",
      "y_test.shape:  (11347, 1)\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:22,709 WARNING Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject4\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject4\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject5.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10489, 12, 1)\n",
      "y_test.shape:  (10489, 1)\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:26,741 WARNING Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject5\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject5\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject6.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11416, 12, 1)\n",
      "y_test.shape:  (11416, 1)\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:30,598 WARNING Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject6\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject6\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject7.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11317, 12, 1)\n",
      "y_test.shape:  (11317, 1)\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:34,574 WARNING Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject7\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject7\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject8.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11216, 12, 1)\n",
      "y_test.shape:  (11216, 1)\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:38,625 WARNING Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject8\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject8\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject9.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11685, 12, 1)\n",
      "y_test.shape:  (11685, 1)\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:02:42,891 WARNING Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject9\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject9\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'diatrend_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold2_training',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'ohio_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                                '2020\\\\fold2_training',\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\mixed.py',\n",
      "                   't1dexi_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\fold2_training',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:04:16,287 WARNING Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-02-02 23:04:16,402 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 761202 samples, validate on 190250 samples\n",
      "Epoch 1/10000\n",
      "759808/761202 [============================>.] - ETA: 0s - loss: 0.1296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761202/761202 [==============================] - 10s 12us/sample - loss: 0.1293 - val_loss: -0.0565\n",
      "Epoch 2/10000\n",
      "761202/761202 [==============================] - 8s 11us/sample - loss: -0.0202 - val_loss: -0.1114\n",
      "Epoch 3/10000\n",
      "761202/761202 [==============================] - 8s 11us/sample - loss: -0.0618 - val_loss: -0.1233\n",
      "Epoch 4/10000\n",
      "761202/761202 [==============================] - 8s 11us/sample - loss: -0.0858 - val_loss: -0.1503\n",
      "Epoch 5/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1029 - val_loss: -0.1603\n",
      "Epoch 6/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1178 - val_loss: -0.1588\n",
      "Epoch 7/10000\n",
      "761202/761202 [==============================] - 8s 11us/sample - loss: -0.1288 - val_loss: -0.1639\n",
      "Epoch 8/10000\n",
      "761202/761202 [==============================] - 8s 11us/sample - loss: -0.1368 - val_loss: -0.1555\n",
      "Epoch 9/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1434 - val_loss: -0.1687\n",
      "Epoch 10/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1481 - val_loss: -0.1627\n",
      "Epoch 11/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1531 - val_loss: -0.1758\n",
      "Epoch 12/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1553 - val_loss: -0.1718\n",
      "Epoch 13/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1591 - val_loss: -0.1763\n",
      "Epoch 14/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1608 - val_loss: -0.1781\n",
      "Epoch 15/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1634 - val_loss: -0.1829\n",
      "Epoch 16/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1646 - val_loss: -0.1795\n",
      "Epoch 17/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1644 - val_loss: -0.1722\n",
      "Epoch 18/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1665 - val_loss: -0.1844\n",
      "Epoch 19/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1671 - val_loss: -0.1684\n",
      "Epoch 20/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1674 - val_loss: -0.1783\n",
      "Epoch 21/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1684 - val_loss: -0.1812\n",
      "Epoch 22/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1698 - val_loss: -0.1834\n",
      "Epoch 23/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1690 - val_loss: -0.1776\n",
      "Epoch 24/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1696 - val_loss: -0.1824\n",
      "Epoch 25/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1711 - val_loss: -0.1837\n",
      "Epoch 26/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1721 - val_loss: -0.1827\n",
      "Epoch 27/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1717 - val_loss: -0.1789\n",
      "Epoch 28/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1717 - val_loss: -0.1865\n",
      "Epoch 29/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1726 - val_loss: -0.1752\n",
      "Epoch 30/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1736 - val_loss: -0.1704\n",
      "Epoch 31/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1733 - val_loss: -0.1829\n",
      "Epoch 32/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1749 - val_loss: -0.1848\n",
      "Epoch 33/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1740 - val_loss: -0.1779\n",
      "Epoch 34/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1751 - val_loss: -0.1790\n",
      "Epoch 35/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1756 - val_loss: -0.1820\n",
      "Epoch 36/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1757 - val_loss: -0.1762\n",
      "Epoch 37/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1761 - val_loss: -0.1839\n",
      "Epoch 38/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1765 - val_loss: -0.1857\n",
      "Epoch 39/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1771 - val_loss: -0.1818\n",
      "Epoch 40/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1776 - val_loss: -0.1855\n",
      "Epoch 41/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1777 - val_loss: -0.1854\n",
      "Epoch 42/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1781 - val_loss: -0.1810\n",
      "Epoch 43/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1773 - val_loss: -0.1846\n",
      "Epoch 44/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1782 - val_loss: -0.1812\n",
      "Epoch 45/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1779 - val_loss: -0.1824\n",
      "Epoch 46/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1787 - val_loss: -0.1845\n",
      "Epoch 47/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1792 - val_loss: -0.1805\n",
      "Epoch 48/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1793 - val_loss: -0.1873\n",
      "Epoch 49/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1791 - val_loss: -0.1839\n",
      "Epoch 50/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1795 - val_loss: -0.1843\n",
      "Epoch 51/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1802 - val_loss: -0.1829\n",
      "Epoch 52/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1804 - val_loss: -0.1763\n",
      "Epoch 53/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1811 - val_loss: -0.1809\n",
      "Epoch 54/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1808 - val_loss: -0.1748\n",
      "Epoch 55/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1804 - val_loss: -0.1853\n",
      "Epoch 56/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1815 - val_loss: -0.1903\n",
      "Epoch 57/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1811 - val_loss: -0.1862\n",
      "Epoch 58/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1820 - val_loss: -0.1848\n",
      "Epoch 59/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1822 - val_loss: -0.1830\n",
      "Epoch 60/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1812 - val_loss: -0.1875\n",
      "Epoch 61/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1822 - val_loss: -0.1883\n",
      "Epoch 62/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1821 - val_loss: -0.1850\n",
      "Epoch 63/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1816 - val_loss: -0.1894\n",
      "Epoch 64/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1830 - val_loss: -0.1830\n",
      "Epoch 65/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1837 - val_loss: -0.1876\n",
      "Epoch 66/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1824 - val_loss: -0.1889\n",
      "Epoch 67/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1834 - val_loss: -0.1901\n",
      "Epoch 68/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1832 - val_loss: -0.1898\n",
      "Epoch 69/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1839 - val_loss: -0.1886\n",
      "Epoch 70/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1832 - val_loss: -0.1844\n",
      "Epoch 71/10000\n",
      "761202/761202 [==============================] - 10s 12us/sample - loss: -0.1842 - val_loss: -0.1842\n",
      "Epoch 72/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1851 - val_loss: -0.1899\n",
      "Epoch 73/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1848 - val_loss: -0.1855\n",
      "Epoch 74/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1843 - val_loss: -0.1866\n",
      "Epoch 75/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1855 - val_loss: -0.1881\n",
      "Epoch 76/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1853 - val_loss: -0.1873\n",
      "Epoch 77/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1851 - val_loss: -0.1826\n",
      "Epoch 78/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1860 - val_loss: -0.1888\n",
      "Epoch 79/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1856 - val_loss: -0.1858\n",
      "Epoch 80/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1858 - val_loss: -0.1894\n",
      "Epoch 81/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1867 - val_loss: -0.1865\n",
      "Epoch 82/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1866 - val_loss: -0.1863\n",
      "Epoch 83/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1864 - val_loss: -0.1857\n",
      "Epoch 84/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1865 - val_loss: -0.1824\n",
      "Epoch 85/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1866 - val_loss: -0.1863\n",
      "Epoch 86/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1879 - val_loss: -0.1880\n",
      "Epoch 87/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1879 - val_loss: -0.1874\n",
      "Epoch 88/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1874 - val_loss: -0.1862\n",
      "Epoch 89/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1885 - val_loss: -0.1894\n",
      "Epoch 90/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1884 - val_loss: -0.1842\n",
      "Epoch 91/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1890 - val_loss: -0.1882\n",
      "Epoch 92/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1889 - val_loss: -0.1882\n",
      "Epoch 93/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1882 - val_loss: -0.1812\n",
      "Epoch 94/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1888 - val_loss: -0.1847\n",
      "Epoch 95/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1890 - val_loss: -0.1827\n",
      "Epoch 96/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1899 - val_loss: -0.1822\n",
      "Epoch 97/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1896 - val_loss: -0.1850\n",
      "Epoch 98/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1897 - val_loss: -0.1864\n",
      "Epoch 99/10000\n",
      "761202/761202 [==============================] - 10s 14us/sample - loss: -0.1904 - val_loss: -0.1823\n",
      "Epoch 100/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1907 - val_loss: -0.1869\n",
      "Epoch 101/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1906 - val_loss: -0.1839\n",
      "Epoch 102/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1909 - val_loss: -0.1865\n",
      "Epoch 103/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1911 - val_loss: -0.1814\n",
      "Epoch 104/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1919 - val_loss: -0.1874\n",
      "Epoch 105/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1920 - val_loss: -0.1864\n",
      "Epoch 106/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1922 - val_loss: -0.1854\n",
      "Epoch 107/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1924 - val_loss: -0.1877\n",
      "Epoch 108/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1935 - val_loss: -0.1879\n",
      "Epoch 109/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1929 - val_loss: -0.1820\n",
      "Epoch 110/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1922 - val_loss: -0.1845\n",
      "Epoch 111/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1941 - val_loss: -0.1842\n",
      "Epoch 112/10000\n",
      "761202/761202 [==============================] - 9s 11us/sample - loss: -0.1938 - val_loss: -0.1841\n",
      "Epoch 113/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1939 - val_loss: -0.1852\n",
      "Epoch 114/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1946 - val_loss: -0.1845\n",
      "Epoch 115/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1944 - val_loss: -0.1822\n",
      "Epoch 116/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1954 - val_loss: -0.1841\n",
      "Epoch 117/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1956 - val_loss: -0.1828\n",
      "Epoch 118/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1953 - val_loss: -0.1830\n",
      "Epoch 119/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1956 - val_loss: -0.1841\n",
      "Epoch 120/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.1958 - val_loss: -0.1785\n",
      "Epoch 121/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1952 - val_loss: -0.1788\n",
      "Epoch 122/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1967 - val_loss: -0.1839\n",
      "Epoch 123/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1975 - val_loss: -0.1803\n",
      "Epoch 124/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1980 - val_loss: -0.1801\n",
      "Epoch 125/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1977 - val_loss: -0.1776\n",
      "Epoch 126/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1981 - val_loss: -0.1831\n",
      "Epoch 127/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1988 - val_loss: -0.1750\n",
      "Epoch 128/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1978 - val_loss: -0.1837\n",
      "Epoch 129/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1992 - val_loss: -0.1797\n",
      "Epoch 130/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2002 - val_loss: -0.1802\n",
      "Epoch 131/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2006 - val_loss: -0.1838\n",
      "Epoch 132/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2002 - val_loss: -0.1826\n",
      "Epoch 133/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.1996 - val_loss: -0.1801\n",
      "Epoch 134/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2006 - val_loss: -0.1826\n",
      "Epoch 135/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2013 - val_loss: -0.1789\n",
      "Epoch 136/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2011 - val_loss: -0.1784\n",
      "Epoch 137/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2014 - val_loss: -0.1805\n",
      "Epoch 138/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2018 - val_loss: -0.1757\n",
      "Epoch 139/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2029 - val_loss: -0.1757\n",
      "Epoch 140/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2032 - val_loss: -0.1791\n",
      "Epoch 141/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2031 - val_loss: -0.1767\n",
      "Epoch 142/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2043 - val_loss: -0.1721\n",
      "Epoch 143/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2040 - val_loss: -0.1795\n",
      "Epoch 144/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2039 - val_loss: -0.1771\n",
      "Epoch 145/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2048 - val_loss: -0.1758\n",
      "Epoch 146/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2052 - val_loss: -0.1788\n",
      "Epoch 147/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2055 - val_loss: -0.1763\n",
      "Epoch 148/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2059 - val_loss: -0.1751\n",
      "Epoch 149/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2071 - val_loss: -0.1737\n",
      "Epoch 150/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2075 - val_loss: -0.1763\n",
      "Epoch 151/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2069 - val_loss: -0.1694\n",
      "Epoch 152/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2070 - val_loss: -0.1726\n",
      "Epoch 153/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2079 - val_loss: -0.1762\n",
      "Epoch 154/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2083 - val_loss: -0.1715\n",
      "Epoch 155/10000\n",
      "761202/761202 [==============================] - 11s 14us/sample - loss: -0.2093 - val_loss: -0.1715\n",
      "Epoch 156/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2095 - val_loss: -0.1696\n",
      "Epoch 157/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2088 - val_loss: -0.1660\n",
      "Epoch 158/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2097 - val_loss: -0.1760\n",
      "Epoch 159/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2098 - val_loss: -0.1676\n",
      "Epoch 160/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2104 - val_loss: -0.1685\n",
      "Epoch 161/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2112 - val_loss: -0.1697\n",
      "Epoch 162/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2113 - val_loss: -0.1666\n",
      "Epoch 163/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2115 - val_loss: -0.1664\n",
      "Epoch 164/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2130 - val_loss: -0.1696\n",
      "Epoch 165/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2129 - val_loss: -0.1681\n",
      "Epoch 166/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2131 - val_loss: -0.1700\n",
      "Epoch 167/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2133 - val_loss: -0.1635\n",
      "Epoch 168/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2150 - val_loss: -0.1689\n",
      "Epoch 169/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2146 - val_loss: -0.1653\n",
      "Epoch 170/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2153 - val_loss: -0.1595\n",
      "Epoch 171/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2158 - val_loss: -0.1637\n",
      "Epoch 172/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2162 - val_loss: -0.1619\n",
      "Epoch 173/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2171 - val_loss: -0.1639\n",
      "Epoch 174/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2172 - val_loss: -0.1624\n",
      "Epoch 175/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2173 - val_loss: -0.1656\n",
      "Epoch 176/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2178 - val_loss: -0.1655\n",
      "Epoch 177/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2181 - val_loss: -0.1626\n",
      "Epoch 178/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2184 - val_loss: -0.1663\n",
      "Epoch 179/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2189 - val_loss: -0.1623\n",
      "Epoch 180/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2184 - val_loss: -0.1613\n",
      "Epoch 181/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2206 - val_loss: -0.1591\n",
      "Epoch 182/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2206 - val_loss: -0.1548\n",
      "Epoch 183/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2197 - val_loss: -0.1611\n",
      "Epoch 184/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2217 - val_loss: -0.1599\n",
      "Epoch 185/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2221 - val_loss: -0.1602\n",
      "Epoch 186/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2223 - val_loss: -0.1542\n",
      "Epoch 187/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2229 - val_loss: -0.1600\n",
      "Epoch 188/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2235 - val_loss: -0.1567\n",
      "Epoch 189/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2237 - val_loss: -0.1600\n",
      "Epoch 190/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2240 - val_loss: -0.1555\n",
      "Epoch 191/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2254 - val_loss: -0.1596\n",
      "Epoch 192/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2250 - val_loss: -0.1616\n",
      "Epoch 193/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2257 - val_loss: -0.1571\n",
      "Epoch 194/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2264 - val_loss: -0.1520\n",
      "Epoch 195/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2257 - val_loss: -0.1554\n",
      "Epoch 196/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2275 - val_loss: -0.1489\n",
      "Epoch 197/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2278 - val_loss: -0.1509\n",
      "Epoch 198/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2282 - val_loss: -0.1526\n",
      "Epoch 199/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2289 - val_loss: -0.1480\n",
      "Epoch 200/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2287 - val_loss: -0.1488\n",
      "Epoch 201/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2297 - val_loss: -0.1527\n",
      "Epoch 202/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2299 - val_loss: -0.1499\n",
      "Epoch 203/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2307 - val_loss: -0.1503\n",
      "Epoch 204/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2310 - val_loss: -0.1461\n",
      "Epoch 205/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2319 - val_loss: -0.1510\n",
      "Epoch 206/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2319 - val_loss: -0.1481\n",
      "Epoch 207/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2330 - val_loss: -0.1456\n",
      "Epoch 208/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2325 - val_loss: -0.1492\n",
      "Epoch 209/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2329 - val_loss: -0.1437\n",
      "Epoch 210/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2335 - val_loss: -0.1466\n",
      "Epoch 211/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2345 - val_loss: -0.1482\n",
      "Epoch 212/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2339 - val_loss: -0.1493\n",
      "Epoch 213/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2355 - val_loss: -0.1454\n",
      "Epoch 214/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2355 - val_loss: -0.1402\n",
      "Epoch 215/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2362 - val_loss: -0.1490\n",
      "Epoch 216/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2369 - val_loss: -0.1429\n",
      "Epoch 217/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2375 - val_loss: -0.1406\n",
      "Epoch 218/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2385 - val_loss: -0.1423\n",
      "Epoch 219/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2384 - val_loss: -0.1439\n",
      "Epoch 220/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2390 - val_loss: -0.1406\n",
      "Epoch 221/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2391 - val_loss: -0.1413\n",
      "Epoch 222/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2396 - val_loss: -0.1416\n",
      "Epoch 223/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2406 - val_loss: -0.1429\n",
      "Epoch 224/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2409 - val_loss: -0.1353\n",
      "Epoch 225/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2405 - val_loss: -0.1388\n",
      "Epoch 226/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2422 - val_loss: -0.1399\n",
      "Epoch 227/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2427 - val_loss: -0.1340\n",
      "Epoch 228/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2422 - val_loss: -0.1399\n",
      "Epoch 229/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2434 - val_loss: -0.1373\n",
      "Epoch 230/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2438 - val_loss: -0.1380\n",
      "Epoch 231/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2441 - val_loss: -0.1359\n",
      "Epoch 232/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2449 - val_loss: -0.1340\n",
      "Epoch 233/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2447 - val_loss: -0.1434\n",
      "Epoch 234/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2445 - val_loss: -0.1284\n",
      "Epoch 235/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2458 - val_loss: -0.1320\n",
      "Epoch 236/10000\n",
      "761202/761202 [==============================] - 10s 12us/sample - loss: -0.2463 - val_loss: -0.1324\n",
      "Epoch 237/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2469 - val_loss: -0.1309\n",
      "Epoch 238/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2470 - val_loss: -0.1291\n",
      "Epoch 239/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2467 - val_loss: -0.1304\n",
      "Epoch 240/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2474 - val_loss: -0.1282\n",
      "Epoch 241/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2490 - val_loss: -0.1267\n",
      "Epoch 242/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2496 - val_loss: -0.1224\n",
      "Epoch 243/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2497 - val_loss: -0.1296\n",
      "Epoch 244/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2490 - val_loss: -0.1330\n",
      "Epoch 245/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2506 - val_loss: -0.1332\n",
      "Epoch 246/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2506 - val_loss: -0.1262\n",
      "Epoch 247/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2512 - val_loss: -0.1283\n",
      "Epoch 248/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2523 - val_loss: -0.1220\n",
      "Epoch 249/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2523 - val_loss: -0.1271\n",
      "Epoch 250/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2533 - val_loss: -0.1250\n",
      "Epoch 251/10000\n",
      "761202/761202 [==============================] - 10s 13us/sample - loss: -0.2525 - val_loss: -0.1239\n",
      "Epoch 252/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2546 - val_loss: -0.1214\n",
      "Epoch 253/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2551 - val_loss: -0.1220\n",
      "Epoch 254/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2544 - val_loss: -0.1207\n",
      "Epoch 255/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2549 - val_loss: -0.1162\n",
      "Epoch 256/10000\n",
      "761202/761202 [==============================] - 9s 12us/sample - loss: -0.2551 - val_loss: -0.1187\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1010.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7486, 12, 1)\n",
      "y_test.shape:  (7486, 1)\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:21,337 WARNING Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1010\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1010\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1015.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5708, 12, 1)\n",
      "y_test.shape:  (5708, 1)\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:24,439 WARNING Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1015\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1015\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1043.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7754, 12, 1)\n",
      "y_test.shape:  (7754, 1)\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:27,292 WARNING Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1043\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1043\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1082.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7854, 12, 1)\n",
      "y_test.shape:  (7854, 1)\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:30,851 WARNING Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1082\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1082\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1115.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7773, 12, 1)\n",
      "y_test.shape:  (7773, 1)\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:34,131 WARNING Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1115\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1115\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1121.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7850, 12, 1)\n",
      "y_test.shape:  (7850, 1)\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:37,482 WARNING Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1121\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1121\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1127.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7061, 12, 1)\n",
      "y_test.shape:  (7061, 1)\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:40,911 WARNING Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1127\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1127\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1139.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5249, 12, 1)\n",
      "y_test.shape:  (5249, 1)\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:43,923 WARNING Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1139\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1139\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1143.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7597, 12, 1)\n",
      "y_test.shape:  (7597, 1)\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:46,741 WARNING Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1143\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1143\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1171.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7750, 12, 1)\n",
      "y_test.shape:  (7750, 1)\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:50,011 WARNING Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1171\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1171\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1194.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7941, 12, 1)\n",
      "y_test.shape:  (7941, 1)\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:53,497 WARNING Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1194\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1194\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1201.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7863, 12, 1)\n",
      "y_test.shape:  (7863, 1)\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:43:56,890 WARNING Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1201\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1201\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\252.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7381, 12, 1)\n",
      "y_test.shape:  (7381, 1)\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:00,220 WARNING Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 252\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  252\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\552-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10475, 12, 1)\n",
      "y_test.shape:  (10475, 1)\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:03,438 WARNING Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 552\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  552\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\559-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (12375, 12, 1)\n",
      "y_test.shape:  (12375, 1)\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:07,382 WARNING Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 559\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  559\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject12.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11720, 12, 1)\n",
      "y_test.shape:  (11720, 1)\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:11,879 WARNING Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject12\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject12\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject13.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10456, 12, 1)\n",
      "y_test.shape:  (10456, 1)\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:16,390 WARNING Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject13\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject13\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject14.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11323, 12, 1)\n",
      "y_test.shape:  (11323, 1)\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:20,853 WARNING Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject14\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject14\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject15.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11815, 12, 1)\n",
      "y_test.shape:  (11815, 1)\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:25,341 WARNING Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject15\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject15\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject16.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11652, 12, 1)\n",
      "y_test.shape:  (11652, 1)\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:30,018 WARNING Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject16\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject16\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject17.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11893, 12, 1)\n",
      "y_test.shape:  (11893, 1)\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:34,841 WARNING Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject17\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject17\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject18.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11717, 12, 1)\n",
      "y_test.shape:  (11717, 1)\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:39,435 WARNING Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject18\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject18\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject19.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11711, 12, 1)\n",
      "y_test.shape:  (11711, 1)\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:44,080 WARNING Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject19\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject19\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject20.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11317, 12, 1)\n",
      "y_test.shape:  (11317, 1)\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:48,684 WARNING Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject20\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject20\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject21.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11299, 12, 1)\n",
      "y_test.shape:  (11299, 1)\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:53,325 WARNING Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject21\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject21\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject22.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11819, 12, 1)\n",
      "y_test.shape:  (11819, 1)\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:44:57,958 WARNING Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject22\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject22\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'diatrend_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold3_training',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'ohio_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                                '2020\\\\fold3_training',\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\mixed.py',\n",
      "                   't1dexi_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\fold3_training',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-02 23:46:30,786 WARNING Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-02-02 23:46:30,896 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 760201 samples, validate on 190004 samples\n",
      "Epoch 1/10000\n",
      "755712/760201 [============================>.] - ETA: 0s - loss: 0.1570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760201/760201 [==============================] - 11s 14us/sample - loss: 0.1564 - val_loss: -0.0575\n",
      "Epoch 2/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.0145 - val_loss: -0.1165\n",
      "Epoch 3/10000\n",
      "760201/760201 [==============================] - 9s 11us/sample - loss: -0.0575 - val_loss: -0.1493\n",
      "Epoch 4/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.0836 - val_loss: -0.1522\n",
      "Epoch 5/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1026 - val_loss: -0.1546\n",
      "Epoch 6/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1162 - val_loss: -0.1685\n",
      "Epoch 7/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1275 - val_loss: -0.1798\n",
      "Epoch 8/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1366 - val_loss: -0.1801\n",
      "Epoch 9/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1440 - val_loss: -0.1748\n",
      "Epoch 10/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1482 - val_loss: -0.1832\n",
      "Epoch 11/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1524 - val_loss: -0.1871\n",
      "Epoch 12/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1550 - val_loss: -0.1753\n",
      "Epoch 13/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1590 - val_loss: -0.1904\n",
      "Epoch 14/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1596 - val_loss: -0.1793\n",
      "Epoch 15/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1606 - val_loss: -0.1879\n",
      "Epoch 16/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1636 - val_loss: -0.1928\n",
      "Epoch 17/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1645 - val_loss: -0.1881\n",
      "Epoch 18/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1656 - val_loss: -0.1906\n",
      "Epoch 19/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1665 - val_loss: -0.1969\n",
      "Epoch 20/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1666 - val_loss: -0.1900\n",
      "Epoch 21/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1676 - val_loss: -0.1938\n",
      "Epoch 22/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1683 - val_loss: -0.1930\n",
      "Epoch 23/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1685 - val_loss: -0.1942\n",
      "Epoch 24/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1692 - val_loss: -0.1922\n",
      "Epoch 25/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1703 - val_loss: -0.1965\n",
      "Epoch 26/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1702 - val_loss: -0.1946\n",
      "Epoch 27/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1709 - val_loss: -0.1993\n",
      "Epoch 28/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1716 - val_loss: -0.1979\n",
      "Epoch 29/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1721 - val_loss: -0.1913\n",
      "Epoch 30/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1722 - val_loss: -0.1995\n",
      "Epoch 31/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1714 - val_loss: -0.1915\n",
      "Epoch 32/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1723 - val_loss: -0.1971\n",
      "Epoch 33/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1732 - val_loss: -0.1977\n",
      "Epoch 34/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1734 - val_loss: -0.1883\n",
      "Epoch 35/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1745 - val_loss: -0.1976\n",
      "Epoch 36/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1741 - val_loss: -0.1914\n",
      "Epoch 37/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1749 - val_loss: -0.1964\n",
      "Epoch 38/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1749 - val_loss: -0.1983\n",
      "Epoch 39/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1750 - val_loss: -0.1978\n",
      "Epoch 40/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1763 - val_loss: -0.1924\n",
      "Epoch 41/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1764 - val_loss: -0.1947\n",
      "Epoch 42/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1757 - val_loss: -0.1852\n",
      "Epoch 43/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1765 - val_loss: -0.1970\n",
      "Epoch 44/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1768 - val_loss: -0.1930\n",
      "Epoch 45/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1758 - val_loss: -0.2008\n",
      "Epoch 46/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1772 - val_loss: -0.1998\n",
      "Epoch 47/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1779 - val_loss: -0.1821\n",
      "Epoch 48/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1781 - val_loss: -0.2016\n",
      "Epoch 49/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1779 - val_loss: -0.1872\n",
      "Epoch 50/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1788 - val_loss: -0.1999\n",
      "Epoch 51/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1780 - val_loss: -0.1935\n",
      "Epoch 52/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1788 - val_loss: -0.1971\n",
      "Epoch 53/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1795 - val_loss: -0.1986\n",
      "Epoch 54/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1787 - val_loss: -0.1966\n",
      "Epoch 55/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1799 - val_loss: -0.1932\n",
      "Epoch 56/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1800 - val_loss: -0.1997\n",
      "Epoch 57/10000\n",
      "760201/760201 [==============================] - 10s 14us/sample - loss: -0.1802 - val_loss: -0.1901\n",
      "Epoch 58/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1804 - val_loss: -0.1939\n",
      "Epoch 59/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1812 - val_loss: -0.1995\n",
      "Epoch 60/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1812 - val_loss: -0.1969\n",
      "Epoch 61/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1809 - val_loss: -0.1981\n",
      "Epoch 62/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1812 - val_loss: -0.2035\n",
      "Epoch 63/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1822 - val_loss: -0.2018\n",
      "Epoch 64/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1822 - val_loss: -0.2009\n",
      "Epoch 65/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1820 - val_loss: -0.1941\n",
      "Epoch 66/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1823 - val_loss: -0.1997\n",
      "Epoch 67/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1827 - val_loss: -0.1945\n",
      "Epoch 68/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1825 - val_loss: -0.1932\n",
      "Epoch 69/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1830 - val_loss: -0.1966\n",
      "Epoch 70/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1832 - val_loss: -0.1990\n",
      "Epoch 71/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1834 - val_loss: -0.2011\n",
      "Epoch 72/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1839 - val_loss: -0.1801\n",
      "Epoch 73/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1837 - val_loss: -0.2015\n",
      "Epoch 74/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1838 - val_loss: -0.2013\n",
      "Epoch 75/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1844 - val_loss: -0.2021\n",
      "Epoch 76/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1851 - val_loss: -0.2008\n",
      "Epoch 77/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1846 - val_loss: -0.2003\n",
      "Epoch 78/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1848 - val_loss: -0.2012\n",
      "Epoch 79/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1852 - val_loss: -0.1884\n",
      "Epoch 80/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1855 - val_loss: -0.1995\n",
      "Epoch 81/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1855 - val_loss: -0.1980\n",
      "Epoch 82/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1859 - val_loss: -0.1981\n",
      "Epoch 83/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1860 - val_loss: -0.2041\n",
      "Epoch 84/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1868 - val_loss: -0.2033\n",
      "Epoch 85/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1858 - val_loss: -0.1994\n",
      "Epoch 86/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1867 - val_loss: -0.2009\n",
      "Epoch 87/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1866 - val_loss: -0.2017\n",
      "Epoch 88/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1879 - val_loss: -0.1994\n",
      "Epoch 89/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1881 - val_loss: -0.1996\n",
      "Epoch 90/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1878 - val_loss: -0.1966\n",
      "Epoch 91/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1888 - val_loss: -0.1986\n",
      "Epoch 92/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1884 - val_loss: -0.1972\n",
      "Epoch 93/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1877 - val_loss: -0.1882\n",
      "Epoch 94/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1887 - val_loss: -0.2014\n",
      "Epoch 95/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1888 - val_loss: -0.1940\n",
      "Epoch 96/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1891 - val_loss: -0.2022\n",
      "Epoch 97/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1893 - val_loss: -0.2033\n",
      "Epoch 98/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1891 - val_loss: -0.2013\n",
      "Epoch 99/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1893 - val_loss: -0.2004\n",
      "Epoch 100/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1902 - val_loss: -0.1967\n",
      "Epoch 101/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1899 - val_loss: -0.1989\n",
      "Epoch 102/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1909 - val_loss: -0.1969\n",
      "Epoch 103/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1908 - val_loss: -0.1928\n",
      "Epoch 104/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1911 - val_loss: -0.1918\n",
      "Epoch 105/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1910 - val_loss: -0.2002\n",
      "Epoch 106/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1926 - val_loss: -0.2007\n",
      "Epoch 107/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1922 - val_loss: -0.1996\n",
      "Epoch 108/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1924 - val_loss: -0.1919\n",
      "Epoch 109/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1917 - val_loss: -0.1946\n",
      "Epoch 110/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1932 - val_loss: -0.1963\n",
      "Epoch 111/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1924 - val_loss: -0.1904\n",
      "Epoch 112/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1932 - val_loss: -0.1976\n",
      "Epoch 113/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1934 - val_loss: -0.1991\n",
      "Epoch 114/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1942 - val_loss: -0.1995\n",
      "Epoch 115/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1941 - val_loss: -0.2013\n",
      "Epoch 116/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1942 - val_loss: -0.1970\n",
      "Epoch 117/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1952 - val_loss: -0.1950\n",
      "Epoch 118/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1942 - val_loss: -0.1971\n",
      "Epoch 119/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1954 - val_loss: -0.1991\n",
      "Epoch 120/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1952 - val_loss: -0.1977\n",
      "Epoch 121/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1956 - val_loss: -0.1966\n",
      "Epoch 122/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1962 - val_loss: -0.1962\n",
      "Epoch 123/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1958 - val_loss: -0.1954\n",
      "Epoch 124/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1966 - val_loss: -0.1947\n",
      "Epoch 125/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1971 - val_loss: -0.1946\n",
      "Epoch 126/10000\n",
      "760201/760201 [==============================] - 10s 14us/sample - loss: -0.1969 - val_loss: -0.1953\n",
      "Epoch 127/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1974 - val_loss: -0.1914\n",
      "Epoch 128/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1976 - val_loss: -0.1953\n",
      "Epoch 129/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1981 - val_loss: -0.1888\n",
      "Epoch 130/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1980 - val_loss: -0.1950\n",
      "Epoch 131/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1989 - val_loss: -0.1879\n",
      "Epoch 132/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.1990 - val_loss: -0.1888\n",
      "Epoch 133/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1993 - val_loss: -0.1944\n",
      "Epoch 134/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.1998 - val_loss: -0.1955\n",
      "Epoch 135/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2002 - val_loss: -0.1903\n",
      "Epoch 136/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2003 - val_loss: -0.1977\n",
      "Epoch 137/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2005 - val_loss: -0.1898\n",
      "Epoch 138/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2017 - val_loss: -0.1955\n",
      "Epoch 139/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2009 - val_loss: -0.1927\n",
      "Epoch 140/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2008 - val_loss: -0.1935\n",
      "Epoch 141/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2020 - val_loss: -0.1826\n",
      "Epoch 142/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2028 - val_loss: -0.1943\n",
      "Epoch 143/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2017 - val_loss: -0.1938\n",
      "Epoch 144/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2032 - val_loss: -0.1936\n",
      "Epoch 145/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2038 - val_loss: -0.1906\n",
      "Epoch 146/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2033 - val_loss: -0.1930\n",
      "Epoch 147/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2048 - val_loss: -0.1859\n",
      "Epoch 148/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2044 - val_loss: -0.1877\n",
      "Epoch 149/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2051 - val_loss: -0.1918\n",
      "Epoch 150/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2051 - val_loss: -0.1894\n",
      "Epoch 151/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2056 - val_loss: -0.1893\n",
      "Epoch 152/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2062 - val_loss: -0.1895\n",
      "Epoch 153/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2067 - val_loss: -0.1893\n",
      "Epoch 154/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2070 - val_loss: -0.1913\n",
      "Epoch 155/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2078 - val_loss: -0.1889\n",
      "Epoch 156/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2072 - val_loss: -0.1917\n",
      "Epoch 157/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2084 - val_loss: -0.1860\n",
      "Epoch 158/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2084 - val_loss: -0.1831\n",
      "Epoch 159/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2093 - val_loss: -0.1869\n",
      "Epoch 160/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2094 - val_loss: -0.1910\n",
      "Epoch 161/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2095 - val_loss: -0.1841\n",
      "Epoch 162/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2092 - val_loss: -0.1867\n",
      "Epoch 163/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2109 - val_loss: -0.1856\n",
      "Epoch 164/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2108 - val_loss: -0.1875\n",
      "Epoch 165/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2108 - val_loss: -0.1865\n",
      "Epoch 166/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2120 - val_loss: -0.1859\n",
      "Epoch 167/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2114 - val_loss: -0.1864\n",
      "Epoch 168/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2121 - val_loss: -0.1820\n",
      "Epoch 169/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2126 - val_loss: -0.1842\n",
      "Epoch 170/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2127 - val_loss: -0.1802\n",
      "Epoch 171/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2131 - val_loss: -0.1858\n",
      "Epoch 172/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2137 - val_loss: -0.1847\n",
      "Epoch 173/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2145 - val_loss: -0.1786\n",
      "Epoch 174/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2143 - val_loss: -0.1825\n",
      "Epoch 175/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2150 - val_loss: -0.1811\n",
      "Epoch 176/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2163 - val_loss: -0.1808\n",
      "Epoch 177/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2165 - val_loss: -0.1732\n",
      "Epoch 178/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2162 - val_loss: -0.1696\n",
      "Epoch 179/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2168 - val_loss: -0.1811\n",
      "Epoch 180/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2172 - val_loss: -0.1780\n",
      "Epoch 181/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2179 - val_loss: -0.1814\n",
      "Epoch 182/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2188 - val_loss: -0.1768\n",
      "Epoch 183/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2178 - val_loss: -0.1753\n",
      "Epoch 184/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2197 - val_loss: -0.1794\n",
      "Epoch 185/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2195 - val_loss: -0.1791\n",
      "Epoch 186/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2193 - val_loss: -0.1772\n",
      "Epoch 187/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2201 - val_loss: -0.1765\n",
      "Epoch 188/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2211 - val_loss: -0.1737\n",
      "Epoch 189/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2206 - val_loss: -0.1746\n",
      "Epoch 190/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2212 - val_loss: -0.1733\n",
      "Epoch 191/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2222 - val_loss: -0.1739\n",
      "Epoch 192/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2223 - val_loss: -0.1713\n",
      "Epoch 193/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2225 - val_loss: -0.1649\n",
      "Epoch 194/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2228 - val_loss: -0.1735\n",
      "Epoch 195/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2229 - val_loss: -0.1756\n",
      "Epoch 196/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2238 - val_loss: -0.1774\n",
      "Epoch 197/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2248 - val_loss: -0.1702\n",
      "Epoch 198/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2250 - val_loss: -0.1749\n",
      "Epoch 199/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2251 - val_loss: -0.1691\n",
      "Epoch 200/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2250 - val_loss: -0.1541\n",
      "Epoch 201/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2260 - val_loss: -0.1711\n",
      "Epoch 202/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2265 - val_loss: -0.1689\n",
      "Epoch 203/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2273 - val_loss: -0.1720\n",
      "Epoch 204/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2274 - val_loss: -0.1711\n",
      "Epoch 205/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2276 - val_loss: -0.1658\n",
      "Epoch 206/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2276 - val_loss: -0.1706\n",
      "Epoch 207/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2287 - val_loss: -0.1698\n",
      "Epoch 208/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2290 - val_loss: -0.1687\n",
      "Epoch 209/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2302 - val_loss: -0.1614\n",
      "Epoch 210/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2296 - val_loss: -0.1676\n",
      "Epoch 211/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2300 - val_loss: -0.1702\n",
      "Epoch 212/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2314 - val_loss: -0.1658\n",
      "Epoch 213/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2306 - val_loss: -0.1631\n",
      "Epoch 214/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2308 - val_loss: -0.1658\n",
      "Epoch 215/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2320 - val_loss: -0.1680\n",
      "Epoch 216/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2317 - val_loss: -0.1663\n",
      "Epoch 217/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2327 - val_loss: -0.1670\n",
      "Epoch 218/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2341 - val_loss: -0.1690\n",
      "Epoch 219/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2334 - val_loss: -0.1680\n",
      "Epoch 220/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2340 - val_loss: -0.1625\n",
      "Epoch 221/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2348 - val_loss: -0.1567\n",
      "Epoch 222/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2353 - val_loss: -0.1614\n",
      "Epoch 223/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2347 - val_loss: -0.1665\n",
      "Epoch 224/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2362 - val_loss: -0.1591\n",
      "Epoch 225/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2365 - val_loss: -0.1597\n",
      "Epoch 226/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2366 - val_loss: -0.1530\n",
      "Epoch 227/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2374 - val_loss: -0.1584\n",
      "Epoch 228/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2373 - val_loss: -0.1549\n",
      "Epoch 229/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2381 - val_loss: -0.1504\n",
      "Epoch 230/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2378 - val_loss: -0.1574\n",
      "Epoch 231/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2395 - val_loss: -0.1578\n",
      "Epoch 232/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2397 - val_loss: -0.1574\n",
      "Epoch 233/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2395 - val_loss: -0.1515\n",
      "Epoch 234/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2412 - val_loss: -0.1601\n",
      "Epoch 235/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2411 - val_loss: -0.1596\n",
      "Epoch 236/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2424 - val_loss: -0.1583\n",
      "Epoch 237/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2407 - val_loss: -0.1546\n",
      "Epoch 238/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2421 - val_loss: -0.1530\n",
      "Epoch 239/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2422 - val_loss: -0.1559\n",
      "Epoch 240/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2434 - val_loss: -0.1515\n",
      "Epoch 241/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2426 - val_loss: -0.1555\n",
      "Epoch 242/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2436 - val_loss: -0.1477\n",
      "Epoch 243/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2438 - val_loss: -0.1500\n",
      "Epoch 244/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2445 - val_loss: -0.1489\n",
      "Epoch 245/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2440 - val_loss: -0.1519\n",
      "Epoch 246/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2454 - val_loss: -0.1466\n",
      "Epoch 247/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2457 - val_loss: -0.1542\n",
      "Epoch 248/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2467 - val_loss: -0.1466\n",
      "Epoch 249/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2474 - val_loss: -0.1431\n",
      "Epoch 250/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2476 - val_loss: -0.1440\n",
      "Epoch 251/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2481 - val_loss: -0.1500\n",
      "Epoch 252/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2477 - val_loss: -0.1414\n",
      "Epoch 253/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2494 - val_loss: -0.1341\n",
      "Epoch 254/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2487 - val_loss: -0.1471\n",
      "Epoch 255/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2496 - val_loss: -0.1284\n",
      "Epoch 256/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2496 - val_loss: -0.1414\n",
      "Epoch 257/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2502 - val_loss: -0.1430\n",
      "Epoch 258/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2506 - val_loss: -0.1438\n",
      "Epoch 259/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2508 - val_loss: -0.1371\n",
      "Epoch 260/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2513 - val_loss: -0.1414\n",
      "Epoch 261/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2521 - val_loss: -0.1418\n",
      "Epoch 262/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2528 - val_loss: -0.1430\n",
      "Epoch 263/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2530 - val_loss: -0.1426\n",
      "Epoch 264/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2537 - val_loss: -0.1408\n",
      "Epoch 265/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2544 - val_loss: -0.1375\n",
      "Epoch 266/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2544 - val_loss: -0.1314\n",
      "Epoch 267/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2541 - val_loss: -0.1359\n",
      "Epoch 268/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2549 - val_loss: -0.1420\n",
      "Epoch 269/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2559 - val_loss: -0.1311\n",
      "Epoch 270/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2562 - val_loss: -0.1363\n",
      "Epoch 271/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2558 - val_loss: -0.1348\n",
      "Epoch 272/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2565 - val_loss: -0.1301\n",
      "Epoch 273/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2569 - val_loss: -0.1359\n",
      "Epoch 274/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2576 - val_loss: -0.1265\n",
      "Epoch 275/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2577 - val_loss: -0.1377\n",
      "Epoch 276/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2590 - val_loss: -0.1334\n",
      "Epoch 277/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2596 - val_loss: -0.1213\n",
      "Epoch 278/10000\n",
      "760201/760201 [==============================] - 10s 13us/sample - loss: -0.2591 - val_loss: -0.1310\n",
      "Epoch 279/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2601 - val_loss: -0.1315\n",
      "Epoch 280/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2599 - val_loss: -0.1277\n",
      "Epoch 281/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2603 - val_loss: -0.1308\n",
      "Epoch 282/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2612 - val_loss: -0.1311\n",
      "Epoch 283/10000\n",
      "760201/760201 [==============================] - 9s 12us/sample - loss: -0.2617 - val_loss: -0.1281\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1205.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7411, 12, 1)\n",
      "y_test.shape:  (7411, 1)\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:30:59,816 WARNING Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1205\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1205\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1211.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7841, 12, 1)\n",
      "y_test.shape:  (7841, 1)\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:03,763 WARNING Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1211\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1211\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1219.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7883, 12, 1)\n",
      "y_test.shape:  (7883, 1)\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:07,708 WARNING Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1219\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1219\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1230.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7589, 12, 1)\n",
      "y_test.shape:  (7589, 1)\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:11,666 WARNING Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1230\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1230\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1239.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7681, 12, 1)\n",
      "y_test.shape:  (7681, 1)\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:15,580 WARNING Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1239\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1239\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1271.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7942, 12, 1)\n",
      "y_test.shape:  (7942, 1)\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:19,626 WARNING Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1271\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1271\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1286.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7963, 12, 1)\n",
      "y_test.shape:  (7963, 1)\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:23,787 WARNING Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1286\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1286\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1311.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7384, 12, 1)\n",
      "y_test.shape:  (7384, 1)\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:27,818 WARNING Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1311\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1311\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1330.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7877, 12, 1)\n",
      "y_test.shape:  (7877, 1)\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:31,953 WARNING Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1330\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1330\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1336.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7669, 12, 1)\n",
      "y_test.shape:  (7669, 1)\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:36,323 WARNING Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1336\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1336\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1343.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7292, 12, 1)\n",
      "y_test.shape:  (7292, 1)\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:40,417 WARNING Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1343\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1343\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1345.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7489, 12, 1)\n",
      "y_test.shape:  (7489, 1)\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:44,420 WARNING Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1345\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1345\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1348.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7713, 12, 1)\n",
      "y_test.shape:  (7713, 1)\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:48,467 WARNING Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1348\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1348\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\563-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (14269, 12, 1)\n",
      "y_test.shape:  (14269, 1)\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:52,654 WARNING Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 563\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  563\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\567-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (12050, 12, 1)\n",
      "y_test.shape:  (12050, 1)\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:31:58,192 WARNING Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 567\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  567\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject23.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11505, 12, 1)\n",
      "y_test.shape:  (11505, 1)\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:03,737 WARNING Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject23\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject23\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject24.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (9648, 12, 1)\n",
      "y_test.shape:  (9648, 1)\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:08,894 WARNING Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject24\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject24\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject25.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11748, 12, 1)\n",
      "y_test.shape:  (11748, 1)\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:13,628 WARNING Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject25\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject25\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject26.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11613, 12, 1)\n",
      "y_test.shape:  (11613, 1)\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:18,898 WARNING Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject26\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject26\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject27.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11831, 12, 1)\n",
      "y_test.shape:  (11831, 1)\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:24,230 WARNING Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject27\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject27\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject28.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11762, 12, 1)\n",
      "y_test.shape:  (11762, 1)\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:29,402 WARNING Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject28\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject28\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject29.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5079, 12, 1)\n",
      "y_test.shape:  (5079, 1)\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:35,013 WARNING Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject29\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject29\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject30.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11724, 12, 1)\n",
      "y_test.shape:  (11724, 1)\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:39,171 WARNING Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject30\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject30\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject31.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11911, 12, 1)\n",
      "y_test.shape:  (11911, 1)\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:44,447 WARNING Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject31\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject31\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject32.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11607, 12, 1)\n",
      "y_test.shape:  (11607, 1)\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:49,976 WARNING Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject32\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject32\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject33.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11639, 12, 1)\n",
      "y_test.shape:  (11639, 1)\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:32:55,369 WARNING Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject33\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject33\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'diatrend_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold4_training',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'ohio_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                                '2020\\\\fold4_training',\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\mixed.py',\n",
      "                   't1dexi_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\fold4_training',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 00:34:28,875 WARNING Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-02-03 00:34:29,009 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 748950 samples, validate on 187184 samples\n",
      "Epoch 1/10000\n",
      "746496/748950 [============================>.] - ETA: 0s - loss: 0.1239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748950/748950 [==============================] - 11s 15us/sample - loss: 0.1236 - val_loss: -0.0886\n",
      "Epoch 2/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.0205 - val_loss: -0.1318\n",
      "Epoch 3/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.0586 - val_loss: -0.1371\n",
      "Epoch 4/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.0816 - val_loss: -0.1652\n",
      "Epoch 5/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.0995 - val_loss: -0.1643\n",
      "Epoch 6/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1130 - val_loss: -0.1590\n",
      "Epoch 7/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1241 - val_loss: -0.1786\n",
      "Epoch 8/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1337 - val_loss: -0.1824\n",
      "Epoch 9/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1407 - val_loss: -0.1548\n",
      "Epoch 10/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1469 - val_loss: -0.1733\n",
      "Epoch 11/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1503 - val_loss: -0.1739\n",
      "Epoch 12/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1542 - val_loss: -0.1955\n",
      "Epoch 13/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1568 - val_loss: -0.1889\n",
      "Epoch 14/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1600 - val_loss: -0.1813\n",
      "Epoch 15/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1605 - val_loss: -0.1729\n",
      "Epoch 16/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1630 - val_loss: -0.1797\n",
      "Epoch 17/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1630 - val_loss: -0.1860\n",
      "Epoch 18/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1653 - val_loss: -0.1860\n",
      "Epoch 19/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1663 - val_loss: -0.1842\n",
      "Epoch 20/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1658 - val_loss: -0.1824\n",
      "Epoch 21/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1677 - val_loss: -0.1832\n",
      "Epoch 22/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1672 - val_loss: -0.1920\n",
      "Epoch 23/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1684 - val_loss: -0.1932\n",
      "Epoch 24/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1704 - val_loss: -0.1971\n",
      "Epoch 25/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.1700 - val_loss: -0.1990\n",
      "Epoch 26/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1709 - val_loss: -0.1925\n",
      "Epoch 27/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1717 - val_loss: -0.1903\n",
      "Epoch 28/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1718 - val_loss: -0.1970\n",
      "Epoch 29/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1722 - val_loss: -0.1864\n",
      "Epoch 30/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1728 - val_loss: -0.1968\n",
      "Epoch 31/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1730 - val_loss: -0.2007\n",
      "Epoch 32/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1738 - val_loss: -0.2013\n",
      "Epoch 33/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1735 - val_loss: -0.2023\n",
      "Epoch 34/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1735 - val_loss: -0.1904\n",
      "Epoch 35/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1749 - val_loss: -0.1941\n",
      "Epoch 36/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1746 - val_loss: -0.2030\n",
      "Epoch 37/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1753 - val_loss: -0.1973\n",
      "Epoch 38/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1756 - val_loss: -0.1975\n",
      "Epoch 39/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1757 - val_loss: -0.1939\n",
      "Epoch 40/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1760 - val_loss: -0.1989\n",
      "Epoch 41/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1761 - val_loss: -0.1901\n",
      "Epoch 42/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1761 - val_loss: -0.2019\n",
      "Epoch 43/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1770 - val_loss: -0.1868\n",
      "Epoch 44/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1769 - val_loss: -0.1991\n",
      "Epoch 45/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1780 - val_loss: -0.2020\n",
      "Epoch 46/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1773 - val_loss: -0.2037\n",
      "Epoch 47/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1787 - val_loss: -0.1990\n",
      "Epoch 48/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1791 - val_loss: -0.1994\n",
      "Epoch 49/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1786 - val_loss: -0.1985\n",
      "Epoch 50/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1792 - val_loss: -0.1930\n",
      "Epoch 51/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1798 - val_loss: -0.1979\n",
      "Epoch 52/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1797 - val_loss: -0.1915\n",
      "Epoch 53/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1801 - val_loss: -0.1998\n",
      "Epoch 54/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1809 - val_loss: -0.2035\n",
      "Epoch 55/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1805 - val_loss: -0.1977\n",
      "Epoch 56/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1808 - val_loss: -0.1980\n",
      "Epoch 57/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1809 - val_loss: -0.2021\n",
      "Epoch 58/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1810 - val_loss: -0.1968\n",
      "Epoch 59/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1814 - val_loss: -0.1977\n",
      "Epoch 60/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1812 - val_loss: -0.2032\n",
      "Epoch 61/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1816 - val_loss: -0.2011\n",
      "Epoch 62/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1818 - val_loss: -0.2015\n",
      "Epoch 63/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1819 - val_loss: -0.2026\n",
      "Epoch 64/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1827 - val_loss: -0.1969\n",
      "Epoch 65/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1827 - val_loss: -0.1970\n",
      "Epoch 66/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1817 - val_loss: -0.2012\n",
      "Epoch 67/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1834 - val_loss: -0.2033\n",
      "Epoch 68/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1835 - val_loss: -0.2022\n",
      "Epoch 69/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1836 - val_loss: -0.1976\n",
      "Epoch 70/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1839 - val_loss: -0.2028\n",
      "Epoch 71/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1843 - val_loss: -0.2023\n",
      "Epoch 72/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1838 - val_loss: -0.1985\n",
      "Epoch 73/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1842 - val_loss: -0.2025\n",
      "Epoch 74/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1848 - val_loss: -0.1961\n",
      "Epoch 75/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1847 - val_loss: -0.1984\n",
      "Epoch 76/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1849 - val_loss: -0.1936\n",
      "Epoch 77/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1849 - val_loss: -0.2036\n",
      "Epoch 78/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1856 - val_loss: -0.1986\n",
      "Epoch 79/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1856 - val_loss: -0.1983\n",
      "Epoch 80/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1867 - val_loss: -0.1995\n",
      "Epoch 81/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1861 - val_loss: -0.2046\n",
      "Epoch 82/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1868 - val_loss: -0.1977\n",
      "Epoch 83/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1865 - val_loss: -0.1977\n",
      "Epoch 84/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1869 - val_loss: -0.1969\n",
      "Epoch 85/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1871 - val_loss: -0.1958\n",
      "Epoch 86/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1879 - val_loss: -0.2021\n",
      "Epoch 87/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1875 - val_loss: -0.2031\n",
      "Epoch 88/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1882 - val_loss: -0.1997\n",
      "Epoch 89/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1870 - val_loss: -0.1993\n",
      "Epoch 90/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1883 - val_loss: -0.2049\n",
      "Epoch 91/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1889 - val_loss: -0.2020\n",
      "Epoch 92/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1894 - val_loss: -0.1982\n",
      "Epoch 93/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1890 - val_loss: -0.1980\n",
      "Epoch 94/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1900 - val_loss: -0.1981\n",
      "Epoch 95/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1894 - val_loss: -0.2013\n",
      "Epoch 96/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1902 - val_loss: -0.2034\n",
      "Epoch 97/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1892 - val_loss: -0.2008\n",
      "Epoch 98/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1913 - val_loss: -0.1931\n",
      "Epoch 99/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1906 - val_loss: -0.1959\n",
      "Epoch 100/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1907 - val_loss: -0.1981\n",
      "Epoch 101/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1909 - val_loss: -0.1976\n",
      "Epoch 102/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1909 - val_loss: -0.2004\n",
      "Epoch 103/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1918 - val_loss: -0.1961\n",
      "Epoch 104/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1917 - val_loss: -0.1963\n",
      "Epoch 105/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1925 - val_loss: -0.2004\n",
      "Epoch 106/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1917 - val_loss: -0.1977\n",
      "Epoch 107/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1932 - val_loss: -0.1988\n",
      "Epoch 108/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.1927 - val_loss: -0.1905\n",
      "Epoch 109/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1928 - val_loss: -0.1958\n",
      "Epoch 110/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1930 - val_loss: -0.1973\n",
      "Epoch 111/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1940 - val_loss: -0.2005\n",
      "Epoch 112/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1943 - val_loss: -0.1893\n",
      "Epoch 113/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1939 - val_loss: -0.1943\n",
      "Epoch 114/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1946 - val_loss: -0.1910\n",
      "Epoch 115/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1949 - val_loss: -0.1974\n",
      "Epoch 116/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1956 - val_loss: -0.1977\n",
      "Epoch 117/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1958 - val_loss: -0.1940\n",
      "Epoch 118/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1958 - val_loss: -0.1982\n",
      "Epoch 119/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1965 - val_loss: -0.1968\n",
      "Epoch 120/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1965 - val_loss: -0.1982\n",
      "Epoch 121/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1965 - val_loss: -0.1996\n",
      "Epoch 122/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1969 - val_loss: -0.1952\n",
      "Epoch 123/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1974 - val_loss: -0.1999\n",
      "Epoch 124/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1978 - val_loss: -0.1972\n",
      "Epoch 125/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1980 - val_loss: -0.1964\n",
      "Epoch 126/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1980 - val_loss: -0.1972\n",
      "Epoch 127/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.1991 - val_loss: -0.2005\n",
      "Epoch 128/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1986 - val_loss: -0.1937\n",
      "Epoch 129/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.1993 - val_loss: -0.1944\n",
      "Epoch 130/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.1998 - val_loss: -0.1941\n",
      "Epoch 131/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2001 - val_loss: -0.1966\n",
      "Epoch 132/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2010 - val_loss: -0.1964\n",
      "Epoch 133/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2007 - val_loss: -0.1945\n",
      "Epoch 134/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2008 - val_loss: -0.1948\n",
      "Epoch 135/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2018 - val_loss: -0.1912\n",
      "Epoch 136/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2018 - val_loss: -0.1957\n",
      "Epoch 137/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2021 - val_loss: -0.1921\n",
      "Epoch 138/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2016 - val_loss: -0.1910\n",
      "Epoch 139/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2032 - val_loss: -0.1894\n",
      "Epoch 140/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2029 - val_loss: -0.1962\n",
      "Epoch 141/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2034 - val_loss: -0.1992\n",
      "Epoch 142/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2042 - val_loss: -0.1948\n",
      "Epoch 143/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2041 - val_loss: -0.1949\n",
      "Epoch 144/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2051 - val_loss: -0.1896\n",
      "Epoch 145/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2042 - val_loss: -0.1882\n",
      "Epoch 146/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2051 - val_loss: -0.1935\n",
      "Epoch 147/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2050 - val_loss: -0.1879\n",
      "Epoch 148/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2060 - val_loss: -0.1934\n",
      "Epoch 149/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2063 - val_loss: -0.1897\n",
      "Epoch 150/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2064 - val_loss: -0.1864\n",
      "Epoch 151/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2071 - val_loss: -0.1896\n",
      "Epoch 152/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2076 - val_loss: -0.1915\n",
      "Epoch 153/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2083 - val_loss: -0.1940\n",
      "Epoch 154/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2076 - val_loss: -0.1890\n",
      "Epoch 155/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2085 - val_loss: -0.1840\n",
      "Epoch 156/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2087 - val_loss: -0.1912\n",
      "Epoch 157/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2097 - val_loss: -0.1944\n",
      "Epoch 158/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2100 - val_loss: -0.1843\n",
      "Epoch 159/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2100 - val_loss: -0.1887\n",
      "Epoch 160/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2103 - val_loss: -0.1871\n",
      "Epoch 161/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2106 - val_loss: -0.1895\n",
      "Epoch 162/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2117 - val_loss: -0.1907\n",
      "Epoch 163/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2114 - val_loss: -0.1879\n",
      "Epoch 164/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2125 - val_loss: -0.1866\n",
      "Epoch 165/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2130 - val_loss: -0.1881\n",
      "Epoch 166/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2134 - val_loss: -0.1875\n",
      "Epoch 167/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2127 - val_loss: -0.1841\n",
      "Epoch 168/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2138 - val_loss: -0.1886\n",
      "Epoch 169/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2143 - val_loss: -0.1882\n",
      "Epoch 170/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2146 - val_loss: -0.1829\n",
      "Epoch 171/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2155 - val_loss: -0.1837\n",
      "Epoch 172/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2144 - val_loss: -0.1831\n",
      "Epoch 173/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2160 - val_loss: -0.1827\n",
      "Epoch 174/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2168 - val_loss: -0.1831\n",
      "Epoch 175/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2174 - val_loss: -0.1872\n",
      "Epoch 176/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2162 - val_loss: -0.1791\n",
      "Epoch 177/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2175 - val_loss: -0.1764\n",
      "Epoch 178/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2188 - val_loss: -0.1812\n",
      "Epoch 179/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2189 - val_loss: -0.1843\n",
      "Epoch 180/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2190 - val_loss: -0.1837\n",
      "Epoch 181/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2203 - val_loss: -0.1833\n",
      "Epoch 182/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2189 - val_loss: -0.1783\n",
      "Epoch 183/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2204 - val_loss: -0.1815\n",
      "Epoch 184/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2209 - val_loss: -0.1787\n",
      "Epoch 185/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2206 - val_loss: -0.1755\n",
      "Epoch 186/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2219 - val_loss: -0.1811\n",
      "Epoch 187/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2227 - val_loss: -0.1801\n",
      "Epoch 188/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2229 - val_loss: -0.1763\n",
      "Epoch 189/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2232 - val_loss: -0.1778\n",
      "Epoch 190/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2233 - val_loss: -0.1744\n",
      "Epoch 191/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2244 - val_loss: -0.1731\n",
      "Epoch 192/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2246 - val_loss: -0.1783\n",
      "Epoch 193/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2242 - val_loss: -0.1702\n",
      "Epoch 194/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2255 - val_loss: -0.1722\n",
      "Epoch 195/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2257 - val_loss: -0.1727\n",
      "Epoch 196/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2269 - val_loss: -0.1782\n",
      "Epoch 197/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2274 - val_loss: -0.1736\n",
      "Epoch 198/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2269 - val_loss: -0.1748\n",
      "Epoch 199/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2287 - val_loss: -0.1702\n",
      "Epoch 200/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2291 - val_loss: -0.1695\n",
      "Epoch 201/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2298 - val_loss: -0.1692\n",
      "Epoch 202/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2291 - val_loss: -0.1706\n",
      "Epoch 203/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2297 - val_loss: -0.1729\n",
      "Epoch 204/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2298 - val_loss: -0.1758\n",
      "Epoch 205/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2309 - val_loss: -0.1754\n",
      "Epoch 206/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2310 - val_loss: -0.1637\n",
      "Epoch 207/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2318 - val_loss: -0.1690\n",
      "Epoch 208/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2310 - val_loss: -0.1636\n",
      "Epoch 209/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2334 - val_loss: -0.1638\n",
      "Epoch 210/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2319 - val_loss: -0.1655\n",
      "Epoch 211/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2335 - val_loss: -0.1670\n",
      "Epoch 212/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2346 - val_loss: -0.1676\n",
      "Epoch 213/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2348 - val_loss: -0.1623\n",
      "Epoch 214/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2354 - val_loss: -0.1712\n",
      "Epoch 215/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2359 - val_loss: -0.1603\n",
      "Epoch 216/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2363 - val_loss: -0.1666\n",
      "Epoch 217/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2358 - val_loss: -0.1598\n",
      "Epoch 218/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2374 - val_loss: -0.1625\n",
      "Epoch 219/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2379 - val_loss: -0.1609\n",
      "Epoch 220/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2380 - val_loss: -0.1594\n",
      "Epoch 221/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2389 - val_loss: -0.1614\n",
      "Epoch 222/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2393 - val_loss: -0.1613\n",
      "Epoch 223/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2393 - val_loss: -0.1567\n",
      "Epoch 224/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2395 - val_loss: -0.1591\n",
      "Epoch 225/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2394 - val_loss: -0.1531\n",
      "Epoch 226/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2413 - val_loss: -0.1637\n",
      "Epoch 227/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2415 - val_loss: -0.1636\n",
      "Epoch 228/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2419 - val_loss: -0.1534\n",
      "Epoch 229/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2414 - val_loss: -0.1616\n",
      "Epoch 230/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2433 - val_loss: -0.1487\n",
      "Epoch 231/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2437 - val_loss: -0.1574\n",
      "Epoch 232/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2433 - val_loss: -0.1521\n",
      "Epoch 233/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2443 - val_loss: -0.1614\n",
      "Epoch 234/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2442 - val_loss: -0.1590\n",
      "Epoch 235/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2448 - val_loss: -0.1540\n",
      "Epoch 236/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2456 - val_loss: -0.1551\n",
      "Epoch 237/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2460 - val_loss: -0.1571\n",
      "Epoch 238/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2457 - val_loss: -0.1521\n",
      "Epoch 239/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2478 - val_loss: -0.1536\n",
      "Epoch 240/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2471 - val_loss: -0.1545\n",
      "Epoch 241/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2479 - val_loss: -0.1524\n",
      "Epoch 242/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2489 - val_loss: -0.1513\n",
      "Epoch 243/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2490 - val_loss: -0.1510\n",
      "Epoch 244/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2494 - val_loss: -0.1505\n",
      "Epoch 245/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2511 - val_loss: -0.1456\n",
      "Epoch 246/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2500 - val_loss: -0.1455\n",
      "Epoch 247/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2511 - val_loss: -0.1469\n",
      "Epoch 248/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2510 - val_loss: -0.1461\n",
      "Epoch 249/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2527 - val_loss: -0.1434\n",
      "Epoch 250/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2524 - val_loss: -0.1342\n",
      "Epoch 251/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2534 - val_loss: -0.1333\n",
      "Epoch 252/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2529 - val_loss: -0.1431\n",
      "Epoch 253/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2540 - val_loss: -0.1469\n",
      "Epoch 254/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2541 - val_loss: -0.1448\n",
      "Epoch 255/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2548 - val_loss: -0.1419\n",
      "Epoch 256/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2553 - val_loss: -0.1469\n",
      "Epoch 257/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2564 - val_loss: -0.1434\n",
      "Epoch 258/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2571 - val_loss: -0.1332\n",
      "Epoch 259/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2561 - val_loss: -0.1443\n",
      "Epoch 260/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2579 - val_loss: -0.1391\n",
      "Epoch 261/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2566 - val_loss: -0.1421\n",
      "Epoch 262/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2590 - val_loss: -0.1369\n",
      "Epoch 263/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2598 - val_loss: -0.1353\n",
      "Epoch 264/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2596 - val_loss: -0.1426\n",
      "Epoch 265/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2590 - val_loss: -0.1351\n",
      "Epoch 266/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2603 - val_loss: -0.1346\n",
      "Epoch 267/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2614 - val_loss: -0.1338\n",
      "Epoch 268/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2606 - val_loss: -0.1302\n",
      "Epoch 269/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2619 - val_loss: -0.1263\n",
      "Epoch 270/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2627 - val_loss: -0.1320\n",
      "Epoch 271/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2618 - val_loss: -0.1352\n",
      "Epoch 272/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2624 - val_loss: -0.1330\n",
      "Epoch 273/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2631 - val_loss: -0.1291\n",
      "Epoch 274/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2636 - val_loss: -0.1317\n",
      "Epoch 275/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2639 - val_loss: -0.1254\n",
      "Epoch 276/10000\n",
      "748950/748950 [==============================] - 9s 13us/sample - loss: -0.2649 - val_loss: -0.1336\n",
      "Epoch 277/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2654 - val_loss: -0.1238\n",
      "Epoch 278/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2655 - val_loss: -0.1324\n",
      "Epoch 279/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2655 - val_loss: -0.1255\n",
      "Epoch 280/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2665 - val_loss: -0.1257\n",
      "Epoch 281/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2672 - val_loss: -0.1253\n",
      "Epoch 282/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2672 - val_loss: -0.1183\n",
      "Epoch 283/10000\n",
      "748950/748950 [==============================] - 10s 14us/sample - loss: -0.2684 - val_loss: -0.1234\n",
      "Epoch 284/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2683 - val_loss: -0.1245\n",
      "Epoch 285/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2682 - val_loss: -0.1210\n",
      "Epoch 286/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2693 - val_loss: -0.1232\n",
      "Epoch 287/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2696 - val_loss: -0.1207\n",
      "Epoch 288/10000\n",
      "748950/748950 [==============================] - 10s 13us/sample - loss: -0.2700 - val_loss: -0.1232\n",
      "Epoch 289/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2702 - val_loss: -0.1223\n",
      "Epoch 290/10000\n",
      "748950/748950 [==============================] - 9s 12us/sample - loss: -0.2716 - val_loss: -0.1213\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1361.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7659, 12, 1)\n",
      "y_test.shape:  (7659, 1)\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:00,845 WARNING Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1361\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1361\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1362.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (6251, 12, 1)\n",
      "y_test.shape:  (6251, 1)\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:05,464 WARNING Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1362\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1362\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1363.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7635, 12, 1)\n",
      "y_test.shape:  (7635, 1)\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:09,649 WARNING Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1363\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1363\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1377.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7785, 12, 1)\n",
      "y_test.shape:  (7785, 1)\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:14,191 WARNING Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1377\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1377\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1381.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7749, 12, 1)\n",
      "y_test.shape:  (7749, 1)\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:18,740 WARNING Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1381\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1381\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1386.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7360, 12, 1)\n",
      "y_test.shape:  (7360, 1)\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:23,233 WARNING Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1386\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1386\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1408.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7348, 12, 1)\n",
      "y_test.shape:  (7348, 1)\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:27,624 WARNING Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1408\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1408\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1422.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7096, 12, 1)\n",
      "y_test.shape:  (7096, 1)\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:32,068 WARNING Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1422\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1422\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1427.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7290, 12, 1)\n",
      "y_test.shape:  (7290, 1)\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:36,539 WARNING Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1427\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1427\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1433.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7644, 12, 1)\n",
      "y_test.shape:  (7644, 1)\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:41,047 WARNING Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1433\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1433\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1435.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7022, 12, 1)\n",
      "y_test.shape:  (7022, 1)\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:45,596 WARNING Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1435\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1435\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1457.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7752, 12, 1)\n",
      "y_test.shape:  (7752, 1)\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:50,127 WARNING Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1457\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1457\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1459.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7535, 12, 1)\n",
      "y_test.shape:  (7535, 1)\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:54,720 WARNING Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1459\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1459\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\570-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13217, 12, 1)\n",
      "y_test.shape:  (13217, 1)\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:20:59,312 WARNING Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 570\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  570\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\575-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13056, 12, 1)\n",
      "y_test.shape:  (13056, 1)\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:05,095 WARNING Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 575\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  575\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\584-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13543, 12, 1)\n",
      "y_test.shape:  (13543, 1)\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:10,984 WARNING Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 584\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  584\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject34.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11469, 12, 1)\n",
      "y_test.shape:  (11469, 1)\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:17,166 WARNING Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject34\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject34\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject35.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11692, 12, 1)\n",
      "y_test.shape:  (11692, 1)\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:22,870 WARNING Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject35\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject35\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject36.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11157, 12, 1)\n",
      "y_test.shape:  (11157, 1)\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:28,632 WARNING Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject36\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject36\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject37.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11500, 12, 1)\n",
      "y_test.shape:  (11500, 1)\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:34,354 WARNING Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject37\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject37\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject38.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11531, 12, 1)\n",
      "y_test.shape:  (11531, 1)\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:40,113 WARNING Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject38\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject38\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject39.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11071, 12, 1)\n",
      "y_test.shape:  (11071, 1)\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:45,973 WARNING Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject39\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject39\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject40.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11431, 12, 1)\n",
      "y_test.shape:  (11431, 1)\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:51,740 WARNING Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject40\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject40\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject41.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11515, 12, 1)\n",
      "y_test.shape:  (11515, 1)\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:21:57,566 WARNING Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject41\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject41\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject42.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11435, 12, 1)\n",
      "y_test.shape:  (11435, 1)\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:22:03,512 WARNING Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject42\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject42\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject43.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11396, 12, 1)\n",
      "y_test.shape:  (11396, 1)\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:22:09,533 WARNING Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject43\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject43\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject44.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10069, 12, 1)\n",
      "y_test.shape:  (10069, 1)\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:22:15,399 WARNING Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject44\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject44\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'diatrend_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\fold5_training',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'ohio_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                                '2020\\\\fold5_training',\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\mixed.py',\n",
      "                   't1dexi_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\fold5_training',\n",
      "                   'test_fraction': 0,\n",
      "                   'train_fraction': 0.8,\n",
      "                   'valid_fraction': 0.2},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': '1e-3',\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "loading training data for all patients ...\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 01:23:54,338 WARNING Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2025-02-03 01:23:54,443 WARNING `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 788187 samples, validate on 196997 samples\n",
      "Epoch 1/10000\n",
      "784384/788187 [============================>.] - ETA: 0s - loss: 0.1260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788187/788187 [==============================] - 13s 16us/sample - loss: 0.1254 - val_loss: -0.0671\n",
      "Epoch 2/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.0139 - val_loss: -0.1180\n",
      "Epoch 3/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.0518 - val_loss: -0.1118\n",
      "Epoch 4/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.0743 - val_loss: -0.1304\n",
      "Epoch 5/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.0928 - val_loss: -0.1499\n",
      "Epoch 6/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1078 - val_loss: -0.1409\n",
      "Epoch 7/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1181 - val_loss: -0.1540\n",
      "Epoch 8/10000\n",
      "788187/788187 [==============================] - 9s 12us/sample - loss: -0.1269 - val_loss: -0.1567\n",
      "Epoch 9/10000\n",
      "788187/788187 [==============================] - 9s 12us/sample - loss: -0.1342 - val_loss: -0.1532\n",
      "Epoch 10/10000\n",
      "788187/788187 [==============================] - 9s 12us/sample - loss: -0.1390 - val_loss: -0.1609\n",
      "Epoch 11/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1439 - val_loss: -0.1643\n",
      "Epoch 12/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1464 - val_loss: -0.1654\n",
      "Epoch 13/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1491 - val_loss: -0.1669\n",
      "Epoch 14/10000\n",
      "788187/788187 [==============================] - 9s 12us/sample - loss: -0.1509 - val_loss: -0.1656\n",
      "Epoch 15/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1518 - val_loss: -0.1701\n",
      "Epoch 16/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1537 - val_loss: -0.1596\n",
      "Epoch 17/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1557 - val_loss: -0.1720\n",
      "Epoch 18/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1557 - val_loss: -0.1722\n",
      "Epoch 19/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1573 - val_loss: -0.1675\n",
      "Epoch 20/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1574 - val_loss: -0.1743\n",
      "Epoch 21/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1582 - val_loss: -0.1613\n",
      "Epoch 22/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1593 - val_loss: -0.1676\n",
      "Epoch 23/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1595 - val_loss: -0.1745\n",
      "Epoch 24/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1602 - val_loss: -0.1782\n",
      "Epoch 25/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1614 - val_loss: -0.1719\n",
      "Epoch 26/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1608 - val_loss: -0.1791\n",
      "Epoch 27/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1620 - val_loss: -0.1684\n",
      "Epoch 28/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1622 - val_loss: -0.1741\n",
      "Epoch 29/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1631 - val_loss: -0.1811\n",
      "Epoch 30/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1632 - val_loss: -0.1689\n",
      "Epoch 31/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1627 - val_loss: -0.1800\n",
      "Epoch 32/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1645 - val_loss: -0.1798\n",
      "Epoch 33/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1649 - val_loss: -0.1804\n",
      "Epoch 34/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1649 - val_loss: -0.1818\n",
      "Epoch 35/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1652 - val_loss: -0.1808\n",
      "Epoch 36/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1657 - val_loss: -0.1805\n",
      "Epoch 37/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1661 - val_loss: -0.1712\n",
      "Epoch 38/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1661 - val_loss: -0.1774\n",
      "Epoch 39/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1660 - val_loss: -0.1773\n",
      "Epoch 40/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1674 - val_loss: -0.1780\n",
      "Epoch 41/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1663 - val_loss: -0.1772\n",
      "Epoch 42/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1683 - val_loss: -0.1819\n",
      "Epoch 43/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1675 - val_loss: -0.1755\n",
      "Epoch 44/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1676 - val_loss: -0.1778\n",
      "Epoch 45/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1670 - val_loss: -0.1817\n",
      "Epoch 46/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1691 - val_loss: -0.1791\n",
      "Epoch 47/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1691 - val_loss: -0.1765\n",
      "Epoch 48/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1685 - val_loss: -0.1721\n",
      "Epoch 49/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1690 - val_loss: -0.1766\n",
      "Epoch 50/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1694 - val_loss: -0.1808\n",
      "Epoch 51/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1694 - val_loss: -0.1783\n",
      "Epoch 52/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1711 - val_loss: -0.1796\n",
      "Epoch 53/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1698 - val_loss: -0.1808\n",
      "Epoch 54/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1699 - val_loss: -0.1795\n",
      "Epoch 55/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1709 - val_loss: -0.1788\n",
      "Epoch 56/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1710 - val_loss: -0.1798\n",
      "Epoch 57/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1706 - val_loss: -0.1804\n",
      "Epoch 58/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1712 - val_loss: -0.1794\n",
      "Epoch 59/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1719 - val_loss: -0.1669\n",
      "Epoch 60/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1715 - val_loss: -0.1824\n",
      "Epoch 61/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1729 - val_loss: -0.1819\n",
      "Epoch 62/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1714 - val_loss: -0.1754\n",
      "Epoch 63/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1727 - val_loss: -0.1772\n",
      "Epoch 64/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1721 - val_loss: -0.1790\n",
      "Epoch 65/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1729 - val_loss: -0.1699\n",
      "Epoch 66/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1731 - val_loss: -0.1783\n",
      "Epoch 67/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1735 - val_loss: -0.1832\n",
      "Epoch 68/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1735 - val_loss: -0.1762\n",
      "Epoch 69/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1739 - val_loss: -0.1791\n",
      "Epoch 70/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1742 - val_loss: -0.1798\n",
      "Epoch 71/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1746 - val_loss: -0.1804\n",
      "Epoch 72/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1749 - val_loss: -0.1756\n",
      "Epoch 73/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1745 - val_loss: -0.1846\n",
      "Epoch 74/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1746 - val_loss: -0.1801\n",
      "Epoch 75/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1748 - val_loss: -0.1807\n",
      "Epoch 76/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1747 - val_loss: -0.1795\n",
      "Epoch 77/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1753 - val_loss: -0.1835\n",
      "Epoch 78/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1756 - val_loss: -0.1798\n",
      "Epoch 79/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1763 - val_loss: -0.1775\n",
      "Epoch 80/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1774 - val_loss: -0.1848\n",
      "Epoch 81/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1770 - val_loss: -0.1711\n",
      "Epoch 82/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1758 - val_loss: -0.1803\n",
      "Epoch 83/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1770 - val_loss: -0.1801\n",
      "Epoch 84/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1770 - val_loss: -0.1798\n",
      "Epoch 85/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1780 - val_loss: -0.1807\n",
      "Epoch 86/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1767 - val_loss: -0.1809\n",
      "Epoch 87/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1781 - val_loss: -0.1759\n",
      "Epoch 88/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1788 - val_loss: -0.1822\n",
      "Epoch 89/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1784 - val_loss: -0.1768\n",
      "Epoch 90/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1784 - val_loss: -0.1781\n",
      "Epoch 91/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1792 - val_loss: -0.1827\n",
      "Epoch 92/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1784 - val_loss: -0.1758\n",
      "Epoch 93/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1791 - val_loss: -0.1783\n",
      "Epoch 94/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1794 - val_loss: -0.1727\n",
      "Epoch 95/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1795 - val_loss: -0.1773\n",
      "Epoch 96/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1803 - val_loss: -0.1791\n",
      "Epoch 97/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1804 - val_loss: -0.1760\n",
      "Epoch 98/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1800 - val_loss: -0.1834\n",
      "Epoch 99/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1804 - val_loss: -0.1784\n",
      "Epoch 100/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1811 - val_loss: -0.1816\n",
      "Epoch 101/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1812 - val_loss: -0.1838\n",
      "Epoch 102/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1819 - val_loss: -0.1797\n",
      "Epoch 103/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1817 - val_loss: -0.1791\n",
      "Epoch 104/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1823 - val_loss: -0.1802\n",
      "Epoch 105/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1829 - val_loss: -0.1817\n",
      "Epoch 106/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1825 - val_loss: -0.1804\n",
      "Epoch 107/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1828 - val_loss: -0.1788\n",
      "Epoch 108/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1832 - val_loss: -0.1806\n",
      "Epoch 109/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1830 - val_loss: -0.1764\n",
      "Epoch 110/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1839 - val_loss: -0.1801\n",
      "Epoch 111/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1845 - val_loss: -0.1781\n",
      "Epoch 112/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1843 - val_loss: -0.1785\n",
      "Epoch 113/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1843 - val_loss: -0.1792\n",
      "Epoch 114/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1857 - val_loss: -0.1788\n",
      "Epoch 115/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1856 - val_loss: -0.1733\n",
      "Epoch 116/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1858 - val_loss: -0.1754\n",
      "Epoch 117/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1858 - val_loss: -0.1793\n",
      "Epoch 118/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1864 - val_loss: -0.1780\n",
      "Epoch 119/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1865 - val_loss: -0.1733\n",
      "Epoch 120/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1867 - val_loss: -0.1750\n",
      "Epoch 121/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1873 - val_loss: -0.1778\n",
      "Epoch 122/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1880 - val_loss: -0.1789\n",
      "Epoch 123/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1873 - val_loss: -0.1793\n",
      "Epoch 124/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1883 - val_loss: -0.1744\n",
      "Epoch 125/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1891 - val_loss: -0.1746\n",
      "Epoch 126/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1884 - val_loss: -0.1796\n",
      "Epoch 127/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1892 - val_loss: -0.1778\n",
      "Epoch 128/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1897 - val_loss: -0.1755\n",
      "Epoch 129/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1894 - val_loss: -0.1766\n",
      "Epoch 130/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1898 - val_loss: -0.1775\n",
      "Epoch 131/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1907 - val_loss: -0.1769\n",
      "Epoch 132/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1908 - val_loss: -0.1769\n",
      "Epoch 133/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1908 - val_loss: -0.1786\n",
      "Epoch 134/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1908 - val_loss: -0.1702\n",
      "Epoch 135/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1919 - val_loss: -0.1707\n",
      "Epoch 136/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1922 - val_loss: -0.1736\n",
      "Epoch 137/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1930 - val_loss: -0.1751\n",
      "Epoch 138/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1923 - val_loss: -0.1708\n",
      "Epoch 139/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1932 - val_loss: -0.1746\n",
      "Epoch 140/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.1935 - val_loss: -0.1720\n",
      "Epoch 141/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1935 - val_loss: -0.1682\n",
      "Epoch 142/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1943 - val_loss: -0.1719\n",
      "Epoch 143/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.1947 - val_loss: -0.1745\n",
      "Epoch 144/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1945 - val_loss: -0.1708\n",
      "Epoch 145/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1951 - val_loss: -0.1729\n",
      "Epoch 146/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1959 - val_loss: -0.1737\n",
      "Epoch 147/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1957 - val_loss: -0.1575\n",
      "Epoch 148/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1965 - val_loss: -0.1695\n",
      "Epoch 149/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1961 - val_loss: -0.1694\n",
      "Epoch 150/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1964 - val_loss: -0.1677\n",
      "Epoch 151/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.1976 - val_loss: -0.1716\n",
      "Epoch 152/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1978 - val_loss: -0.1647\n",
      "Epoch 153/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1987 - val_loss: -0.1679\n",
      "Epoch 154/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1989 - val_loss: -0.1707\n",
      "Epoch 155/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1998 - val_loss: -0.1649\n",
      "Epoch 156/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2000 - val_loss: -0.1713\n",
      "Epoch 157/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.1996 - val_loss: -0.1650\n",
      "Epoch 158/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2003 - val_loss: -0.1683\n",
      "Epoch 159/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2005 - val_loss: -0.1625\n",
      "Epoch 160/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2007 - val_loss: -0.1676\n",
      "Epoch 161/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2016 - val_loss: -0.1607\n",
      "Epoch 162/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2024 - val_loss: -0.1616\n",
      "Epoch 163/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2024 - val_loss: -0.1645\n",
      "Epoch 164/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2029 - val_loss: -0.1640\n",
      "Epoch 165/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2034 - val_loss: -0.1563\n",
      "Epoch 166/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2038 - val_loss: -0.1644\n",
      "Epoch 167/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2040 - val_loss: -0.1643\n",
      "Epoch 168/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2047 - val_loss: -0.1626\n",
      "Epoch 169/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2054 - val_loss: -0.1546\n",
      "Epoch 170/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2051 - val_loss: -0.1645\n",
      "Epoch 171/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2064 - val_loss: -0.1661\n",
      "Epoch 172/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2051 - val_loss: -0.1568\n",
      "Epoch 173/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2074 - val_loss: -0.1606\n",
      "Epoch 174/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2069 - val_loss: -0.1585\n",
      "Epoch 175/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2078 - val_loss: -0.1638\n",
      "Epoch 176/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2082 - val_loss: -0.1547\n",
      "Epoch 177/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2094 - val_loss: -0.1562\n",
      "Epoch 178/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2090 - val_loss: -0.1510\n",
      "Epoch 179/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2097 - val_loss: -0.1621\n",
      "Epoch 180/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2099 - val_loss: -0.1514\n",
      "Epoch 181/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2099 - val_loss: -0.1575\n",
      "Epoch 182/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2112 - val_loss: -0.1554\n",
      "Epoch 183/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2108 - val_loss: -0.1554\n",
      "Epoch 184/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2118 - val_loss: -0.1526\n",
      "Epoch 185/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2122 - val_loss: -0.1541\n",
      "Epoch 186/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2125 - val_loss: -0.1552\n",
      "Epoch 187/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2130 - val_loss: -0.1555\n",
      "Epoch 188/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2138 - val_loss: -0.1511\n",
      "Epoch 189/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2141 - val_loss: -0.1496\n",
      "Epoch 190/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2140 - val_loss: -0.1449\n",
      "Epoch 191/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2149 - val_loss: -0.1486\n",
      "Epoch 192/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2157 - val_loss: -0.1562\n",
      "Epoch 193/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2158 - val_loss: -0.1516\n",
      "Epoch 194/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2170 - val_loss: -0.1445\n",
      "Epoch 195/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2173 - val_loss: -0.1484\n",
      "Epoch 196/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2177 - val_loss: -0.1539\n",
      "Epoch 197/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2179 - val_loss: -0.1416\n",
      "Epoch 198/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2186 - val_loss: -0.1369\n",
      "Epoch 199/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2178 - val_loss: -0.1492\n",
      "Epoch 200/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2193 - val_loss: -0.1422\n",
      "Epoch 201/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2206 - val_loss: -0.1487\n",
      "Epoch 202/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2207 - val_loss: -0.1436\n",
      "Epoch 203/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2208 - val_loss: -0.1480\n",
      "Epoch 204/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2211 - val_loss: -0.1455\n",
      "Epoch 205/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2218 - val_loss: -0.1415\n",
      "Epoch 206/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2227 - val_loss: -0.1414\n",
      "Epoch 207/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2224 - val_loss: -0.1467\n",
      "Epoch 208/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2228 - val_loss: -0.1436\n",
      "Epoch 209/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2237 - val_loss: -0.1397\n",
      "Epoch 210/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2241 - val_loss: -0.1377\n",
      "Epoch 211/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2247 - val_loss: -0.1398\n",
      "Epoch 212/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2257 - val_loss: -0.1441\n",
      "Epoch 213/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2252 - val_loss: -0.1358\n",
      "Epoch 214/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2262 - val_loss: -0.1404\n",
      "Epoch 215/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2258 - val_loss: -0.1383\n",
      "Epoch 216/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2274 - val_loss: -0.1392\n",
      "Epoch 217/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2276 - val_loss: -0.1377\n",
      "Epoch 218/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2282 - val_loss: -0.1363\n",
      "Epoch 219/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2280 - val_loss: -0.1349\n",
      "Epoch 220/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2290 - val_loss: -0.1344\n",
      "Epoch 221/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2295 - val_loss: -0.1312\n",
      "Epoch 222/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2291 - val_loss: -0.1302\n",
      "Epoch 223/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2308 - val_loss: -0.1358\n",
      "Epoch 224/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2314 - val_loss: -0.1376\n",
      "Epoch 225/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2318 - val_loss: -0.1355\n",
      "Epoch 226/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2326 - val_loss: -0.1368\n",
      "Epoch 227/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2318 - val_loss: -0.1334\n",
      "Epoch 228/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2332 - val_loss: -0.1282\n",
      "Epoch 229/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2320 - val_loss: -0.1225\n",
      "Epoch 230/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2347 - val_loss: -0.1344\n",
      "Epoch 231/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2342 - val_loss: -0.1256\n",
      "Epoch 232/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2351 - val_loss: -0.1324\n",
      "Epoch 233/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2347 - val_loss: -0.1285\n",
      "Epoch 234/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2352 - val_loss: -0.1230\n",
      "Epoch 235/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2355 - val_loss: -0.1244\n",
      "Epoch 236/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2369 - val_loss: -0.1344\n",
      "Epoch 237/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2371 - val_loss: -0.1216\n",
      "Epoch 238/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2374 - val_loss: -0.1297\n",
      "Epoch 239/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2387 - val_loss: -0.1282\n",
      "Epoch 240/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2374 - val_loss: -0.1233\n",
      "Epoch 241/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2394 - val_loss: -0.1197\n",
      "Epoch 242/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2400 - val_loss: -0.1184\n",
      "Epoch 243/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2407 - val_loss: -0.1202\n",
      "Epoch 244/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2407 - val_loss: -0.1231\n",
      "Epoch 245/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2409 - val_loss: -0.1185\n",
      "Epoch 246/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2404 - val_loss: -0.1219\n",
      "Epoch 247/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2412 - val_loss: -0.1196\n",
      "Epoch 248/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2428 - val_loss: -0.1227\n",
      "Epoch 249/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2433 - val_loss: -0.1200\n",
      "Epoch 250/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2439 - val_loss: -0.1168\n",
      "Epoch 251/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2448 - val_loss: -0.1100\n",
      "Epoch 252/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2449 - val_loss: -0.1167\n",
      "Epoch 253/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2450 - val_loss: -0.1146\n",
      "Epoch 254/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2447 - val_loss: -0.1157\n",
      "Epoch 255/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2461 - val_loss: -0.1124\n",
      "Epoch 256/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2462 - val_loss: -0.1116\n",
      "Epoch 257/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2472 - val_loss: -0.1120\n",
      "Epoch 258/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2470 - val_loss: -0.1101\n",
      "Epoch 259/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2485 - val_loss: -0.1086\n",
      "Epoch 260/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2483 - val_loss: -0.1105\n",
      "Epoch 261/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2492 - val_loss: -0.1079\n",
      "Epoch 262/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2494 - val_loss: -0.1033\n",
      "Epoch 263/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2507 - val_loss: -0.1118\n",
      "Epoch 264/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2499 - val_loss: -0.1052\n",
      "Epoch 265/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2513 - val_loss: -0.1160\n",
      "Epoch 266/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2513 - val_loss: -0.1016\n",
      "Epoch 267/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2516 - val_loss: -0.1023\n",
      "Epoch 268/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2522 - val_loss: -0.1140\n",
      "Epoch 269/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2531 - val_loss: -0.1065\n",
      "Epoch 270/10000\n",
      "788187/788187 [==============================] - 10s 12us/sample - loss: -0.2522 - val_loss: -0.1070\n",
      "Epoch 271/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2526 - val_loss: -0.1032\n",
      "Epoch 272/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2551 - val_loss: -0.1055\n",
      "Epoch 273/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2542 - val_loss: -0.1026\n",
      "Epoch 274/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2551 - val_loss: -0.0992\n",
      "Epoch 275/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2564 - val_loss: -0.1053\n",
      "Epoch 276/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2554 - val_loss: -0.0962\n",
      "Epoch 277/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2557 - val_loss: -0.1002\n",
      "Epoch 278/10000\n",
      "788187/788187 [==============================] - 10s 13us/sample - loss: -0.2572 - val_loss: -0.1006\n",
      "Epoch 279/10000\n",
      "788187/788187 [==============================] - 11s 14us/sample - loss: -0.2562 - val_loss: -0.1026\n",
      "Epoch 280/10000\n",
      "788187/788187 [==============================] - 11s 13us/sample - loss: -0.2569 - val_loss: -0.0985\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1484.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5854, 12, 1)\n",
      "y_test.shape:  (5854, 1)\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:13,028 WARNING Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1484\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1484\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1503.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7813, 12, 1)\n",
      "y_test.shape:  (7813, 1)\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:18,299 WARNING Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1503\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1503\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1554.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7953, 12, 1)\n",
      "y_test.shape:  (7953, 1)\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:23,770 WARNING Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1554\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1554\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1558.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (6694, 12, 1)\n",
      "y_test.shape:  (6694, 1)\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:29,175 WARNING Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1558\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1558\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1636.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7349, 12, 1)\n",
      "y_test.shape:  (7349, 1)\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:34,322 WARNING Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1636\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1636\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1650.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7644, 12, 1)\n",
      "y_test.shape:  (7644, 1)\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:39,450 WARNING Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1650\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1650\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1683.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7649, 12, 1)\n",
      "y_test.shape:  (7649, 1)\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:44,755 WARNING Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1683\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1683\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1689.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7844, 12, 1)\n",
      "y_test.shape:  (7844, 1)\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:50,192 WARNING Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1689\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1689\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1695.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7563, 12, 1)\n",
      "y_test.shape:  (7563, 1)\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:11:55,818 WARNING Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1695\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1695\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1722.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7897, 12, 1)\n",
      "y_test.shape:  (7897, 1)\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:01,205 WARNING Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1722\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1722\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_t1dexi_subset\\\\T1DEXI_cgm_processed\\\\1726.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\t1dexi.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7856, 12, 1)\n",
      "y_test.shape:  (7856, 1)\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:06,640 WARNING Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 1726\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  1726\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\588-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (15219, 12, 1)\n",
      "y_test.shape:  (15219, 1)\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:11,948 WARNING Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 588\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  588\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\591-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13090, 12, 1)\n",
      "y_test.shape:  (13090, 1)\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:19,034 WARNING Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 591\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  591\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\596-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13076, 12, 1)\n",
      "y_test.shape:  (13076, 1)\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:25,332 WARNING Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 596\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n",
      "patient id:  596\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject45.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11105, 12, 1)\n",
      "y_test.shape:  (11105, 1)\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:31,962 WARNING Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject45\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject45\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject46.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11395, 12, 1)\n",
      "y_test.shape:  (11395, 1)\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:38,488 WARNING Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject46\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject46\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject47.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11655, 12, 1)\n",
      "y_test.shape:  (11655, 1)\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:45,021 WARNING Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject47\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject47\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject48.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (11726, 12, 1)\n",
      "y_test.shape:  (11726, 1)\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:51,544 WARNING Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject48\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject48\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject49.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (10707, 12, 1)\n",
      "y_test.shape:  (10707, 1)\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:12:58,167 WARNING Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject49\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject49\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject50.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (5496, 12, 1)\n",
      "y_test.shape:  (5496, 1)\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:13:04,612 WARNING Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject50\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject50\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject51.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (8813, 12, 1)\n",
      "y_test.shape:  (8813, 1)\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:13:09,686 WARNING Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject51\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject51\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject53.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (8847, 12, 1)\n",
      "y_test.shape:  (8847, 1)\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:13:15,400 WARNING Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject53\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject53\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'csv_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\modified_diatrend_subset\\\\processed_cgm_data_Subject54.csv',\n",
      "                   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 12,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\diatrend.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_12sh\\\\nb_future_steps_6_seed_10_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [10],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 10,\n",
      "                 'shuffle': True}}\n",
      "x_train.shape:  (0, 12, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 12, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (7913, 12, 1)\n",
      "y_test.shape:  (7913, 1)\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-02-03 02:13:21,267 WARNING Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: Subject54\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_12sh\\nb_future_steps_6_seed_10_\\model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiyi\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient id:  Subject54\n"
     ]
    }
   ],
   "source": [
    "# Experiment training - 1 fold, 60 min sampling horizon\n",
    "for fold_number in range(1, 6):\n",
    "    yaml_filepath = f\"./mixed_dataset_60min/all_final_experiment_fold{fold_number}.yaml\"\n",
    "    mode = \"train\"\n",
    "\n",
    "    cfgs = load_cfgs(yaml_filepath)\n",
    "    print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "    for cfg in cfgs:\n",
    "        seed = int(cfg['train']['seed'])\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Print the configuration - just to make sure that you loaded what you\n",
    "        # wanted to load\n",
    "\n",
    "        module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "        module_model         = load_module(cfg['model']['script_path'])\n",
    "        module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "        module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "        module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(cfg)\n",
    "\n",
    "        #print(\"loading dataset ...\")\n",
    "        #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "        #nb_past_steps_tmp = 36\n",
    "        #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "        #x_train = x_train[:,-nb_past_steps:,:]\n",
    "        #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "        #x_test = x_test[:,-nb_past_steps:,:]\n",
    "        # print(\"x_train.shape: \", x_train.shape)\n",
    "        # print(\"y_train.shape: \", y_train.shape)\n",
    "        # print(\"x_valid.shape: \", x_valid.shape)\n",
    "        # print(\"y_valid.shape: \", y_valid.shape)\n",
    "        # print(\"x_test.shape: \", x_test.shape)\n",
    "        # print(\"y_test.shape: \", y_test.shape)\n",
    "        \n",
    "        #print(\"loading optimizer ...\")\n",
    "        optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "\n",
    "        #print(\"loading loss function ...\")\n",
    "        loss_function = module_loss_function.load()\n",
    "        #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "        #print(\"loading model ...\")\n",
    "        if 'tf_nll' in loss_function.__name__:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1]*2,\n",
    "                cfg['model']\n",
    "            )\n",
    "        else:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1],\n",
    "                cfg['model']\n",
    "            )\n",
    "\n",
    "        if 'initial_weights_path' in cfg['train']:\n",
    "            #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "            model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_function\n",
    "        )\n",
    "\n",
    "        #print(model.summary())\n",
    "\n",
    "        # training mode\n",
    "        if mode == 'train':\n",
    "            #print(\"training model ...\")\n",
    "            train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "        if mode == 'plot_nll':\n",
    "            plot_nll(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_noise_experiment':\n",
    "            plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_seg':\n",
    "            plot_seg(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_dist':\n",
    "            plot_target_distribution(y_test, cfg)\n",
    "\n",
    "        # evaluation mode\n",
    "        if mode == 'evaluate':\n",
    "            evaluate(model, x_test, y_test, cfg)\n",
    "    # Evaluation\n",
    "    yaml_files = glob.glob(f\"./mixed_dataset_60min/fold{fold_number}_eval/*.yaml\")\n",
    "    mode = \"evaluate\"\n",
    "    for yaml_fp in yaml_files:\n",
    "        cfgs = load_cfgs(yaml_fp)\n",
    "        print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "        for cfg in cfgs:\n",
    "            seed = int(cfg['train']['seed'])\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            # Print the configuration - just to make sure that you loaded what you\n",
    "            # wanted to load\n",
    "\n",
    "            module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "            module_model         = load_module(cfg['model']['script_path'])\n",
    "            module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "            module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "            module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "            pp = pprint.PrettyPrinter(indent=4)\n",
    "            pp.pprint(cfg)\n",
    "\n",
    "            #print(\"loading dataset ...\")\n",
    "            #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "            #nb_past_steps_tmp = 36\n",
    "            #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "            x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "            #x_train = x_train[:,-nb_past_steps:,:]\n",
    "            #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "            #x_test = x_test[:,-nb_past_steps:,:]\n",
    "            print(\"x_train.shape: \", x_train.shape)\n",
    "            print(\"y_train.shape: \", y_train.shape)\n",
    "            print(\"x_valid.shape: \", x_valid.shape)\n",
    "            print(\"y_valid.shape: \", y_valid.shape)\n",
    "            print(\"x_test.shape: \", x_test.shape)\n",
    "            print(\"y_test.shape: \", y_test.shape)\n",
    "            #print(\"loading optimizer ...\")\n",
    "            optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "            #print(\"loading loss function ...\")\n",
    "            loss_function = module_loss_function.load()\n",
    "            #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "            #print(\"loading model ...\")\n",
    "            if 'tf_nll' in loss_function.__name__:\n",
    "                model = module_model.load(\n",
    "                    x_train.shape[1:],\n",
    "                    y_train.shape[1]*2,\n",
    "                    cfg['model']\n",
    "                )\n",
    "            else:\n",
    "                model = module_model.load(\n",
    "                    x_train.shape[1:],\n",
    "                    y_train.shape[1],\n",
    "                    cfg['model']\n",
    "                )\n",
    "\n",
    "            if 'initial_weights_path' in cfg['train']:\n",
    "                #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "                model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss_function\n",
    "            )\n",
    "\n",
    "            #print(model.summary())\n",
    "\n",
    "            # training mode\n",
    "            if mode == 'train':\n",
    "                #print(\"training model ...\")\n",
    "                train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "            if mode == 'plot_nll':\n",
    "                plot_nll(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_noise_experiment':\n",
    "                plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_seg':\n",
    "                plot_seg(model, x_test, y_test, cfg)\n",
    "            if mode == 'plot_dist':\n",
    "                plot_target_distribution(y_test, cfg)\n",
    "\n",
    "            # evaluation mode\n",
    "            if mode == 'evaluate':\n",
    "                evaluate(model, x_test, y_test, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mixed_dataset_30min/fold5_eval\\\\588-ws-combined_evaluation.yaml',\n",
       " './mixed_dataset_30min/fold5_eval\\\\591-ws-combined_evaluation.yaml',\n",
       " './mixed_dataset_30min/fold5_eval\\\\596-ws-combined_evaluation.yaml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "yaml_files = [f for f in glob.glob(f\"./mixed_dataset_30min/fold{fold_number}_eval/*.yaml\") if re.search(r'\\d+-ws-combined_evaluation\\.yaml$', f)]\n",
    "yaml_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./mixed_dataset_30min/fold5_eval\\\\588-ws-combined_evaluation.yaml',\n",
       " './mixed_dataset_30min/fold5_eval\\\\591-ws-combined_evaluation.yaml',\n",
       " './mixed_dataset_30min/fold5_eval\\\\596-ws-combined_evaluation.yaml']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_files = [f for f in glob.glob(f\"./mixed_dataset_30min/fold5_eval/*.yaml\") if re.search(r'\\d+-ws-combined_evaluation\\.yaml$', f)]\n",
    "mode = \"evaluate\"\n",
    "yaml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\588-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_6sh\\\\nb_future_steps_6_seed_50_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [50],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 50,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (15291, 6, 1)\n",
      "y_test.shape:  (15291, 1)\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-30 11:03:42,771 WARNING Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 588\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_6sh\\nb_future_steps_6_seed_50_\\model.hdf5\n",
      "patient id:  588\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\591-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_6sh\\\\nb_future_steps_6_seed_50_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [50],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 50,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13270, 6, 1)\n",
      "y_test.shape:  (13270, 1)\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-30 11:03:49,511 WARNING Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 591\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_6sh\\nb_future_steps_6_seed_50_\\model.hdf5\n",
      "patient id:  591\n",
      "Running 1 experiments.\n",
      "{   'dataset': {   'nb_future_steps': 6,\n",
      "                   'nb_past_steps': 6,\n",
      "                   'param_nb_future_steps': [6],\n",
      "                   'scale': 0.01,\n",
      "                   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\datasets\\\\ohio.py',\n",
      "                   'test_fraction': 1.0,\n",
      "                   'train_fraction': 0.0,\n",
      "                   'valid_fraction': 0.0,\n",
      "                   'xml_path': 'C:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\Modify_GenBG\\\\OhioT1DM '\n",
      "                               '2020\\\\596-ws-combined.xml'},\n",
      "    'loss_function': {   'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\loss_functions\\\\nll_keras.py'},\n",
      "    'model': {   'activation_function': 'exp',\n",
      "                 'nb_lstm_states': 256,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\models\\\\lstm_experiment_keras.py'},\n",
      "    'optimizer': {   'learning_rate': 0.001,\n",
      "                     'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\optimizers\\\\adam_keras.py'},\n",
      "    'train': {   'artifacts_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\artifacts\\\\mixed_dataset_6sh\\\\nb_future_steps_6_seed_50_',\n",
      "                 'batch_size': 1024,\n",
      "                 'epochs': 10000,\n",
      "                 'param_seed': [50],\n",
      "                 'patience': 200,\n",
      "                 'script_path': 'c:\\\\Users\\\\baiyi\\\\OneDrive\\\\Desktop\\\\ReproGenBG_ML4H\\\\MartinssonAndvanDoorn\\\\train\\\\train_keras.py',\n",
      "                 'seed': 50,\n",
      "                 'shuffle': True}}\n",
      "nb_future_steps  6\n",
      "x_train.shape:  (0, 6, 1)\n",
      "y_train.shape:  (0, 1)\n",
      "x_valid.shape:  (0, 6, 1)\n",
      "y_valid.shape:  (0, 1)\n",
      "x_test.shape:  (13262, 6, 1)\n",
      "y_test.shape:  (13262, 1)\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-30 11:03:56,086 WARNING Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Evaluating for patient_id: 596\n",
      "loading weights: c:\\Users\\baiyi\\OneDrive\\Desktop\\ReproGenBG_ML4H\\MartinssonAndvanDoorn\\artifacts\\mixed_dataset_6sh\\nb_future_steps_6_seed_50_\\model.hdf5\n",
      "patient id:  596\n"
     ]
    }
   ],
   "source": [
    "for yaml_fp in yaml_files:\n",
    "    cfgs = load_cfgs(yaml_fp)\n",
    "    print(\"Running {} experiments.\".format(len(cfgs)))\n",
    "    for cfg in cfgs:\n",
    "        seed = int(cfg['train']['seed'])\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Print the configuration - just to make sure that you loaded what you\n",
    "        # wanted to load\n",
    "\n",
    "        module_dataset       = load_module(cfg['dataset']['script_path'])\n",
    "        module_model         = load_module(cfg['model']['script_path'])\n",
    "        module_optimizer     = load_module(cfg['optimizer']['script_path'])\n",
    "        module_loss_function = load_module(cfg['loss_function']['script_path'])\n",
    "        module_train         = load_module(cfg['train']['script_path'])\n",
    "\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(cfg)\n",
    "\n",
    "        #print(\"loading dataset ...\")\n",
    "        #nb_past_steps = cfg['dataset']['nb_past_steps']\n",
    "        #nb_past_steps_tmp = 36\n",
    "        #cfg['dataset']['nb_past_steps'] = nb_past_steps_tmp\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = module_dataset.load_dataset(cfg['dataset'])\n",
    "        #x_train = x_train[:,-nb_past_steps:,:]\n",
    "        #x_valid = x_valid[:,-nb_past_steps:,:]\n",
    "        #x_test = x_test[:,-nb_past_steps:,:]\n",
    "        print(\"x_train.shape: \", x_train.shape)\n",
    "        print(\"y_train.shape: \", y_train.shape)\n",
    "        print(\"x_valid.shape: \", x_valid.shape)\n",
    "        print(\"y_valid.shape: \", y_valid.shape)\n",
    "        print(\"x_test.shape: \", x_test.shape)\n",
    "        print(\"y_test.shape: \", y_test.shape)\n",
    "        #print(\"loading optimizer ...\")\n",
    "        optimizer = module_optimizer.load(cfg['optimizer'])\n",
    "\n",
    "        #print(\"loading loss function ...\")\n",
    "        loss_function = module_loss_function.load()\n",
    "        #print(\"loaded function {} ...\".format(loss_function.__name__))\n",
    "\n",
    "        #print(\"loading model ...\")\n",
    "        if 'tf_nll' in loss_function.__name__:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1]*2,\n",
    "                cfg['model']\n",
    "            )\n",
    "        else:\n",
    "            model = module_model.load(\n",
    "                x_train.shape[1:],\n",
    "                y_train.shape[1],\n",
    "                cfg['model']\n",
    "            )\n",
    "\n",
    "        if 'initial_weights_path' in cfg['train']:\n",
    "            #print(\"Loading initial weights: \", cfg['train']['initial_weights_path'])\n",
    "            model.load_weights(cfg['train']['initial_weights_path'])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_function\n",
    "        )\n",
    "\n",
    "        #print(model.summary())\n",
    "\n",
    "        # training mode\n",
    "        if mode == 'train':\n",
    "            #print(\"training model ...\")\n",
    "            train(model, module_train, x_train, y_train, x_valid, y_valid, cfg)\n",
    "        if mode == 'plot_nll':\n",
    "            plot_nll(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_noise_experiment':\n",
    "            plot_noise_experiment(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_seg':\n",
    "            plot_seg(model, x_test, y_test, cfg)\n",
    "        if mode == 'plot_dist':\n",
    "            plot_target_distribution(y_test, cfg)\n",
    "\n",
    "        # evaluation mode\n",
    "        if mode == 'evaluate':\n",
    "            evaluate(model, x_test, y_test, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
