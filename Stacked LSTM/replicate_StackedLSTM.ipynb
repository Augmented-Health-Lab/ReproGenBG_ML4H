{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up_to_nearest_five_minutes(ts):\n",
    "    # Parse the timestamp\n",
    "    dt = datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "    \n",
    "    # Calculate minutes to add to round up to the nearest 5 minutes\n",
    "    minutes_to_add = (5 - dt.minute % 5) % 5\n",
    "    if minutes_to_add == 0 and dt.second == 0:\n",
    "        # If exactly on a 5 minute mark and second is 0, no need to add time\n",
    "        minutes_to_add = 0\n",
    "    \n",
    "    # Add the necessary minutes\n",
    "    new_dt = dt + timedelta(minutes=minutes_to_add)\n",
    "    \n",
    "    # Return the new timestamp in the same format\n",
    "    return new_dt.strftime( \"%d-%m-%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set the \n",
    "def read_ohio(filepath, category, round):\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "    # interval_timedelta = datetime.timedelta(minutes=interval_timedelta)\n",
    "\n",
    "    res = []\n",
    "    for item in root.findall(category):\n",
    "        entry0 = item[0].attrib\n",
    "        if round == True:\n",
    "            adjusted_ts = round_up_to_nearest_five_minutes(entry0['ts'])\n",
    "            entry0['ts'] = adjusted_ts\n",
    "        ts = entry0['ts']\n",
    "        entry0['ts'] = datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "        res.append([entry0])\n",
    "        for i in range(1, len(item)):\n",
    "            # last_entry = item[i - 1].attrib\n",
    "            entry = item[i].attrib\n",
    "            # t1 = datetime.datetime.strptime(entry[\"ts\"], \"%d-%m-%Y %H:%M:%S\")\n",
    "            # t0 = datetime.datetime.strptime(last_entry[\"ts\"], \"%d-%m-%Y %H:%M:%S\")\n",
    "            # delt = t1 - t0\n",
    "            # if category == \"glucose_level\":\n",
    "            #     if delt <= interval_timedelta:\n",
    "            #         res[-1].append([entry])\n",
    "            #     else:\n",
    "            #         res.append([entry])\n",
    "            # else:\n",
    "            ts = entry['ts']\n",
    "            if round == True:\n",
    "                adjusted_ts = round_up_to_nearest_five_minutes(ts)\n",
    "                entry['ts'] = adjusted_ts\n",
    "            ts = entry['ts']\n",
    "            entry['ts'] = datetime.strptime(ts, \"%d-%m-%Y %H:%M:%S\")\n",
    "            res.append([entry])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_into_table(glucose):\n",
    "    glucose_dict = {entry[0]['ts']: entry[0]['value'] for entry in glucose}\n",
    "\n",
    "    # Create the multi-channel database\n",
    "    g_data = []\n",
    "    for timestamp in glucose_dict:\n",
    "        record = {\n",
    "            'timestamp': timestamp,\n",
    "            'glucose_value': glucose_dict[timestamp],\n",
    "            # 'meal_type': None,\n",
    "            # 'meal_carbs': 0\n",
    "        }\n",
    "        \n",
    "        g_data.append(record)\n",
    "\n",
    "    # Create DataFrame\n",
    "    glucose_df = pd.DataFrame(g_data)\n",
    "\n",
    "    # Convert glucose values to numeric type for analysis\n",
    "    glucose_df['glucose_value'] = pd.to_numeric(glucose_df['glucose_value'])\n",
    "    glucose_df['glucose_value'] = glucose_df['glucose_value'] / 100 # Shrink to its 1/100 for scaling\n",
    "\n",
    "    return glucose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segement_data_as_15min(data):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Calculate time differences\n",
    "    df['time_diff'] = df['timestamp'].diff()\n",
    "\n",
    "    # Identify large gaps\n",
    "    df['new_segment'] = df['time_diff'] > pd.Timedelta(minutes=15)\n",
    "\n",
    "    # Find indices where new segments start\n",
    "    segment_starts = df[df['new_segment']].index\n",
    "\n",
    "    # Initialize an empty dictionary to store segments\n",
    "    segments = {}\n",
    "    prev_index = 0\n",
    "\n",
    "    # Loop through each segment start and slice the DataFrame accordingly\n",
    "    for i, start in enumerate(segment_starts, 1):\n",
    "        segments[f'segment_{i}'] = df.iloc[prev_index:start].reset_index(drop=True)\n",
    "        prev_index = start\n",
    "\n",
    "    # Add the last segment from the last gap to the end of the DataFrame\n",
    "    segments[f'segment_{len(segment_starts) + 1}'] = df.iloc[prev_index:].reset_index(drop=True)\n",
    "\n",
    "    # Optionally remove helper columns from each segment\n",
    "    for segment in segments.values():\n",
    "        segment.drop(columns=['time_diff', 'new_segment'], inplace=True)\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align and update segments with meal data\n",
    "def find_closest_glucose_index(glucose_df, meal_time, threshold_seconds=300):\n",
    "    time_diffs = (glucose_df['timestamp'] - meal_time).abs()\n",
    "    within_threshold = time_diffs < pd.Timedelta(seconds=threshold_seconds)\n",
    "    if within_threshold.any():\n",
    "        closest_index = time_diffs[within_threshold].idxmin()\n",
    "        return closest_index\n",
    "    return None\n",
    "\n",
    "def update_segments_with_meals(segments, meal_df):\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        # Initialize the 'carbs' column to zeros\n",
    "        segment_df['carbs'] = 0\n",
    "\n",
    "        for index, meal_row in meal_df.iterrows():\n",
    "            meal_time = meal_row['ts']\n",
    "            closest_glucose_idx = find_closest_glucose_index(segment_df, meal_time)\n",
    "            \n",
    "            if closest_glucose_idx is not None:\n",
    "                segment_df.loc[closest_glucose_idx, 'carbs'] = int(meal_row['carbs'])/100\n",
    "                meal_df.loc[index, 'assigned'] = True\n",
    "\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"C:/Users/username/OneDrive/Desktop/BGprediction/OhioT1DM/2018/train/570-ws-training.xml\"\n",
    "glucose = read_ohio(filepath, \"glucose_level\", True)\n",
    "glucose_df = transfer_into_table(glucose)\n",
    "segments = segement_data_as_15min(glucose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>glucose_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07 16:30:00</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07 16:35:00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07 16:40:00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-07 16:45:00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-07 16:50:00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2021-12-07 21:55:00</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2021-12-07 22:00:00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2021-12-07 22:05:00</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2021-12-07 22:10:00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2021-12-07 22:15:00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  glucose_value\n",
       "0  2021-12-07 16:30:00           1.01\n",
       "1  2021-12-07 16:35:00           1.00\n",
       "2  2021-12-07 16:40:00           1.00\n",
       "3  2021-12-07 16:45:00           0.99\n",
       "4  2021-12-07 16:50:00           0.98\n",
       "..                 ...            ...\n",
       "65 2021-12-07 21:55:00           1.44\n",
       "66 2021-12-07 22:00:00           1.40\n",
       "67 2021-12-07 22:05:00           1.39\n",
       "68 2021-12-07 22:10:00           1.40\n",
       "69 2021-12-07 22:15:00           1.40\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[\"segment_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process meal logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_glucose_index(glucose_df, meal_time, threshold_seconds=300):\n",
    "    time_diffs = (glucose_df['timestamp'] - meal_time).abs()\n",
    "    within_threshold = time_diffs < pd.Timedelta(seconds=threshold_seconds)\n",
    "    if within_threshold.any():\n",
    "        closest_index = time_diffs[within_threshold].idxmin()\n",
    "        return closest_index\n",
    "    return None\n",
    "\n",
    "def update_segments_with_meals(segments, meal_df):\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        # Initialize the 'carbs' column to zeros\n",
    "        segment_df['carb_effect'] = 0\n",
    "\n",
    "        for index, meal_row in meal_df.iterrows():\n",
    "            meal_time = meal_row['ts']\n",
    "            closest_glucose_idx = find_closest_glucose_index(segment_df, meal_time)\n",
    "            \n",
    "            if closest_glucose_idx is not None:\n",
    "                segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
    "                meal_df.loc[index, 'assigned'] = True\n",
    "\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include meal:\n",
    "meal = read_ohio(filepath, \"meal\", True)\n",
    "flattened_meal_data = [item[0] for item in meal]  # Take the first (and only) item from each sublist\n",
    "# Convert to DataFrame\n",
    "meal_df = pd.DataFrame(flattened_meal_data)\n",
    "meal_df['assigned'] = False\n",
    "# Update the segments with meal data\n",
    "# meal_updated_segments = update_segments_with_meals(interpolated_segements, meal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_meal_entry(meal_row):\n",
    "    meal_time = meal_row['ts']\n",
    "    end_effect_time = meal_time + timedelta(hours=3)\n",
    "    carb = float(meal_row['carbs'])\n",
    "\n",
    "    c_eff_list = [0, 0, 0, ]\n",
    "\n",
    "    for i in range(1, 10):\n",
    "        c_eff = (i * 0.111) * carb\n",
    "        if c_eff > carb:\n",
    "            print(\"C_eff > carb\")\n",
    "            c_eff = carb\n",
    "        c_eff_list.append(c_eff)\n",
    "\n",
    "    for j in range(1, 25):\n",
    "        c_eff = (1 - (j * 0.028)) * carb\n",
    "        if c_eff < 0:\n",
    "            print(\"C_eff < 0\")\n",
    "            c_eff = 0\n",
    "        c_eff_list.append(c_eff)\n",
    "\n",
    "    timestamp_list = pd.date_range(start=meal_time, end=end_effect_time, freq='5min')\n",
    "    d = {\"ts\": timestamp_list[:-1], \"carb_effect\": c_eff_list}\n",
    "    meal_effect_df = pd.DataFrame(data = d)\n",
    "\n",
    "    return meal_effect_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_d = {\"ts\": [], \"carb_effect\": []}\n",
    "whole_meal_effect_df = pd.DataFrame(data = empty_d)\n",
    "\n",
    "for index, meal_row in meal_df.iterrows():\n",
    "    meal_effect_df = expand_meal_entry(meal_row)\n",
    "\n",
    "    # Merge the DataFrames on the 'ts' column with an outer join\n",
    "    merged_df = pd.merge(whole_meal_effect_df, meal_effect_df, on='ts', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Fill NaN values with 0 for the carb_effect columns\n",
    "    merged_df['carb_effect_df1'] = merged_df['carb_effect_df1'].fillna(0)\n",
    "    merged_df['carb_effect_df2'] = merged_df['carb_effect_df2'].fillna(0)\n",
    "\n",
    "    # Sum the carb_effect values\n",
    "    merged_df['carb_effect'] = merged_df['carb_effect_df1'] + merged_df['carb_effect_df2']\n",
    "\n",
    "    # Keep only the required columns\n",
    "    whole_meal_effect_df = merged_df[['ts', 'carb_effect']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\3730447383.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whole_meal_effect_df['assigned'] = False\n"
     ]
    }
   ],
   "source": [
    "whole_meal_effect_df['assigned'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.6719917669411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(whole_meal_effect_df['carb_effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.35' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.45' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.55' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.7' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.05' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.55' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.65' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.65' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.15' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\2117006920.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'carb_effect'] = int(meal_row['carb_effect'])/20\n"
     ]
    }
   ],
   "source": [
    "# Need to make it align with the CGM data\n",
    "meal_updated_segments = update_segments_with_meals(segments, whole_meal_effect_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process bolus info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ohio_bolus_tempbasal(filepath, category, round):\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "    # interval_timedelta = datetime.timedelta(minutes=interval_timedelta)\n",
    "\n",
    "    res = []\n",
    "    for item in root.findall(category):\n",
    "        if len(item) == 0:\n",
    "            continue  # Skip if the item has no children\n",
    "            \n",
    "        entry0 = item[0].attrib\n",
    "        if round == True:\n",
    "            adjusted_ts = round_up_to_nearest_five_minutes(entry0['ts_begin'])\n",
    "            entry0['ts_begin'] = adjusted_ts\n",
    "            adjusted_ts = round_up_to_nearest_five_minutes(entry0['ts_end'])\n",
    "            entry0['ts_end'] = adjusted_ts\n",
    "        \n",
    "        entry0['ts_begin'] = datetime.strptime(entry0['ts_begin'], \"%d-%m-%Y %H:%M:%S\")\n",
    "        entry0['ts_end'] = datetime.strptime(entry0['ts_end'], \"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "        res.append([entry0])\n",
    "        for i in range(1, len(item)):\n",
    "            # last_entry = item[i - 1].attrib\n",
    "            entry = item[i].attrib\n",
    "            ts_begin = entry['ts_begin']\n",
    "            ts_end = entry['ts_end']\n",
    "            if round == True:\n",
    "                adjusted_ts_begin = round_up_to_nearest_five_minutes(ts_begin)\n",
    "                entry['ts_end'] = adjusted_ts_begin\n",
    "                adjusted_ts_end = round_up_to_nearest_five_minutes(ts_end)\n",
    "                entry['ts_end'] = adjusted_ts_end\n",
    "            entry['ts_begin'] = datetime.strptime(entry['ts_begin'], \"%d-%m-%Y %H:%M:%S\")\n",
    "            entry['ts_end'] = datetime.strptime(entry['ts_end'], \"%d-%m-%Y %H:%M:%S\")\n",
    "            if category == \"bolus\":\n",
    "                if entry['ts_begin'] != entry['ts_end']:\n",
    "                    print(\"Unequal: begin: \" + str(entry['ts_begin']) + \"end: \" + str(entry['ts_end']))\n",
    "            res.append([entry])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unequal: begin: 2021-12-07 07:41:58end: 2021-12-07 08:15:58\n",
      "Unequal: begin: 2021-12-07 18:31:52end: 2021-12-07 18:35:52\n",
      "Unequal: begin: 2021-12-07 18:34:32end: 2021-12-07 19:05:32\n",
      "Unequal: begin: 2021-12-07 22:19:46end: 2021-12-07 22:20:46\n",
      "Unequal: begin: 2021-12-08 06:14:22end: 2021-12-08 06:15:22\n",
      "Unequal: begin: 2021-12-08 06:18:52end: 2021-12-08 06:50:52\n",
      "Unequal: begin: 2021-12-08 12:04:11end: 2021-12-08 12:05:11\n",
      "Unequal: begin: 2021-12-08 12:09:16end: 2021-12-08 12:40:16\n",
      "Unequal: begin: 2021-12-08 15:46:52end: 2021-12-08 15:50:52\n",
      "Unequal: begin: 2021-12-08 16:48:48end: 2021-12-08 16:50:48\n",
      "Unequal: begin: 2021-12-08 16:50:52end: 2021-12-08 17:20:52\n",
      "Unequal: begin: 2021-12-08 19:21:27end: 2021-12-08 19:25:27\n",
      "Unequal: begin: 2021-12-08 19:26:31end: 2021-12-08 20:00:31\n",
      "Unequal: begin: 2021-12-08 21:34:33end: 2021-12-08 21:35:33\n",
      "Unequal: begin: 2021-12-08 21:36:59end: 2021-12-08 22:10:59\n",
      "Unequal: begin: 2021-12-09 05:24:38end: 2021-12-09 05:25:38\n",
      "Unequal: begin: 2021-12-09 06:24:44end: 2021-12-09 06:25:44\n",
      "Unequal: begin: 2021-12-09 06:29:18end: 2021-12-09 07:00:18\n",
      "Unequal: begin: 2021-12-09 10:11:33end: 2021-12-09 10:15:33\n",
      "Unequal: begin: 2021-12-09 12:04:48end: 2021-12-09 12:35:48\n",
      "Unequal: begin: 2021-12-09 19:37:51end: 2021-12-09 19:40:51\n",
      "Unequal: begin: 2021-12-09 19:42:56end: 2021-12-09 20:15:56\n",
      "Unequal: begin: 2021-12-10 06:06:15end: 2021-12-10 06:10:15\n",
      "Unequal: begin: 2021-12-10 06:11:17end: 2021-12-10 06:45:17\n",
      "Unequal: begin: 2021-12-10 13:26:23end: 2021-12-10 13:30:23\n",
      "Unequal: begin: 2021-12-10 13:31:26end: 2021-12-10 14:05:26\n",
      "Unequal: begin: 2021-12-10 19:59:05end: 2021-12-10 20:30:05\n",
      "Unequal: begin: 2021-12-11 07:46:08end: 2021-12-11 07:50:08\n",
      "Unequal: begin: 2021-12-11 09:23:05end: 2021-12-11 09:25:05\n",
      "Unequal: begin: 2021-12-11 09:26:02end: 2021-12-11 10:00:02\n",
      "Unequal: begin: 2021-12-11 16:52:21end: 2021-12-11 16:55:21\n",
      "Unequal: begin: 2021-12-11 16:57:23end: 2021-12-11 17:30:23\n",
      "Unequal: begin: 2021-12-11 20:17:48end: 2021-12-11 20:20:48\n",
      "Unequal: begin: 2021-12-11 20:20:42end: 2021-12-11 20:50:42\n",
      "Unequal: begin: 2021-12-12 08:31:32end: 2021-12-12 08:35:32\n",
      "Unequal: begin: 2021-12-12 10:07:10end: 2021-12-12 10:45:13\n",
      "Unequal: begin: 2021-12-12 10:12:13end: 2021-12-12 10:45:13\n",
      "Unequal: begin: 2021-12-12 15:12:00end: 2021-12-12 16:15:00\n",
      "Unequal: begin: 2021-12-12 21:14:03end: 2021-12-12 21:15:03\n",
      "Unequal: begin: 2021-12-12 21:17:05end: 2021-12-12 21:50:05\n",
      "Unequal: begin: 2021-12-13 05:11:01end: 2021-12-13 05:15:01\n",
      "Unequal: begin: 2021-12-13 06:16:50end: 2021-12-13 06:20:50\n",
      "Unequal: begin: 2021-12-13 06:21:52end: 2021-12-13 06:55:52\n",
      "Unequal: begin: 2021-12-13 12:27:03end: 2021-12-13 12:30:03\n",
      "Unequal: begin: 2021-12-13 12:29:16end: 2021-12-13 13:00:16\n",
      "Unequal: begin: 2021-12-13 15:29:01end: 2021-12-13 15:30:01\n",
      "Unequal: begin: 2021-12-13 15:34:03end: 2021-12-13 16:05:03\n",
      "Unequal: begin: 2021-12-13 20:52:15end: 2021-12-13 20:55:15\n",
      "Unequal: begin: 2021-12-13 20:56:26end: 2021-12-13 21:30:26\n",
      "Unequal: begin: 2021-12-14 05:12:47end: 2021-12-14 05:15:47\n",
      "Unequal: begin: 2021-12-14 06:09:03end: 2021-12-14 06:10:03\n",
      "Unequal: begin: 2021-12-14 06:14:06end: 2021-12-14 06:45:06\n",
      "Unequal: begin: 2021-12-14 13:56:22end: 2021-12-14 14:00:22\n",
      "Unequal: begin: 2021-12-14 14:00:37end: 2021-12-14 14:30:37\n",
      "Unequal: begin: 2021-12-14 15:45:30end: 2021-12-14 16:20:14\n",
      "Unequal: begin: 2021-12-14 15:49:14end: 2021-12-14 16:20:14\n",
      "Unequal: begin: 2021-12-14 18:39:57end: 2021-12-14 19:40:57\n",
      "Unequal: begin: 2021-12-15 05:28:46end: 2021-12-15 05:30:46\n",
      "Unequal: begin: 2021-12-15 06:32:54end: 2021-12-15 06:35:54\n",
      "Unequal: begin: 2021-12-15 06:37:56end: 2021-12-15 07:10:56\n",
      "Unequal: begin: 2021-12-15 11:34:07end: 2021-12-15 11:35:07\n",
      "Unequal: begin: 2021-12-15 11:39:12end: 2021-12-15 12:10:12\n",
      "Unequal: begin: 2021-12-15 15:57:50end: 2021-12-15 16:00:50\n",
      "Unequal: begin: 2021-12-15 16:52:43end: 2021-12-15 16:55:43\n",
      "Unequal: begin: 2021-12-15 16:56:37end: 2021-12-15 17:30:37\n",
      "Unequal: begin: 2021-12-15 18:27:55end: 2021-12-15 18:30:55\n",
      "Unequal: begin: 2021-12-15 18:32:21end: 2021-12-15 19:05:21\n",
      "Unequal: begin: 2021-12-16 05:12:19end: 2021-12-16 05:15:19\n",
      "Unequal: begin: 2021-12-16 06:15:10end: 2021-12-16 06:45:10\n",
      "Unequal: begin: 2021-12-16 11:53:07end: 2021-12-16 11:55:07\n",
      "Unequal: begin: 2021-12-16 11:56:02end: 2021-12-16 12:30:02\n",
      "Unequal: begin: 2021-12-16 18:26:16end: 2021-12-16 18:30:16\n",
      "Unequal: begin: 2021-12-16 18:29:23end: 2021-12-16 19:00:23\n",
      "Unequal: begin: 2021-12-17 07:42:52end: 2021-12-17 07:45:52\n",
      "Unequal: begin: 2021-12-17 07:46:50end: 2021-12-17 08:20:50\n",
      "Unequal: begin: 2021-12-17 12:35:57end: 2021-12-17 13:15:01\n",
      "Unequal: begin: 2021-12-17 12:41:01end: 2021-12-17 13:15:01\n",
      "Unequal: begin: 2021-12-17 19:05:33end: 2021-12-17 20:05:33\n",
      "Unequal: begin: 2021-12-17 21:04:57end: 2021-12-17 21:35:57\n",
      "Unequal: begin: 2021-12-17 23:01:26end: 2021-12-17 23:05:26\n",
      "Unequal: begin: 2021-12-18 09:29:32end: 2021-12-18 09:30:32\n",
      "Unequal: begin: 2021-12-18 09:33:12end: 2021-12-18 10:05:12\n",
      "Unequal: begin: 2021-12-18 20:09:02end: 2021-12-18 20:45:06\n",
      "Unequal: begin: 2021-12-18 20:14:06end: 2021-12-18 20:45:06\n",
      "Unequal: begin: 2021-12-18 22:14:25end: 2021-12-18 22:45:25\n",
      "Unequal: begin: 2021-12-19 09:20:59end: 2021-12-19 09:50:59\n",
      "Unequal: begin: 2021-12-19 13:28:42end: 2021-12-19 14:05:03\n",
      "Unequal: begin: 2021-12-19 13:32:03end: 2021-12-19 14:05:03\n",
      "Unequal: begin: 2021-12-19 18:13:06end: 2021-12-19 19:15:06\n",
      "Unequal: begin: 2021-12-19 21:01:50end: 2021-12-19 21:05:50\n",
      "Unequal: begin: 2021-12-19 21:04:18end: 2021-12-19 21:35:18\n",
      "Unequal: begin: 2021-12-20 07:22:25end: 2021-12-20 07:25:25\n",
      "Unequal: begin: 2021-12-20 08:42:38end: 2021-12-20 08:45:38\n",
      "Unequal: begin: 2021-12-20 08:45:30end: 2021-12-20 09:15:30\n",
      "Unequal: begin: 2021-12-20 16:14:59end: 2021-12-20 16:15:59\n",
      "Unequal: begin: 2021-12-20 16:16:59end: 2021-12-20 16:50:59\n",
      "Unequal: begin: 2021-12-20 19:11:11end: 2021-12-20 19:15:11\n",
      "Unequal: begin: 2021-12-20 19:15:59end: 2021-12-20 19:45:59\n",
      "Unequal: begin: 2021-12-21 05:11:07end: 2021-12-21 05:15:07\n",
      "Unequal: begin: 2021-12-21 06:16:21end: 2021-12-21 06:50:21\n",
      "Unequal: begin: 2021-12-21 06:30:16end: 2021-12-21 07:00:16\n",
      "Unequal: begin: 2021-12-21 12:17:37end: 2021-12-21 12:20:37\n",
      "Unequal: begin: 2021-12-21 12:19:15end: 2021-12-21 12:50:15\n",
      "Unequal: begin: 2021-12-21 13:28:37end: 2021-12-21 13:30:37\n",
      "Unequal: begin: 2021-12-21 13:30:53end: 2021-12-21 14:00:53\n",
      "Unequal: begin: 2021-12-21 16:39:20end: 2021-12-21 17:10:20\n",
      "Unequal: begin: 2021-12-21 19:25:44end: 2021-12-21 20:00:36\n",
      "Unequal: begin: 2021-12-21 19:28:36end: 2021-12-21 20:00:36\n",
      "Unequal: begin: 2021-12-21 19:42:00end: 2021-12-21 20:15:00\n",
      "Unequal: begin: 2021-12-22 05:07:41end: 2021-12-22 05:10:41\n",
      "Unequal: begin: 2021-12-22 07:53:32end: 2021-12-22 08:25:32\n",
      "Unequal: begin: 2021-12-22 11:58:32end: 2021-12-22 12:00:32\n",
      "Unequal: begin: 2021-12-22 12:03:27end: 2021-12-22 12:35:27\n",
      "Unequal: begin: 2021-12-22 17:51:56end: 2021-12-22 17:55:56\n",
      "Unequal: begin: 2021-12-22 17:56:44end: 2021-12-22 18:30:44\n",
      "Unequal: begin: 2021-12-23 05:22:20end: 2021-12-23 05:25:20\n",
      "Unequal: begin: 2021-12-23 06:13:27end: 2021-12-23 06:15:27\n",
      "Unequal: begin: 2021-12-23 06:18:31end: 2021-12-23 06:50:31\n",
      "Unequal: begin: 2021-12-23 11:38:12end: 2021-12-23 12:15:50\n",
      "Unequal: begin: 2021-12-23 11:42:50end: 2021-12-23 12:15:50\n",
      "Unequal: begin: 2021-12-23 12:08:36end: 2021-12-23 12:40:36\n",
      "Unequal: begin: 2021-12-23 15:22:57end: 2021-12-23 15:25:57\n",
      "Unequal: begin: 2021-12-23 15:28:02end: 2021-12-23 16:00:02\n",
      "Unequal: begin: 2021-12-23 19:21:42end: 2021-12-23 19:25:42\n",
      "Unequal: begin: 2021-12-23 19:26:15end: 2021-12-23 20:00:15\n",
      "Unequal: begin: 2021-12-23 20:58:39end: 2021-12-23 21:00:39\n",
      "Unequal: begin: 2021-12-23 21:00:03end: 2021-12-23 21:30:03\n",
      "Unequal: begin: 2021-12-24 06:58:41end: 2021-12-24 07:00:41\n",
      "Unequal: begin: 2021-12-24 07:34:16end: 2021-12-24 08:05:16\n",
      "Unequal: begin: 2021-12-24 13:13:21end: 2021-12-24 13:15:21\n",
      "Unequal: begin: 2021-12-24 13:17:04end: 2021-12-24 13:50:04\n",
      "Unequal: begin: 2021-12-24 18:39:32end: 2021-12-24 18:40:32\n",
      "Unequal: begin: 2021-12-24 18:44:36end: 2021-12-24 19:15:36\n",
      "Unequal: begin: 2021-12-25 00:37:21end: 2021-12-25 00:40:21\n",
      "Unequal: begin: 2021-12-25 00:40:57end: 2021-12-25 01:10:57\n",
      "Unequal: begin: 2021-12-25 10:07:11end: 2021-12-25 10:10:11\n",
      "Unequal: begin: 2021-12-25 10:12:13end: 2021-12-25 10:45:13\n",
      "Unequal: begin: 2021-12-25 18:57:49end: 2021-12-25 19:00:49\n",
      "Unequal: begin: 2021-12-25 19:01:31end: 2021-12-25 19:35:31\n",
      "Unequal: begin: 2021-12-25 21:41:56end: 2021-12-25 21:45:56\n",
      "Unequal: begin: 2021-12-25 21:44:51end: 2021-12-25 22:15:51\n",
      "Unequal: begin: 2021-12-26 09:55:09end: 2021-12-26 10:25:09\n",
      "Unequal: begin: 2021-12-26 19:54:35end: 2021-12-26 19:55:35\n",
      "Unequal: begin: 2021-12-26 20:41:04end: 2021-12-26 21:45:04\n",
      "Unequal: begin: 2021-12-26 20:53:42end: 2021-12-26 21:25:42\n",
      "Unequal: begin: 2021-12-27 08:36:10end: 2021-12-27 08:40:10\n",
      "Unequal: begin: 2021-12-27 08:40:45end: 2021-12-27 09:10:45\n",
      "Unequal: begin: 2021-12-27 15:09:28end: 2021-12-27 15:45:50\n",
      "Unequal: begin: 2021-12-27 15:12:50end: 2021-12-27 15:45:50\n",
      "Unequal: begin: 2021-12-27 15:22:13end: 2021-12-27 15:55:13\n",
      "Unequal: begin: 2021-12-27 18:16:19end: 2021-12-27 19:20:19\n",
      "Unequal: begin: 2021-12-27 21:13:04end: 2021-12-27 21:15:04\n",
      "Unequal: begin: 2021-12-27 21:15:58end: 2021-12-27 21:45:58\n",
      "Unequal: begin: 2021-12-28 06:11:20end: 2021-12-28 06:15:20\n",
      "Unequal: begin: 2021-12-28 06:16:24end: 2021-12-28 06:50:24\n",
      "Unequal: begin: 2021-12-28 11:50:43end: 2021-12-28 12:20:43\n",
      "Unequal: begin: 2021-12-28 15:43:38end: 2021-12-28 15:45:38\n",
      "Unequal: begin: 2021-12-28 19:17:04end: 2021-12-28 19:20:04\n",
      "Unequal: begin: 2021-12-28 19:22:08end: 2021-12-28 19:55:08\n",
      "Unequal: begin: 2021-12-29 07:08:12end: 2021-12-29 07:10:12\n",
      "Unequal: begin: 2021-12-29 07:51:02end: 2021-12-29 07:55:02\n",
      "Unequal: begin: 2021-12-29 07:53:38end: 2021-12-29 08:25:38\n",
      "Unequal: begin: 2021-12-29 12:33:36end: 2021-12-29 13:10:18\n",
      "Unequal: begin: 2021-12-29 12:37:18end: 2021-12-29 13:10:18\n",
      "Unequal: begin: 2021-12-29 16:11:32end: 2021-12-29 16:45:32\n",
      "Unequal: begin: 2021-12-29 18:46:58end: 2021-12-29 18:50:58\n",
      "Unequal: begin: 2021-12-29 18:50:44end: 2021-12-29 19:20:44\n",
      "Unequal: begin: 2021-12-30 08:07:38end: 2021-12-30 08:10:38\n",
      "Unequal: begin: 2021-12-30 08:12:26end: 2021-12-30 08:45:26\n",
      "Unequal: begin: 2021-12-30 12:47:47end: 2021-12-30 12:50:47\n",
      "Unequal: begin: 2021-12-30 12:52:52end: 2021-12-30 13:25:52\n",
      "Unequal: begin: 2021-12-30 20:18:31end: 2021-12-30 20:20:31\n",
      "Unequal: begin: 2021-12-30 20:23:32end: 2021-12-30 20:55:32\n",
      "Unequal: begin: 2021-12-30 20:33:51end: 2021-12-30 20:35:51\n",
      "Unequal: begin: 2021-12-30 20:36:25end: 2021-12-30 21:10:25\n",
      "Unequal: begin: 2021-12-31 06:21:40end: 2021-12-31 06:25:40\n",
      "Unequal: begin: 2021-12-31 06:26:43end: 2021-12-31 07:00:43\n",
      "Unequal: begin: 2021-12-31 10:17:14end: 2021-12-31 10:20:14\n",
      "Unequal: begin: 2021-12-31 10:19:42end: 2021-12-31 10:50:42\n",
      "Unequal: begin: 2021-12-31 12:09:13end: 2021-12-31 12:10:13\n",
      "Unequal: begin: 2021-12-31 12:14:17end: 2021-12-31 12:45:17\n",
      "Unequal: begin: 2021-12-31 21:01:46end: 2021-12-31 21:05:46\n",
      "Unequal: begin: 2021-12-31 21:06:49end: 2021-12-31 21:40:49\n",
      "Unequal: begin: 2022-01-01 07:54:15end: 2022-01-01 07:55:15\n",
      "Unequal: begin: 2022-01-01 10:09:44end: 2022-01-01 10:10:44\n",
      "Unequal: begin: 2022-01-01 10:13:11end: 2022-01-01 10:45:11\n",
      "Unequal: begin: 2022-01-01 13:51:30end: 2022-01-01 13:55:30\n",
      "Unequal: begin: 2022-01-01 13:56:34end: 2022-01-01 15:00:34\n",
      "Unequal: begin: 2022-01-01 19:39:09end: 2022-01-01 20:10:09\n",
      "Unequal: begin: 2022-01-01 22:34:07end: 2022-01-01 22:35:07\n",
      "Unequal: begin: 2022-01-02 09:44:45end: 2022-01-02 09:45:45\n",
      "Unequal: begin: 2022-01-02 09:49:49end: 2022-01-02 10:20:49\n",
      "Unequal: begin: 2022-01-02 14:51:41end: 2022-01-02 14:55:41\n",
      "Unequal: begin: 2022-01-02 14:54:40end: 2022-01-02 15:25:40\n",
      "Unequal: begin: 2022-01-02 17:54:52end: 2022-01-02 17:55:52\n",
      "Unequal: begin: 2022-01-02 17:59:07end: 2022-01-02 18:30:07\n",
      "Unequal: begin: 2022-01-02 21:21:47end: 2022-01-02 21:25:47\n",
      "Unequal: begin: 2022-01-02 21:25:59end: 2022-01-02 21:55:59\n",
      "Unequal: begin: 2022-01-03 05:14:50end: 2022-01-03 05:15:50\n",
      "Unequal: begin: 2022-01-03 06:11:02end: 2022-01-03 06:15:02\n",
      "Unequal: begin: 2022-01-03 06:16:04end: 2022-01-03 06:50:04\n",
      "Unequal: begin: 2022-01-03 11:40:22end: 2022-01-03 12:10:22\n",
      "Unequal: begin: 2022-01-03 16:04:42end: 2022-01-03 16:05:42\n",
      "Unequal: begin: 2022-01-03 16:09:44end: 2022-01-03 16:40:44\n",
      "Unequal: begin: 2022-01-03 19:06:15end: 2022-01-03 19:10:15\n",
      "Unequal: begin: 2022-01-03 19:11:03end: 2022-01-03 20:15:03\n",
      "Unequal: begin: 2022-01-04 00:54:21end: 2022-01-04 00:55:21\n",
      "Unequal: begin: 2022-01-04 05:01:56end: 2022-01-04 05:05:56\n",
      "Unequal: begin: 2022-01-04 06:10:46end: 2022-01-04 06:40:46\n",
      "Unequal: begin: 2022-01-04 11:23:17end: 2022-01-04 11:25:17\n",
      "Unequal: begin: 2022-01-04 11:28:21end: 2022-01-04 12:00:21\n",
      "Unequal: begin: 2022-01-04 19:57:50end: 2022-01-04 20:00:50\n",
      "Unequal: begin: 2022-01-04 20:02:54end: 2022-01-04 20:35:54\n",
      "Unequal: begin: 2022-01-05 05:20:13end: 2022-01-05 05:50:13\n",
      "Unequal: begin: 2022-01-05 09:21:36end: 2022-01-05 09:25:36\n",
      "Unequal: begin: 2022-01-05 12:39:14end: 2022-01-05 12:40:14\n",
      "Unequal: begin: 2022-01-05 12:42:24end: 2022-01-05 13:15:24\n",
      "Unequal: begin: 2022-01-05 15:48:58end: 2022-01-05 15:50:58\n",
      "Unequal: begin: 2022-01-05 20:29:21end: 2022-01-05 20:30:21\n",
      "Unequal: begin: 2022-01-05 20:33:31end: 2022-01-05 21:05:31\n",
      "Unequal: begin: 2022-01-06 05:29:04end: 2022-01-06 05:30:04\n",
      "Unequal: begin: 2022-01-06 06:24:55end: 2022-01-06 06:25:55\n",
      "Unequal: begin: 2022-01-06 06:29:58end: 2022-01-06 07:00:58\n",
      "Unequal: begin: 2022-01-06 09:47:03end: 2022-01-06 09:50:03\n",
      "Unequal: begin: 2022-01-06 11:51:51end: 2022-01-06 11:55:51\n",
      "Unequal: begin: 2022-01-06 11:56:55end: 2022-01-06 12:30:55\n",
      "Unequal: begin: 2022-01-06 15:26:31end: 2022-01-06 15:30:31\n",
      "Unequal: begin: 2022-01-06 19:28:05end: 2022-01-06 19:30:05\n",
      "Unequal: begin: 2022-01-06 19:33:10end: 2022-01-06 20:05:10\n",
      "Unequal: begin: 2022-01-07 08:01:04end: 2022-01-07 08:05:04\n",
      "Unequal: begin: 2022-01-07 08:06:06end: 2022-01-07 08:40:06\n",
      "Unequal: begin: 2022-01-07 14:28:19end: 2022-01-07 14:30:19\n",
      "Unequal: begin: 2022-01-07 14:33:21end: 2022-01-07 15:05:21\n",
      "Unequal: begin: 2022-01-07 21:57:49end: 2022-01-07 22:00:49\n",
      "Unequal: begin: 2022-01-07 22:02:53end: 2022-01-07 22:35:53\n",
      "Unequal: begin: 2022-01-08 06:21:43end: 2022-01-08 06:25:43\n",
      "Unequal: begin: 2022-01-08 08:56:24end: 2022-01-08 09:00:24\n",
      "Unequal: begin: 2022-01-08 09:01:27end: 2022-01-08 09:35:27\n",
      "Unequal: begin: 2022-01-08 13:21:47end: 2022-01-08 14:00:08\n",
      "Unequal: begin: 2022-01-08 13:26:08end: 2022-01-08 14:00:08\n",
      "Unequal: begin: 2022-01-08 13:32:41end: 2022-01-08 14:05:41\n",
      "Unequal: begin: 2022-01-08 19:13:15end: 2022-01-08 19:45:15\n",
      "Unequal: begin: 2022-01-08 19:41:55end: 2022-01-08 20:15:55\n",
      "Unequal: begin: 2022-01-09 06:03:34end: 2022-01-09 06:05:34\n",
      "Unequal: begin: 2022-01-09 09:18:08end: 2022-01-09 09:20:08\n",
      "Unequal: begin: 2022-01-09 09:21:38end: 2022-01-09 09:55:38\n",
      "Unequal: begin: 2022-01-09 19:04:46end: 2022-01-09 19:05:46\n",
      "Unequal: begin: 2022-01-09 21:13:25end: 2022-01-09 21:15:25\n",
      "Unequal: begin: 2022-01-09 21:18:29end: 2022-01-09 21:50:29\n",
      "Unequal: begin: 2022-01-10 05:22:31end: 2022-01-10 05:25:31\n",
      "Unequal: begin: 2022-01-10 06:23:09end: 2022-01-10 06:25:09\n",
      "Unequal: begin: 2022-01-10 06:28:11end: 2022-01-10 07:00:11\n",
      "Unequal: begin: 2022-01-10 11:29:49end: 2022-01-10 11:30:49\n",
      "Unequal: begin: 2022-01-10 11:34:53end: 2022-01-10 12:05:53\n",
      "Unequal: begin: 2022-01-10 14:33:02end: 2022-01-10 14:35:02\n",
      "Unequal: begin: 2022-01-10 14:34:50end: 2022-01-10 15:05:50\n",
      "Unequal: begin: 2022-01-10 18:02:17end: 2022-01-10 18:05:17\n",
      "Unequal: begin: 2022-01-10 18:07:22end: 2022-01-10 19:10:22\n",
      "Unequal: begin: 2022-01-10 21:42:06end: 2022-01-10 21:45:06\n",
      "Unequal: begin: 2022-01-11 05:03:08end: 2022-01-11 05:05:08\n",
      "Unequal: begin: 2022-01-11 06:04:48end: 2022-01-11 06:35:48\n",
      "Unequal: begin: 2022-01-11 12:34:09end: 2022-01-11 12:35:09\n",
      "Unequal: begin: 2022-01-11 12:38:35end: 2022-01-11 13:10:35\n",
      "Unequal: begin: 2022-01-11 18:21:19end: 2022-01-11 18:25:19\n",
      "Unequal: begin: 2022-01-11 18:49:20end: 2022-01-11 19:50:20\n",
      "Unequal: begin: 2022-01-12 05:26:37end: 2022-01-12 05:30:37\n",
      "Unequal: begin: 2022-01-12 08:56:38end: 2022-01-12 09:00:38\n",
      "Unequal: begin: 2022-01-12 09:00:25end: 2022-01-12 09:30:25\n",
      "Unequal: begin: 2022-01-12 12:28:05end: 2022-01-12 12:30:05\n",
      "Unequal: begin: 2022-01-12 12:33:07end: 2022-01-12 13:05:07\n",
      "Unequal: begin: 2022-01-12 18:40:57end: 2022-01-12 19:10:57\n",
      "Unequal: begin: 2022-01-13 05:09:54end: 2022-01-13 05:10:54\n",
      "Unequal: begin: 2022-01-13 06:12:17end: 2022-01-13 06:15:17\n",
      "Unequal: begin: 2022-01-13 06:17:20end: 2022-01-13 06:50:20\n",
      "Unequal: begin: 2022-01-13 11:31:32end: 2022-01-13 11:35:32\n",
      "Unequal: begin: 2022-01-13 11:36:36end: 2022-01-13 12:10:36\n",
      "Unequal: begin: 2022-01-13 20:21:36end: 2022-01-13 20:25:36\n",
      "Unequal: begin: 2022-01-13 20:26:40end: 2022-01-13 21:00:40\n",
      "Unequal: begin: 2022-01-14 07:14:47end: 2022-01-14 07:15:47\n",
      "Unequal: begin: 2022-01-14 08:57:52end: 2022-01-14 09:00:52\n",
      "Unequal: begin: 2022-01-14 09:01:06end: 2022-01-14 09:35:06\n",
      "Unequal: begin: 2022-01-14 11:32:17end: 2022-01-14 11:35:17\n",
      "Unequal: begin: 2022-01-14 11:37:20end: 2022-01-14 12:10:20\n",
      "Unequal: begin: 2022-01-14 16:29:46end: 2022-01-14 16:30:46\n",
      "Unequal: begin: 2022-01-14 16:34:51end: 2022-01-14 17:05:51\n",
      "Unequal: begin: 2022-01-14 18:44:47end: 2022-01-14 18:45:47\n",
      "Unequal: begin: 2022-01-14 18:49:52end: 2022-01-14 19:20:52\n",
      "Unequal: begin: 2022-01-15 03:11:54end: 2022-01-15 03:15:54\n",
      "Unequal: begin: 2022-01-15 09:13:04end: 2022-01-15 09:15:04\n",
      "Unequal: begin: 2022-01-15 09:18:06end: 2022-01-15 09:50:06\n",
      "Unequal: begin: 2022-01-15 14:39:08end: 2022-01-15 14:40:08\n",
      "Unequal: begin: 2022-01-15 14:44:12end: 2022-01-15 15:15:12\n",
      "Unequal: begin: 2022-01-15 20:59:08end: 2022-01-15 21:00:08\n",
      "Unequal: begin: 2022-01-15 21:04:12end: 2022-01-15 21:35:12\n",
      "Unequal: begin: 2022-01-16 08:26:05end: 2022-01-16 08:30:05\n",
      "Unequal: begin: 2022-01-16 08:31:00end: 2022-01-16 09:05:00\n",
      "Unequal: begin: 2022-01-16 13:43:44end: 2022-01-16 13:45:44\n",
      "Unequal: begin: 2022-01-16 13:48:12end: 2022-01-16 14:20:12\n",
      "Unequal: begin: 2022-01-16 18:44:39end: 2022-01-16 18:45:39\n",
      "Unequal: begin: 2022-01-16 18:47:51end: 2022-01-16 19:20:51\n",
      "Unequal: begin: 2022-01-16 20:11:38end: 2022-01-16 20:15:38\n",
      "Unequal: begin: 2022-01-16 20:16:11end: 2022-01-16 21:20:11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_begin</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>type</th>\n",
       "      <th>dose</th>\n",
       "      <th>bwz_carb_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07 07:40:54</td>\n",
       "      <td>2021-12-07 07:40:54</td>\n",
       "      <td>normal dual</td>\n",
       "      <td>8.0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07 07:41:58</td>\n",
       "      <td>2021-12-07 08:15:58</td>\n",
       "      <td>square dual</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07 18:31:52</td>\n",
       "      <td>2021-12-07 18:35:52</td>\n",
       "      <td>normal dual</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-07 18:34:32</td>\n",
       "      <td>2021-12-07 19:05:32</td>\n",
       "      <td>square dual</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-07 22:19:46</td>\n",
       "      <td>2021-12-07 22:20:46</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2022-01-16 13:48:12</td>\n",
       "      <td>2022-01-16 14:20:12</td>\n",
       "      <td>square dual</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2022-01-16 18:44:39</td>\n",
       "      <td>2022-01-16 18:45:39</td>\n",
       "      <td>normal dual</td>\n",
       "      <td>4.8</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-01-16 18:47:51</td>\n",
       "      <td>2022-01-16 19:20:51</td>\n",
       "      <td>square dual</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2022-01-16 20:11:38</td>\n",
       "      <td>2022-01-16 20:15:38</td>\n",
       "      <td>normal dual</td>\n",
       "      <td>6.7</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2022-01-16 20:16:11</td>\n",
       "      <td>2022-01-16 21:20:11</td>\n",
       "      <td>square dual</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ts_begin              ts_end         type  dose bwz_carb_input\n",
       "0   2021-12-07 07:40:54 2021-12-07 07:40:54  normal dual   8.0            102\n",
       "1   2021-12-07 07:41:58 2021-12-07 08:15:58  square dual   6.4              0\n",
       "2   2021-12-07 18:31:52 2021-12-07 18:35:52  normal dual   4.0             65\n",
       "3   2021-12-07 18:34:32 2021-12-07 19:05:32  square dual   4.1              0\n",
       "4   2021-12-07 22:19:46 2021-12-07 22:20:46       normal   0.7              0\n",
       "..                  ...                 ...          ...   ...            ...\n",
       "321 2022-01-16 13:48:12 2022-01-16 14:20:12  square dual   5.6              0\n",
       "322 2022-01-16 18:44:39 2022-01-16 18:45:39  normal dual   4.8             60\n",
       "323 2022-01-16 18:47:51 2022-01-16 19:20:51  square dual   3.8              0\n",
       "324 2022-01-16 20:11:38 2022-01-16 20:15:38  normal dual   6.7            175\n",
       "325 2022-01-16 20:16:11 2022-01-16 21:20:11  square dual  15.1              0\n",
       "\n",
       "[326 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include bolus:\n",
    "bolus = read_ohio_bolus_tempbasal(filepath, \"bolus\", True)\n",
    "flattened_bolus_data = [item[0] for item in bolus]  # Take the first (and only) item from each sublist\n",
    "# Convert to DataFrame\n",
    "bolus_df = pd.DataFrame(flattened_bolus_data)\n",
    "# bolus_df['assigned'] = False\n",
    "bolus_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_bolus_entry(bolus_row):\n",
    "    bolus_time = bolus_row['ts_begin']\n",
    "    timestamp_list = [bolus_time, ]\n",
    "    # end_effect_time = bolus_time + timedelta(hours=3)\n",
    "    dose = float(bolus_row['dose'])\n",
    "\n",
    "    b_eff_list = [dose, ]\n",
    "    b_eff = dose\n",
    "\n",
    "    i = 1\n",
    "    while b_eff > 0:\n",
    "        b_eff = dose - (i * 0.07)\n",
    "        b_eff_list.append(b_eff)\n",
    "        timestamp_list.append(bolus_time + timedelta(minutes=5 * i))\n",
    "        i += 1\n",
    "    # print(len(timestamp_list[:-1]))\n",
    "    # print(len(b_eff_list[:-1]))\n",
    "\n",
    "\n",
    "    d = {\"ts\": timestamp_list[:-1], \"bolus_effect\": b_eff_list[:-1]}\n",
    "    bolus_effect_df = pd.DataFrame(data = d)\n",
    "\n",
    "    return bolus_effect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_b = {\"ts\": [], \"bolus_effect\": []}\n",
    "whole_bolus_effect_df = pd.DataFrame(data = empty_b)\n",
    "\n",
    "for index, bolus_row in bolus_df.iterrows():\n",
    "    bolus_effect_df = expand_bolus_entry(bolus_row)\n",
    "\n",
    "    # Merge the DataFrames on the 'ts' column with an outer join\n",
    "    merged_df = pd.merge(whole_bolus_effect_df, bolus_effect_df, on='ts', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Fill NaN values with 0 for the carb_effect columns\n",
    "    merged_df['bolus_effect_df1'] = merged_df['bolus_effect_df1'].fillna(0)\n",
    "    merged_df['bolus_effect_df2'] = merged_df['bolus_effect_df2'].fillna(0)\n",
    "    \n",
    "\n",
    "    # Sum the carb_effect values\n",
    "    merged_df['bolus_effect'] = merged_df['bolus_effect_df1'] + merged_df['bolus_effect_df2']\n",
    "\n",
    "    # Keep only the required columns\n",
    "    whole_bolus_effect_df = merged_df[['ts', 'bolus_effect']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\953268531.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  whole_bolus_effect_df[\"assigned\"] = False\n"
     ]
    }
   ],
   "source": [
    "whole_bolus_effect_df[\"assigned\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.980957724514357"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(whole_bolus_effect_df[\"bolus_effect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_segments_with_bolus(segments, bolus_df):\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        # Initialize the 'carbs' column to zeros\n",
    "        segment_df['bolus_effect'] = 0\n",
    "\n",
    "        for index, bolus_row in bolus_df.iterrows():\n",
    "            bolus_time = bolus_row['ts']\n",
    "            closest_glucose_idx = find_closest_glucose_index(segment_df, bolus_time)\n",
    "            \n",
    "            if closest_glucose_idx is not None:\n",
    "                segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
    "                bolus_df.loc[index, 'assigned'] = True\n",
    "\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.32499999999999973' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.31999999999999984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4499999999999993' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.48' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.635' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.48499999999999943' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.1149999999999998' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0149999999999997' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.23' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.3849999999999998' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7649999999999999' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.13' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.915' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6799999999999999' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.245' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.19499999999999998' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8700000000000001' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.3399999999999994' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n",
      "C:\\Users\\username\\AppData\\Local\\Temp\\ipykernel_15572\\1956024289.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.8' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  segment_df.loc[closest_glucose_idx, 'bolus_effect'] = float(bolus_row['bolus_effect']) /2\n"
     ]
    }
   ],
   "source": [
    "# Need to make it align with the CGM data\n",
    "bolus_updated_segments = update_segments_with_bolus(meal_updated_segments, whole_bolus_effect_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process step info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = f\"C:/Users/username/OneDrive/Desktop/BGprediction/OhioT1DM/2018/train/559-ws-training.xml\"\n",
    "steps = read_ohio(filepath, \"basis_steps\", True)\n",
    "flattened_steps_data = [item[0] for item in steps]  # Take the first (and only) item from each sublist\n",
    "# Convert to DataFrame\n",
    "step_df = pd.DataFrame(flattened_steps_data)\n",
    "# step_df['assigned'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accumulated_step(window_list, step_df):\n",
    "    start_time = window_list[0]\n",
    "    end_time = window_list[-1]\n",
    "\n",
    "    step_list = []\n",
    "    counter = 1\n",
    "    for idx, step_row in step_df.iterrows():\n",
    "        \n",
    "        if step_row['ts'] >= start_time and step_row['ts'] < end_time:\n",
    "            step_list.append(counter * float(step_row['value']))\n",
    "            counter += 1\n",
    "\n",
    "        if step_row['ts'] >= end_time:\n",
    "            break\n",
    "    # print(\"length of step_list \", len(step_list))\n",
    "    if len(step_list) == 0:\n",
    "        return None\n",
    "    accumulate_step = sum(step_list)/len(step_list)\n",
    "    return accumulate_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_step_list = []\n",
    "# test_segment = segments[\"segment_1\"]\n",
    "for segment_name, segment_df in bolus_updated_segments.items():\n",
    "    accumulate_step_list = []\n",
    "    for index, cgm_row in segment_df.iterrows():\n",
    "        current = cgm_row['timestamp']\n",
    "        first_timestamp = current - timedelta(minutes=50)\n",
    "        window_list = pd.date_range(start=first_timestamp, end=current, freq='5min')\n",
    "\n",
    "        accumulated_step = compute_accumulated_step(window_list, step_df)\n",
    "        accumulate_step_list.append(accumulated_step)\n",
    "    segment_df['steps'] = accumulate_step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_1':              timestamp  glucose_value  carb_effect  bolus_effect      steps\n",
       " 0  2021-12-07 16:30:00           1.01         0.00         0.290   0.000000\n",
       " 1  2021-12-07 16:35:00           1.00         0.00         0.255   0.000000\n",
       " 2  2021-12-07 16:40:00           1.00         0.00         0.220   0.000000\n",
       " 3  2021-12-07 16:45:00           0.99         0.00         0.185        NaN\n",
       " 4  2021-12-07 16:50:00           0.98         0.00         0.150        NaN\n",
       " ..                 ...            ...          ...           ...        ...\n",
       " 65 2021-12-07 21:55:00           1.44         0.05         0.565   3.000000\n",
       " 66 2021-12-07 22:00:00           1.40         0.05         0.530   2.666667\n",
       " 67 2021-12-07 22:05:00           1.39         0.10         0.495   2.400000\n",
       " 68 2021-12-07 22:10:00           1.40         0.10         0.460   7.800000\n",
       " 69 2021-12-07 22:15:00           1.40         0.15         0.350  13.600000\n",
       " \n",
       " [70 rows x 5 columns],\n",
       " 'segment_2':                timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0    2021-12-07 22:35:00           1.39         0.20         0.285   11.5\n",
       " 1    2021-12-07 22:40:00           1.43         0.20         0.250    9.7\n",
       " 2    2021-12-07 22:45:00           1.38         0.20         0.215    8.9\n",
       " 3    2021-12-07 22:50:00           1.33         0.20         0.180    7.0\n",
       " 4    2021-12-07 22:55:00           1.32         0.20         0.145    5.1\n",
       " ...                  ...            ...          ...           ...    ...\n",
       " 1627 2021-12-13 14:10:00           2.35         1.65         0.915    9.0\n",
       " 1628 2021-12-13 14:15:00           2.30         1.60         0.880    6.5\n",
       " 1629 2021-12-13 14:20:00           2.25         1.55         0.845    4.0\n",
       " 1630 2021-12-13 14:25:00           2.21         1.45         0.810    1.8\n",
       " 1631 2021-12-13 14:30:00           2.20         1.40         0.525    0.8\n",
       " \n",
       " [1632 rows x 5 columns],\n",
       " 'segment_3':                timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0    2021-12-13 17:10:00           1.99          5.4         0.415   18.5\n",
       " 1    2021-12-13 17:15:00           1.90          5.2         0.380   38.4\n",
       " 2    2021-12-13 17:20:00           1.78          5.0         0.345   36.1\n",
       " 3    2021-12-13 17:25:00           1.67          4.8         0.310   33.6\n",
       " 4    2021-12-13 17:30:00           1.57          4.6         0.275   51.9\n",
       " ...                  ...            ...          ...           ...    ...\n",
       " 1018 2021-12-17 06:00:00           2.74          0.0         0.000    0.0\n",
       " 1019 2021-12-17 06:05:00           2.72          0.0         0.000    0.0\n",
       " 1020 2021-12-17 06:10:00           2.70          0.0         0.000    0.0\n",
       " 1021 2021-12-17 06:15:00           2.68          0.0         0.000    0.0\n",
       " 1022 2021-12-17 06:20:00           2.65          0.0         0.000    0.0\n",
       " \n",
       " [1023 rows x 5 columns],\n",
       " 'segment_4':               timestamp  glucose_value  carb_effect  bolus_effect      steps\n",
       " 0   2021-12-17 07:40:00           2.68         0.00         1.445  14.875000\n",
       " 1   2021-12-17 07:45:00           2.67         0.00         4.100  23.222222\n",
       " 2   2021-12-17 07:50:00           2.70         0.00         4.065  20.900000\n",
       " 3   2021-12-17 07:55:00           2.70         0.00         4.030  18.200000\n",
       " 4   2021-12-17 08:00:00           2.69         0.45         3.995  15.500000\n",
       " ..                  ...            ...          ...           ...        ...\n",
       " 153 2021-12-17 20:25:00           1.63         8.30         0.945  57.000000\n",
       " 154 2021-12-17 20:30:00           1.65         8.00         0.910  42.800000\n",
       " 155 2021-12-17 20:35:00           1.71         7.75         0.875  39.800000\n",
       " 156 2021-12-17 20:40:00           1.78         7.45         0.840  25.500000\n",
       " 157 2021-12-17 20:45:00           1.86         7.20         0.805  20.300000\n",
       " \n",
       " [158 rows x 5 columns],\n",
       " 'segment_5':              timestamp  glucose_value  carb_effect  bolus_effect      steps\n",
       " 0  2021-12-17 23:15:00           2.41            0         1.445   1.666667\n",
       " 1  2021-12-17 23:20:00           2.41            0         1.410   1.428571\n",
       " 2  2021-12-17 23:25:00           2.44            0         1.375   6.250000\n",
       " 3  2021-12-17 23:30:00           2.52            0         1.340  15.555556\n",
       " 4  2021-12-17 23:35:00           2.57            0         1.305  14.000000\n",
       " ..                 ...            ...          ...           ...        ...\n",
       " 65 2021-12-18 04:40:00           2.87            0         2.165   0.000000\n",
       " 66 2021-12-18 04:45:00           2.86            0         2.130   0.000000\n",
       " 67 2021-12-18 04:50:00           2.87            0         2.095   0.000000\n",
       " 68 2021-12-18 04:55:00           2.90            0         2.060   0.000000\n",
       " 69 2021-12-18 05:00:00           2.87            0         1.990   0.000000\n",
       " \n",
       " [70 rows x 5 columns],\n",
       " 'segment_6':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2021-12-18 08:40:00           2.64          0.0         0.485    6.9\n",
       " 1   2021-12-18 08:45:00           2.66          0.0         0.450   26.0\n",
       " 2   2021-12-18 08:50:00           2.57          0.0         0.415   23.1\n",
       " 3   2021-12-18 08:55:00           2.59          0.0         0.380   20.2\n",
       " 4   2021-12-18 09:00:00           2.49          0.0         0.345   17.3\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 271 2021-12-19 07:15:00           2.00          0.0         0.000    0.0\n",
       " 272 2021-12-19 07:20:00           2.00          0.0         0.000    0.0\n",
       " 273 2021-12-19 07:25:00           2.00          0.0         0.000    0.0\n",
       " 274 2021-12-19 07:30:00           2.01          0.0         0.000    0.0\n",
       " 275 2021-12-19 07:35:00           1.98          0.0         0.000    0.0\n",
       " \n",
       " [276 rows x 5 columns],\n",
       " 'segment_7':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2021-12-19 09:20:00           2.07         0.00         3.600  25.00\n",
       " 1   2021-12-19 09:25:00           2.06         0.00         3.565  25.70\n",
       " 2   2021-12-19 09:30:00           2.06         0.00         3.530  25.10\n",
       " 3   2021-12-19 09:35:00           2.10         0.60         3.495  24.05\n",
       " 4   2021-12-19 09:40:00           2.18         1.25         3.460  43.80\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 953 2021-12-22 16:45:00           1.66         0.00         1.655   3.10\n",
       " 954 2021-12-22 16:50:00           1.69         0.00         1.620   2.30\n",
       " 955 2021-12-22 16:55:00           1.71         0.00         1.585   1.50\n",
       " 956 2021-12-22 17:00:00           1.73         0.00         1.550   1.20\n",
       " 957 2021-12-22 17:05:00           1.74         0.00         1.480   0.90\n",
       " \n",
       " [958 rows x 5 columns],\n",
       " 'segment_8':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2021-12-22 18:05:00           1.62         0.00         3.445   27.2\n",
       " 1   2021-12-22 18:10:00           1.63         0.55         3.410   22.3\n",
       " 2   2021-12-22 18:15:00           1.64         1.10         3.375   17.4\n",
       " 3   2021-12-22 18:20:00           1.63         1.65         3.340   14.8\n",
       " 4   2021-12-22 18:25:00           1.64         2.20         3.305   13.0\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 289 2021-12-23 18:15:00           2.06         1.50         0.695   68.8\n",
       " 290 2021-12-23 18:20:00           2.02         1.40         0.660   84.8\n",
       " 291 2021-12-23 18:25:00           2.07         1.30         0.625   82.4\n",
       " 292 2021-12-23 18:30:00           2.15         1.20         0.590   71.2\n",
       " 293 2021-12-23 18:35:00           2.18         0.00         0.520   60.2\n",
       " \n",
       " [294 rows x 5 columns],\n",
       " 'segment_9':              timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0  2021-12-23 21:10:00           2.39         2.70         2.580    7.5\n",
       " 1  2021-12-23 21:15:00           2.42         2.55         2.545    6.3\n",
       " 2  2021-12-23 21:20:00           2.48         2.45         2.510    5.1\n",
       " 3  2021-12-23 21:25:00           2.56         2.35         2.475    5.9\n",
       " 4  2021-12-23 21:30:00           2.57         2.25         2.440    4.5\n",
       " ..                 ...            ...          ...           ...    ...\n",
       " 65 2021-12-24 02:35:00           2.23         0.00         0.305    0.0\n",
       " 66 2021-12-24 02:40:00           2.23         0.00         0.270    0.0\n",
       " 67 2021-12-24 02:45:00           2.23         0.00         0.235    0.0\n",
       " 68 2021-12-24 02:50:00           2.24         0.00         0.200    0.0\n",
       " 69 2021-12-24 02:55:00           2.25         0.00         0.165    0.0\n",
       " \n",
       " [70 rows x 5 columns],\n",
       " 'segment_10':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2021-12-24 07:10:00           2.55          0.0         1.230    9.9\n",
       " 1   2021-12-24 07:15:00           2.58          0.0         1.195   16.8\n",
       " 2   2021-12-24 07:20:00           2.60          0.0         1.160   14.9\n",
       " 3   2021-12-24 07:25:00           2.60          0.0         1.125   13.0\n",
       " 4   2021-12-24 07:30:00           2.60          0.0         3.000   11.1\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 869 2021-12-27 07:35:00           1.96          0.0         1.770    0.0\n",
       " 870 2021-12-27 07:40:00           1.96          0.0         1.735    0.0\n",
       " 871 2021-12-27 07:45:00           1.97          0.0         1.700    0.0\n",
       " 872 2021-12-27 07:50:00           1.97          0.0         1.665    0.0\n",
       " 873 2021-12-27 07:55:00           1.98          0.0         1.595    0.0\n",
       " \n",
       " [874 rows x 5 columns],\n",
       " 'segment_11':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2021-12-27 08:30:00           1.84         0.00         1.385   27.9\n",
       " 1   2021-12-27 08:35:00           1.86         0.00         3.400   24.7\n",
       " 2   2021-12-27 08:40:00           1.88         0.00         3.365   22.5\n",
       " 3   2021-12-27 08:45:00           1.91         0.00         3.330   21.2\n",
       " 4   2021-12-27 08:50:00           1.96         0.00         3.295   17.7\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 654 2021-12-29 15:00:00           1.96         2.60         3.085    0.0\n",
       " 655 2021-12-29 15:05:00           1.99         2.45         3.050    0.0\n",
       " 656 2021-12-29 15:10:00           2.01         2.30         3.015    0.0\n",
       " 657 2021-12-29 15:15:00           2.01         2.15         2.980    0.0\n",
       " 658 2021-12-29 15:20:00           2.04         2.05         1.560    0.0\n",
       " \n",
       " [659 rows x 5 columns],\n",
       " 'segment_12':                timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0    2021-12-29 18:00:00           2.53         1.05         1.825   15.9\n",
       " 1    2021-12-29 18:05:00           2.51         1.00         1.790   24.9\n",
       " 2    2021-12-29 18:10:00           2.47         0.95         1.755   91.8\n",
       " 3    2021-12-29 18:15:00           2.44         0.95         1.720   81.7\n",
       " 4    2021-12-29 18:20:00           2.41         0.90         1.685   71.6\n",
       " ...                  ...            ...          ...           ...    ...\n",
       " 1023 2022-01-02 07:15:00           2.29         0.00         0.000    0.0\n",
       " 1024 2022-01-02 07:20:00           2.33         0.00         0.000    0.0\n",
       " 1025 2022-01-02 07:25:00           2.37         0.00         0.000    0.0\n",
       " 1026 2022-01-02 07:30:00           2.33         0.00         0.000    0.0\n",
       " 1027 2022-01-02 07:35:00           2.32         0.00         0.000    0.0\n",
       " \n",
       " [1028 rows x 5 columns],\n",
       " 'segment_13':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2022-01-02 08:30:00           2.38          0.0         1.095   18.5\n",
       " 1   2022-01-02 08:35:00           2.39          0.0         1.060   16.3\n",
       " 2   2022-01-02 08:40:00           2.37          0.0         1.025   28.1\n",
       " 3   2022-01-02 08:45:00           2.35          0.0         0.990   24.5\n",
       " 4   2022-01-02 08:50:00           2.36          0.0         0.955   20.9\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 680 2022-01-04 17:10:00           2.45          0.0         3.570    0.0\n",
       " 681 2022-01-04 17:15:00           2.52          0.0         3.535   12.0\n",
       " 682 2022-01-04 17:20:00           2.49          0.0         3.500   10.8\n",
       " 683 2022-01-04 17:25:00           2.48          0.0         3.465   11.6\n",
       " 684 2022-01-04 17:30:00           2.51          0.0         3.395   19.2\n",
       " \n",
       " [685 rows x 5 columns],\n",
       " 'segment_14':               timestamp  glucose_value  carb_effect  bolus_effect      steps\n",
       " 0   2022-01-04 20:05:00           2.74          0.0         2.345   3.400000\n",
       " 1   2022-01-04 20:10:00           2.76          0.0         2.310   0.000000\n",
       " 2   2022-01-04 20:15:00           2.71          0.0         2.275   1.000000\n",
       " 3   2022-01-04 20:20:00           2.72          0.4         2.240   0.800000\n",
       " 4   2022-01-04 20:25:00           2.74          0.8         2.205  24.666667\n",
       " ..                  ...            ...          ...           ...        ...\n",
       " 841 2022-01-07 18:10:00           2.65          0.0         0.530  61.900000\n",
       " 842 2022-01-07 18:15:00           2.69          0.0         0.495  56.700000\n",
       " 843 2022-01-07 18:20:00           2.73          0.0         0.460  69.700000\n",
       " 844 2022-01-07 18:25:00           2.82          0.0         0.425  78.500000\n",
       " 845 2022-01-07 18:30:00           2.88          0.0         2.720  84.300000\n",
       " \n",
       " [846 rows x 5 columns],\n",
       " 'segment_15':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2022-01-08 06:35:00           1.90          0.0         0.645    2.0\n",
       " 1   2022-01-08 06:40:00           1.89          0.0         0.610    1.8\n",
       " 2   2022-01-08 06:45:00           1.87          0.0         0.575    1.6\n",
       " 3   2022-01-08 06:50:00           1.83          0.0         0.540    1.4\n",
       " 4   2022-01-08 06:55:00           1.76          0.0         0.505    1.2\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 221 2022-01-09 01:00:00           1.22          0.0         4.485    0.0\n",
       " 222 2022-01-09 01:05:00           1.23          0.0         4.450    0.0\n",
       " 223 2022-01-09 01:10:00           1.23          0.0         4.415    0.0\n",
       " 224 2022-01-09 01:15:00           1.23          0.0         4.380    0.0\n",
       " 225 2022-01-09 01:20:00           1.21          0.0         4.310    0.0\n",
       " \n",
       " [226 rows x 5 columns],\n",
       " 'segment_16':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2022-01-09 06:20:00           2.44          0.0         1.495    0.0\n",
       " 1   2022-01-09 06:25:00           2.37          0.0         1.460    0.0\n",
       " 2   2022-01-09 06:30:00           2.31          0.0         1.425    0.0\n",
       " 3   2022-01-09 06:35:00           2.25          0.0         1.390    0.0\n",
       " 4   2022-01-09 06:40:00           2.21          0.0         1.355    0.0\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 136 2022-01-09 17:40:00           1.86          0.0         0.000   47.4\n",
       " 137 2022-01-09 17:45:00           1.88          0.0         0.000   41.1\n",
       " 138 2022-01-09 17:50:00           1.87          0.0         0.000   47.0\n",
       " 139 2022-01-09 17:55:00           1.86          0.0         0.000   44.6\n",
       " 140 2022-01-09 18:00:00           1.85          0.0         0.000   36.6\n",
       " \n",
       " [141 rows x 5 columns],\n",
       " 'segment_17':                timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0    2022-01-09 19:20:00           1.42          0.0         0.195   45.2\n",
       " 1    2022-01-09 19:25:00           1.38          0.0         0.160   40.0\n",
       " 2    2022-01-09 19:30:00           1.37          0.0         0.125   62.8\n",
       " 3    2022-01-09 19:35:00           1.34          0.0         0.090   54.6\n",
       " 4    2022-01-09 19:40:00           1.30          0.0         0.055   46.6\n",
       " ...                  ...            ...          ...           ...    ...\n",
       " 1121 2022-01-13 16:45:00           1.94          0.0         0.005    0.0\n",
       " 1122 2022-01-13 16:50:00           1.93          0.0         1.845    0.0\n",
       " 1123 2022-01-13 16:55:00           1.93          0.0         1.810    0.0\n",
       " 1124 2022-01-13 17:00:00           1.92          0.0         1.775    0.0\n",
       " 1125 2022-01-13 17:05:00           1.90          0.0         1.740    0.0\n",
       " \n",
       " [1126 rows x 5 columns],\n",
       " 'segment_18':              timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0  2022-01-13 20:35:00           2.15          0.0         4.930   53.4\n",
       " 1  2022-01-13 20:40:00           2.15          0.0         4.895   44.8\n",
       " 2  2022-01-13 20:45:00           2.16          0.9         4.860   36.7\n",
       " 3  2022-01-13 20:50:00           2.20          1.8         4.825   28.8\n",
       " 4  2022-01-13 20:55:00           2.22          2.7         4.790   22.3\n",
       " ..                 ...            ...          ...           ...    ...\n",
       " 65 2022-01-14 02:00:00           2.44          0.0         2.655    0.0\n",
       " 66 2022-01-14 02:05:00           2.46          0.0         2.620    0.0\n",
       " 67 2022-01-14 02:10:00           2.46          0.0         2.585    0.0\n",
       " 68 2022-01-14 02:15:00           2.45          0.0         2.550    0.0\n",
       " 69 2022-01-14 02:20:00           2.44          0.0         2.515    0.0\n",
       " \n",
       " [70 rows x 5 columns],\n",
       " 'segment_19':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2022-01-14 05:15:00           2.60          0.0         1.290    0.0\n",
       " 1   2022-01-14 05:20:00           2.61          0.0         1.255    0.0\n",
       " 2   2022-01-14 05:25:00           2.62          0.0         1.220    0.0\n",
       " 3   2022-01-14 05:30:00           2.69          0.0         1.185    0.0\n",
       " 4   2022-01-14 05:35:00           2.76          0.0         1.150    0.0\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 299 2022-01-15 06:10:00           2.47          0.0         0.000    0.0\n",
       " 300 2022-01-15 06:15:00           2.50          0.0         0.000    0.0\n",
       " 301 2022-01-15 06:20:00           2.51          0.0         0.000    0.0\n",
       " 302 2022-01-15 06:25:00           2.50          0.0         0.000    0.0\n",
       " 303 2022-01-15 06:30:00           2.49          0.0         0.000    0.0\n",
       " \n",
       " [304 rows x 5 columns],\n",
       " 'segment_20':               timestamp  glucose_value  carb_effect  bolus_effect  steps\n",
       " 0   2022-01-15 08:45:00           2.55          0.0         0.000    3.0\n",
       " 1   2022-01-15 08:50:00           2.58          0.0         0.000    2.6\n",
       " 2   2022-01-15 08:55:00           2.63          0.0         0.000    2.2\n",
       " 3   2022-01-15 09:00:00           2.64          0.0         0.000    1.8\n",
       " 4   2022-01-15 09:05:00           2.67          0.0         0.000    1.4\n",
       " ..                  ...            ...          ...           ...    ...\n",
       " 467 2022-01-16 23:40:00           1.13          0.0         1.880   83.1\n",
       " 468 2022-01-16 23:45:00           1.18          0.0         1.845   53.2\n",
       " 469 2022-01-16 23:50:00           1.20          0.0         1.810   26.8\n",
       " 470 2022-01-16 23:55:00           1.23          0.0         1.775    9.5\n",
       " 471 2022-01-17 00:00:00           1.28          0.0         0.160    1.3\n",
       " \n",
       " [472 rows x 5 columns]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolus_updated_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "filename = '570_combined_segments.pkl'\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(bolus_updated_segments, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load the dictionary from the file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m     loaded_df_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Verify the content\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_df_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "filename = '559_combined_segments.pkl'\n",
    "# Load the dictionary from the file\n",
    "with open(filename, 'rb') as f:\n",
    "    loaded_df_dict = pickle.load(f)\n",
    "\n",
    "# Verify the content\n",
    "\n",
    "print(loaded_df_dict['segment_1'])\n",
    "print(loaded_df_dict['segment_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolus_updated_segments = loaded_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(segments, ph, history):\n",
    "    '''\n",
    "    ph = 6, 30 minutes ahead\n",
    "    ph = 12, 60 minutes ahead\n",
    "    '''\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    raw_glu_list = []\n",
    "    \n",
    "    # Iterate over each segment\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        # Ensure all columns are of numeric type\n",
    "        segment_df['carb_effect'] = pd.to_numeric(segment_df['carb_effect'], errors='coerce')\n",
    "        segment_df['steps'] = pd.to_numeric(segment_df['steps'], errors='coerce')\n",
    "        segment_df['steps'] = segment_df['steps'] / 20\n",
    "        segment_df['bolus_effect'] = pd.to_numeric(segment_df['bolus_effect'], errors='coerce')\n",
    "\n",
    "        # Fill NaNs that might have been introduced by conversion errors\n",
    "        segment_df.fillna(0, inplace=True)\n",
    "\n",
    "        # Maximum index for creating a complete feature set\n",
    "        max_index = len(segment_df) - (history-1+ph+1)  # Subtracting 22 because we need to predict index + 21 and need index + history-1 to exist\n",
    "        \n",
    "        # Iterate through the data to create feature-label pairs\n",
    "        for i in range(max_index + 1):\n",
    "            # Extracting features from index i to i+history-1\n",
    "            features = segment_df.loc[i:i+history-1, ['glucose_value', 'carb_effect', 'bolus_effect', 'steps']] # .values.flatten() # 'carb_effect', 'bolus_effect', 'steps'\n",
    "            # Extracting label for index i+21\n",
    "            # Do the label transform\n",
    "            label = segment_df.loc[i+history-1+ph, 'glucose_value'] - segment_df.loc[i+history-1, 'glucose_value']\n",
    "            \n",
    "            raw_glu_list.append(segment_df.loc[i+history-1+ph, 'glucose_value'])\n",
    "            features_list.append(features)\n",
    "            labels_list.append(label)\n",
    "            \n",
    "    print(\"len of features_list \" + str(len(features_list)))\n",
    "    print(\"len of labels_list \" + str(len(labels_list)))\n",
    "    # new_labels_list = label_delta_transform(labels_list)    \n",
    "    # print(\"after label transform. the len of label list \"+str(len(new_labels_list)))    \n",
    "    return features_list, labels_list, raw_glu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of features_list 10402\n",
      "len of labels_list 10402\n"
     ]
    }
   ],
   "source": [
    "# Check whether bolus_updated_segments is updated with \n",
    "\n",
    "# Prepare for training\n",
    "features_list, labels_list, raw_glu_list = prepare_dataset(bolus_updated_segments, 6, 24)\n",
    "\n",
    "# Build training and validation loader\n",
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(raw_glu_list) # Maybe need to replace this\n",
    "\n",
    "# For one channel\n",
    "# data_sequences = np.reshape(features_array, (features_array.shape[0], features_array.shape[1], 1))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_array, labels_array, test_size=0.2, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8321, 24, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# class StackedLSTMModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_classes):\n",
    "#         super(StackedLSTMModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         # First LSTM layer\n",
    "#         self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True).to(device)\n",
    "\n",
    "#         # Dropout layer\n",
    "#         self.dropout = nn.Dropout(0.2).to(device)\n",
    "\n",
    "#         # Second LSTM layer\n",
    "#         self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True).to(device)\n",
    "\n",
    "#         # First Dense layer\n",
    "#         self.fc1 = nn.Linear(hidden_size, 512).to(device)\n",
    "\n",
    "#         # Second Dense layer\n",
    "#         self.fc2 = nn.Linear(512, 128).to(device)\n",
    "\n",
    "#         # Output layer\n",
    "#         self.fc3 = nn.Linear(128, num_classes).to(device)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # h0 = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "#         # c0 = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "\n",
    "#         # Forward pass through first LSTM layer\n",
    "#         out, _ = self.lstm1(x.view(len(x), 1, -1))\n",
    "\n",
    "#         # Apply dropout\n",
    "#         out = self.dropout(out)\n",
    "\n",
    "#         # Forward pass through second LSTM layer\n",
    "#         out, _ = self.lstm2(out)\n",
    "\n",
    "#         # Pass through first Dense layer\n",
    "#         out = self.fc1(out[:, -1, :])\n",
    "\n",
    "#         # Pass through second Dense layer\n",
    "#         out = self.fc2(out)\n",
    "\n",
    "#         # Pass through output layer\n",
    "#         out = self.fc3(out)\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # First LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True).to(device)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_prob).to(device)\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, num_layers=1, batch_first=True).to(device)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 512).to(device)\n",
    "        self.fc2 = nn.Linear(512, 128).to(device)\n",
    "        self.fc3 = nn.Linear(128, output_size).to(device)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     # Initialize hidden and cell state for the first LSTM layer\n",
    "    #     h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "    #     c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "    #     # First LSTM layer\n",
    "    #     out, (hn, cn) = self.lstm1(x, (h0, c0))\n",
    "        \n",
    "    #     # Dropout layer\n",
    "    #     out = self.dropout(out)\n",
    "        \n",
    "    #     # Initialize hidden and cell state for the second LSTM layer\n",
    "    #     h1 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "    #     c1 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "    #     # Second LSTM layer\n",
    "    #     out, (hn, cn) = self.lstm2(out, (h1, c1))\n",
    "        \n",
    "    #     # Fully connected layers\n",
    "    #     out = out[:, -1, :]  # Get the last time step output\n",
    "    #     out = self.relu(self.fc1(out))\n",
    "    #     out = self.relu(self.fc2(out))\n",
    "    #     out = self.fc3(out)  # Remove the exponential activation function\n",
    "        \n",
    "    #     return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # Get the batch size from the input tensor\n",
    "\n",
    "        # Initialize hidden and cell state for the first LSTM layer\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # First LSTM layer\n",
    "        out, (hn, cn) = self.lstm1(x, (h0, c0))\n",
    "        \n",
    "        # Dropout layer\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Initialize hidden and cell state for the second LSTM layer\n",
    "        h1 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        c1 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        out, (hn, cn) = self.lstm2(out, (h1, c1))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = out[:, -1, :]  # Get the last time step output\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation (assuming X_train, y_train, X_val, y_val are numpy arrays)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # The original batch size = 128, however, training on 128 cannot get the model fully trained, so change to 32.\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8321, 24, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0100, 0.0000, 0.2900, 0.0000],\n",
       "        [1.0000, 0.0000, 0.2550, 0.0000],\n",
       "        [1.0000, 0.0000, 0.2200, 0.0000],\n",
       "        [0.9900, 0.0000, 0.1850, 0.0000],\n",
       "        [0.9800, 0.0000, 0.1500, 0.0000],\n",
       "        [0.9800, 0.0000, 0.1150, 0.0000],\n",
       "        [0.9500, 0.0000, 0.0800, 0.0000],\n",
       "        [0.9400, 0.0000, 0.0450, 0.0000],\n",
       "        [0.9200, 0.0000, 0.0100, 0.0000],\n",
       "        [0.9000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8300, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.9300, 0.0000, 0.0000, 0.0000],\n",
       "        [0.9500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.9600, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4  # Number of input features\n",
    "hidden_size = 128  # Hidden vector size\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "output_size = 1  # Single output\n",
    "dropout_prob = 0.2  # Dropout probability\n",
    "\n",
    "\n",
    "\n",
    "model = StackedLSTM(input_size, hidden_size, num_layers, output_size, dropout_prob) # input_size, hidden_size, num_layers, output_size, dropout_prob\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\username\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\username\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.0993\n",
      "Epoch [2/500], Training Loss: 3.4017\n",
      "Epoch [3/500], Training Loss: 1.8830\n",
      "Epoch [4/500], Training Loss: 1.3812\n",
      "Epoch [5/500], Training Loss: 1.1093\n",
      "Epoch [6/500], Training Loss: 0.8871\n",
      "Epoch [7/500], Training Loss: 0.9057\n",
      "Epoch [8/500], Training Loss: 0.8221\n",
      "Epoch [9/500], Training Loss: 0.8266\n",
      "Epoch [10/500], Training Loss: 0.8648\n",
      "Epoch [11/500], Training Loss: 0.7920\n",
      "Epoch [12/500], Training Loss: 0.7709\n",
      "Epoch [13/500], Training Loss: 0.6678\n",
      "Epoch [14/500], Training Loss: 0.6954\n",
      "Epoch [15/500], Training Loss: 0.6979\n",
      "Epoch [16/500], Training Loss: 0.7457\n",
      "Epoch [17/500], Training Loss: 0.7275\n",
      "Epoch [18/500], Training Loss: 0.6936\n",
      "Epoch [19/500], Training Loss: 0.7210\n",
      "Epoch [20/500], Training Loss: 0.6573\n",
      "Epoch [21/500], Training Loss: 0.7101\n",
      "Epoch [22/500], Training Loss: 0.6964\n",
      "Epoch [23/500], Training Loss: 0.6780\n",
      "Epoch [24/500], Training Loss: 0.5976\n",
      "Epoch [25/500], Training Loss: 0.6721\n",
      "Epoch [26/500], Training Loss: 0.7192\n",
      "Epoch [27/500], Training Loss: 0.6281\n",
      "Epoch [28/500], Training Loss: 0.6554\n",
      "Epoch [29/500], Training Loss: 0.6681\n",
      "Epoch [30/500], Training Loss: 0.7165\n",
      "Epoch [31/500], Training Loss: 0.6399\n",
      "Epoch [32/500], Training Loss: 0.7131\n",
      "Epoch [33/500], Training Loss: 0.5947\n",
      "Epoch [34/500], Training Loss: 0.7278\n",
      "Epoch [35/500], Training Loss: 0.6452\n",
      "Epoch [36/500], Training Loss: 0.6204\n",
      "Epoch [37/500], Training Loss: 0.6679\n",
      "Epoch [38/500], Training Loss: 0.6080\n",
      "Epoch [39/500], Training Loss: 0.6312\n",
      "Epoch [40/500], Training Loss: 0.6058\n",
      "Epoch [41/500], Training Loss: 0.6304\n",
      "Epoch [42/500], Training Loss: 0.6339\n",
      "Epoch [43/500], Training Loss: 0.6718\n",
      "Epoch [44/500], Training Loss: 0.6437\n",
      "Epoch [45/500], Training Loss: 0.6239\n",
      "Epoch [46/500], Training Loss: 0.5588\n",
      "Epoch [47/500], Training Loss: 0.5789\n",
      "Epoch [48/500], Training Loss: 0.6370\n",
      "Epoch [49/500], Training Loss: 0.6009\n",
      "Epoch [50/500], Training Loss: 0.6294\n",
      "Epoch [51/500], Training Loss: 0.6448\n",
      "Epoch [52/500], Training Loss: 0.5053\n",
      "Epoch [53/500], Training Loss: 0.5831\n",
      "Epoch [54/500], Training Loss: 0.5672\n",
      "Epoch [55/500], Training Loss: 0.6028\n",
      "Epoch [56/500], Training Loss: 0.6021\n",
      "Epoch [57/500], Training Loss: 0.5883\n",
      "Epoch [58/500], Training Loss: 0.6381\n",
      "Epoch [59/500], Training Loss: 0.5597\n",
      "Epoch [60/500], Training Loss: 0.6475\n",
      "Epoch [61/500], Training Loss: 0.5859\n",
      "Epoch [62/500], Training Loss: 0.5886\n",
      "Epoch [63/500], Training Loss: 0.4966\n",
      "Epoch [64/500], Training Loss: 0.6581\n",
      "Epoch [65/500], Training Loss: 0.6521\n",
      "Epoch [66/500], Training Loss: 0.6406\n",
      "Epoch [67/500], Training Loss: 0.5624\n",
      "Epoch [68/500], Training Loss: 0.6324\n",
      "Epoch [69/500], Training Loss: 0.5749\n",
      "Epoch [70/500], Training Loss: 0.5728\n",
      "Epoch [71/500], Training Loss: 0.6304\n",
      "Epoch [72/500], Training Loss: 0.6798\n",
      "Epoch [73/500], Training Loss: 0.5691\n",
      "Epoch [74/500], Training Loss: 0.5916\n",
      "Epoch [75/500], Training Loss: 0.5600\n",
      "Epoch [76/500], Training Loss: 0.5319\n",
      "Epoch [77/500], Training Loss: 0.5603\n",
      "Epoch [78/500], Training Loss: 0.5885\n",
      "Epoch [79/500], Training Loss: 0.5931\n",
      "Epoch [80/500], Training Loss: 0.5773\n",
      "Epoch [81/500], Training Loss: 0.6144\n",
      "Epoch [82/500], Training Loss: 0.6476\n",
      "Epoch [83/500], Training Loss: 0.5968\n",
      "Epoch [84/500], Training Loss: 0.5097\n",
      "Epoch [85/500], Training Loss: 0.5864\n",
      "Epoch [86/500], Training Loss: 0.5868\n",
      "Epoch [87/500], Training Loss: 0.5715\n",
      "Epoch [88/500], Training Loss: 0.5522\n",
      "Epoch [89/500], Training Loss: 0.5554\n",
      "Epoch [90/500], Training Loss: 0.5584\n",
      "Epoch [91/500], Training Loss: 0.5749\n",
      "Epoch [92/500], Training Loss: 0.6004\n",
      "Epoch [93/500], Training Loss: 0.5861\n",
      "Epoch [94/500], Training Loss: 0.5673\n",
      "Epoch [95/500], Training Loss: 0.5245\n",
      "Epoch [96/500], Training Loss: 0.5450\n",
      "Epoch [97/500], Training Loss: 0.5508\n",
      "Epoch [98/500], Training Loss: 0.6322\n",
      "Epoch [99/500], Training Loss: 0.5705\n",
      "Epoch [100/500], Training Loss: 0.5511\n",
      "Epoch [101/500], Training Loss: 0.5111\n",
      "Epoch [102/500], Training Loss: 0.5691\n",
      "Epoch [103/500], Training Loss: 0.5611\n",
      "Epoch [104/500], Training Loss: 0.5721\n",
      "Epoch [105/500], Training Loss: 0.5760\n",
      "Epoch [106/500], Training Loss: 0.5026\n",
      "Epoch [107/500], Training Loss: 0.5447\n",
      "Epoch [108/500], Training Loss: 0.6123\n",
      "Epoch [109/500], Training Loss: 0.5221\n",
      "Epoch [110/500], Training Loss: 0.5546\n",
      "Epoch [111/500], Training Loss: 0.4850\n",
      "Epoch [112/500], Training Loss: 0.5184\n",
      "Epoch [113/500], Training Loss: 0.5461\n",
      "Epoch [114/500], Training Loss: 0.4971\n",
      "Epoch [115/500], Training Loss: 0.5626\n",
      "Epoch [116/500], Training Loss: 0.5477\n",
      "Epoch [117/500], Training Loss: 0.5661\n",
      "Epoch [118/500], Training Loss: 0.5621\n",
      "Epoch [119/500], Training Loss: 0.5224\n",
      "Epoch [120/500], Training Loss: 0.5621\n",
      "Epoch [121/500], Training Loss: 0.5218\n",
      "Epoch [122/500], Training Loss: 0.5437\n",
      "Epoch [123/500], Training Loss: 0.5216\n",
      "Epoch [124/500], Training Loss: 0.5431\n",
      "Epoch [125/500], Training Loss: 0.4963\n",
      "Epoch [126/500], Training Loss: 0.5169\n",
      "Epoch [127/500], Training Loss: 0.4867\n",
      "Epoch [128/500], Training Loss: 0.5144\n",
      "Epoch [129/500], Training Loss: 0.5348\n",
      "Epoch [130/500], Training Loss: 0.5511\n",
      "Epoch [131/500], Training Loss: 0.5568\n",
      "Epoch [132/500], Training Loss: 0.5122\n",
      "Epoch [133/500], Training Loss: 0.4842\n",
      "Epoch [134/500], Training Loss: 0.5174\n",
      "Epoch [135/500], Training Loss: 0.5140\n",
      "Epoch [136/500], Training Loss: 0.4984\n",
      "Epoch [137/500], Training Loss: 0.5611\n",
      "Epoch [138/500], Training Loss: 0.4800\n",
      "Epoch [139/500], Training Loss: 0.5119\n",
      "Epoch [140/500], Training Loss: 0.4956\n",
      "Epoch [141/500], Training Loss: 0.4797\n",
      "Epoch [142/500], Training Loss: 0.5141\n",
      "Epoch [143/500], Training Loss: 0.4762\n",
      "Epoch [144/500], Training Loss: 0.4534\n",
      "Epoch [145/500], Training Loss: 0.4735\n",
      "Epoch [146/500], Training Loss: 0.4427\n",
      "Epoch [147/500], Training Loss: 0.4749\n",
      "Epoch [148/500], Training Loss: 0.4934\n",
      "Epoch [149/500], Training Loss: 0.4963\n",
      "Epoch [150/500], Training Loss: 0.4170\n",
      "Epoch [151/500], Training Loss: 0.4269\n",
      "Epoch [152/500], Training Loss: 0.5279\n",
      "Epoch [153/500], Training Loss: 0.3753\n",
      "Epoch [154/500], Training Loss: 0.4758\n",
      "Epoch [155/500], Training Loss: 0.4189\n",
      "Epoch [156/500], Training Loss: 0.4639\n",
      "Epoch [157/500], Training Loss: 0.5033\n",
      "Epoch [158/500], Training Loss: 0.4238\n",
      "Epoch [159/500], Training Loss: 0.4258\n",
      "Epoch [160/500], Training Loss: 0.4055\n",
      "Epoch [161/500], Training Loss: 0.4027\n",
      "Epoch [162/500], Training Loss: 0.3482\n",
      "Epoch [163/500], Training Loss: 0.3584\n",
      "Epoch [164/500], Training Loss: 0.3776\n",
      "Epoch [165/500], Training Loss: 0.4302\n",
      "Epoch [166/500], Training Loss: 0.4124\n",
      "Epoch [167/500], Training Loss: 0.4385\n",
      "Epoch [168/500], Training Loss: 0.3617\n",
      "Epoch [169/500], Training Loss: 0.3344\n",
      "Epoch [170/500], Training Loss: 0.3789\n",
      "Epoch [171/500], Training Loss: 0.3362\n",
      "Epoch [172/500], Training Loss: 0.3804\n",
      "Epoch [173/500], Training Loss: 0.3273\n",
      "Epoch [174/500], Training Loss: 0.3615\n",
      "Epoch [175/500], Training Loss: 0.3374\n",
      "Epoch [176/500], Training Loss: 0.3360\n",
      "Epoch [177/500], Training Loss: 0.3399\n",
      "Epoch [178/500], Training Loss: 0.3238\n",
      "Epoch [179/500], Training Loss: 0.3481\n",
      "Epoch [180/500], Training Loss: 0.3276\n",
      "Epoch [181/500], Training Loss: 0.3029\n",
      "Epoch [182/500], Training Loss: 0.3354\n",
      "Epoch [183/500], Training Loss: 0.2898\n",
      "Epoch [184/500], Training Loss: 0.2597\n",
      "Epoch [185/500], Training Loss: 0.2600\n",
      "Epoch [186/500], Training Loss: 0.2961\n",
      "Epoch [187/500], Training Loss: 0.2327\n",
      "Epoch [188/500], Training Loss: 0.2378\n",
      "Epoch [189/500], Training Loss: 0.2684\n",
      "Epoch [190/500], Training Loss: 0.2289\n",
      "Epoch [191/500], Training Loss: 0.2350\n",
      "Epoch [192/500], Training Loss: 0.2276\n",
      "Epoch [193/500], Training Loss: 0.2092\n",
      "Epoch [194/500], Training Loss: 0.1958\n",
      "Epoch [195/500], Training Loss: 0.1898\n",
      "Epoch [196/500], Training Loss: 0.1851\n",
      "Epoch [197/500], Training Loss: 0.1570\n",
      "Epoch [198/500], Training Loss: 0.1751\n",
      "Epoch [199/500], Training Loss: 0.1797\n",
      "Epoch [200/500], Training Loss: 0.2243\n",
      "Epoch [201/500], Training Loss: 0.1622\n",
      "Epoch [202/500], Training Loss: 0.1313\n",
      "Epoch [203/500], Training Loss: 0.1487\n",
      "Epoch [204/500], Training Loss: 0.1586\n",
      "Epoch [205/500], Training Loss: 0.1046\n",
      "Epoch [206/500], Training Loss: 0.1241\n",
      "Epoch [207/500], Training Loss: 0.1639\n",
      "Epoch [208/500], Training Loss: 0.0896\n",
      "Epoch [209/500], Training Loss: 0.1162\n",
      "Epoch [210/500], Training Loss: 0.1280\n",
      "Epoch [211/500], Training Loss: 0.1149\n",
      "Epoch [212/500], Training Loss: 0.0852\n",
      "Epoch [213/500], Training Loss: 0.0870\n",
      "Epoch [214/500], Training Loss: 0.0478\n",
      "Epoch [215/500], Training Loss: 0.1047\n",
      "Epoch [216/500], Training Loss: 0.0614\n",
      "Epoch [217/500], Training Loss: 0.0697\n",
      "Epoch [218/500], Training Loss: 0.0499\n",
      "Epoch [219/500], Training Loss: 0.0832\n",
      "Epoch [220/500], Training Loss: 0.0882\n",
      "Epoch [221/500], Training Loss: 0.0529\n",
      "Epoch [222/500], Training Loss: 0.0914\n",
      "Epoch [223/500], Training Loss: 0.0838\n",
      "Epoch [224/500], Training Loss: 0.0855\n",
      "Epoch [225/500], Training Loss: 0.0340\n",
      "Epoch [226/500], Training Loss: 0.0483\n",
      "Epoch [227/500], Training Loss: 0.0429\n",
      "Epoch [228/500], Training Loss: 0.0368\n",
      "Epoch [229/500], Training Loss: 0.0329\n",
      "Epoch [230/500], Training Loss: 0.0378\n",
      "Epoch [231/500], Training Loss: 0.0772\n",
      "Epoch [232/500], Training Loss: 0.0638\n",
      "Epoch [233/500], Training Loss: 0.0318\n",
      "Epoch [234/500], Training Loss: 0.0543\n",
      "Epoch [235/500], Training Loss: 0.0531\n",
      "Epoch [236/500], Training Loss: 0.0471\n",
      "Epoch [237/500], Training Loss: 0.0422\n",
      "Epoch [238/500], Training Loss: 0.0493\n",
      "Epoch [239/500], Training Loss: 0.0246\n",
      "Epoch [240/500], Training Loss: 0.0235\n",
      "Epoch [241/500], Training Loss: 0.0208\n",
      "Epoch [242/500], Training Loss: 0.0202\n",
      "Epoch [243/500], Training Loss: 0.0273\n",
      "Epoch [244/500], Training Loss: 0.0360\n",
      "Epoch [245/500], Training Loss: 0.0519\n",
      "Epoch [246/500], Training Loss: 0.0081\n",
      "Epoch [247/500], Training Loss: 0.0290\n",
      "Epoch [248/500], Training Loss: 0.0446\n",
      "Epoch [249/500], Training Loss: 0.0352\n",
      "Epoch [250/500], Training Loss: 0.0086\n",
      "Epoch [251/500], Training Loss: 0.0444\n",
      "Epoch [252/500], Training Loss: 0.0052\n",
      "Epoch [253/500], Training Loss: 0.0500\n",
      "Epoch [254/500], Training Loss: 0.0604\n",
      "Epoch [255/500], Training Loss: 0.0459\n",
      "Epoch [256/500], Training Loss: 0.0213\n",
      "Epoch [257/500], Training Loss: 0.0018\n",
      "Epoch [258/500], Training Loss: 0.0369\n",
      "Epoch [259/500], Training Loss: 0.0357\n",
      "Epoch [260/500], Training Loss: 0.0361\n",
      "Epoch [261/500], Training Loss: 0.0035\n",
      "Epoch [262/500], Training Loss: 0.0322\n",
      "Epoch [263/500], Training Loss: 0.0120\n",
      "Epoch [264/500], Training Loss: 0.0196\n",
      "Epoch [265/500], Training Loss: 0.0422\n",
      "Epoch [266/500], Training Loss: 0.0012\n",
      "Epoch [267/500], Training Loss: 0.0390\n",
      "Epoch [268/500], Training Loss: 0.0210\n",
      "Epoch [269/500], Training Loss: 0.0243\n",
      "Epoch [270/500], Training Loss: 0.0229\n",
      "Epoch [271/500], Training Loss: 0.0146\n",
      "Epoch [272/500], Training Loss: 0.0515\n",
      "Epoch [273/500], Training Loss: 0.0139\n",
      "Epoch [274/500], Training Loss: 0.0179\n",
      "Epoch [275/500], Training Loss: 0.0039\n",
      "Epoch [276/500], Training Loss: 0.0192\n",
      "Epoch [277/500], Training Loss: 0.0024\n",
      "Epoch [278/500], Training Loss: 0.0102\n",
      "Epoch [279/500], Training Loss: 0.0029\n",
      "Epoch [280/500], Training Loss: 0.0367\n",
      "Epoch [281/500], Training Loss: 0.0005\n",
      "Epoch [282/500], Training Loss: 0.0263\n",
      "Epoch [283/500], Training Loss: 0.0306\n",
      "Epoch [284/500], Training Loss: 0.0039\n",
      "Epoch [285/500], Training Loss: 0.0043\n",
      "Epoch [286/500], Training Loss: 0.0040\n",
      "Epoch [287/500], Training Loss: 0.0068\n",
      "Epoch [288/500], Training Loss: 0.0260\n",
      "Epoch [289/500], Training Loss: 0.0001\n",
      "Epoch [290/500], Training Loss: 0.0296\n",
      "Epoch [291/500], Training Loss: 0.0189\n",
      "Epoch [292/500], Training Loss: 0.0032\n",
      "Epoch [293/500], Training Loss: 0.0160\n",
      "Epoch [294/500], Training Loss: 0.0112\n",
      "Epoch [295/500], Training Loss: 0.0006\n",
      "Epoch [296/500], Training Loss: 0.0238\n",
      "Epoch [297/500], Training Loss: 0.0047\n",
      "Epoch [298/500], Training Loss: 0.0009\n",
      "Epoch [299/500], Training Loss: 0.0062\n",
      "Epoch [300/500], Training Loss: 0.0015\n",
      "Epoch [301/500], Training Loss: 0.0137\n",
      "Epoch [302/500], Training Loss: 0.0008\n",
      "Epoch [303/500], Training Loss: 0.0401\n",
      "Epoch [304/500], Training Loss: 0.0001\n",
      "Epoch [305/500], Training Loss: 0.0140\n",
      "Epoch [306/500], Training Loss: 0.0044\n",
      "Epoch [307/500], Training Loss: 0.0062\n",
      "Epoch [308/500], Training Loss: 0.0002\n",
      "Epoch [309/500], Training Loss: 0.0084\n",
      "Epoch [310/500], Training Loss: 0.0008\n",
      "Epoch [311/500], Training Loss: 0.0071\n",
      "Epoch [312/500], Training Loss: 0.0104\n",
      "Epoch [313/500], Training Loss: 0.0001\n",
      "Epoch [314/500], Training Loss: 0.0195\n",
      "Epoch [315/500], Training Loss: 0.0008\n",
      "Epoch [316/500], Training Loss: 0.0073\n",
      "Epoch [317/500], Training Loss: 0.0053\n",
      "Epoch [318/500], Training Loss: 0.0014\n",
      "Epoch [319/500], Training Loss: 0.0146\n",
      "Epoch [320/500], Training Loss: 0.0005\n",
      "Epoch [321/500], Training Loss: 0.0052\n",
      "Epoch [322/500], Training Loss: 0.0011\n",
      "Epoch [323/500], Training Loss: 0.0242\n",
      "Epoch [324/500], Training Loss: 0.0011\n",
      "Epoch [325/500], Training Loss: 0.0161\n",
      "Epoch [326/500], Training Loss: 0.0005\n",
      "Epoch [327/500], Training Loss: 0.0017\n",
      "Epoch [328/500], Training Loss: 0.0062\n",
      "Epoch [329/500], Training Loss: 0.0008\n",
      "Epoch [330/500], Training Loss: 0.0165\n",
      "Epoch [331/500], Training Loss: 0.0002\n",
      "Epoch [332/500], Training Loss: 0.0361\n",
      "Epoch [333/500], Training Loss: 0.0229\n",
      "Epoch [334/500], Training Loss: 0.0163\n",
      "Epoch [335/500], Training Loss: 0.0015\n",
      "Epoch [336/500], Training Loss: 0.0104\n",
      "Epoch [337/500], Training Loss: 0.0057\n",
      "Epoch [338/500], Training Loss: 0.0000\n",
      "Epoch [339/500], Training Loss: 0.0079\n",
      "Epoch [340/500], Training Loss: 0.0000\n",
      "Epoch [341/500], Training Loss: 0.0071\n",
      "Epoch [342/500], Training Loss: 0.0000\n",
      "Epoch [343/500], Training Loss: 0.0406\n",
      "Epoch [344/500], Training Loss: 0.0004\n",
      "Epoch [345/500], Training Loss: 0.0085\n",
      "Epoch [346/500], Training Loss: 0.0022\n",
      "Epoch [347/500], Training Loss: 0.0004\n",
      "Epoch [348/500], Training Loss: 0.0033\n",
      "Epoch [349/500], Training Loss: 0.0030\n",
      "Epoch [350/500], Training Loss: 0.0123\n",
      "Epoch [351/500], Training Loss: 0.0138\n",
      "Epoch [352/500], Training Loss: 0.0000\n",
      "Epoch [353/500], Training Loss: 0.0006\n",
      "Epoch [354/500], Training Loss: 0.0018\n",
      "Epoch [355/500], Training Loss: 0.0022\n",
      "Epoch [356/500], Training Loss: 0.0284\n",
      "Epoch [357/500], Training Loss: 0.0089\n",
      "Epoch [358/500], Training Loss: 0.0129\n",
      "Epoch [359/500], Training Loss: 0.0010\n",
      "Epoch [360/500], Training Loss: 0.0142\n",
      "Epoch [361/500], Training Loss: 0.0014\n",
      "Epoch [362/500], Training Loss: 0.0017\n",
      "Epoch [363/500], Training Loss: 0.0537\n",
      "Epoch [364/500], Training Loss: 0.0250\n",
      "Epoch [365/500], Training Loss: 0.0018\n",
      "Epoch [366/500], Training Loss: 0.0031\n",
      "Epoch [367/500], Training Loss: 0.0125\n",
      "Epoch [368/500], Training Loss: 0.0018\n",
      "Epoch [369/500], Training Loss: 0.0248\n",
      "Epoch [370/500], Training Loss: 0.0014\n",
      "Epoch [371/500], Training Loss: 0.0072\n",
      "Epoch [372/500], Training Loss: 0.0004\n",
      "Epoch [373/500], Training Loss: 0.0182\n",
      "Epoch [374/500], Training Loss: 0.0132\n",
      "Epoch [375/500], Training Loss: 0.0359\n",
      "Epoch [376/500], Training Loss: 0.0036\n",
      "Epoch [377/500], Training Loss: 0.0025\n",
      "Epoch [378/500], Training Loss: 0.0003\n",
      "Epoch [379/500], Training Loss: 0.0269\n",
      "Epoch [380/500], Training Loss: 0.0057\n",
      "Epoch [381/500], Training Loss: 0.0115\n",
      "Epoch [382/500], Training Loss: 0.0253\n",
      "Epoch [383/500], Training Loss: 0.0009\n",
      "Epoch [384/500], Training Loss: 0.0007\n",
      "Epoch [385/500], Training Loss: 0.0037\n",
      "Epoch [386/500], Training Loss: 0.0004\n",
      "Epoch [387/500], Training Loss: 0.0046\n",
      "Epoch [388/500], Training Loss: 0.0004\n",
      "Epoch [389/500], Training Loss: 0.0088\n",
      "Epoch [390/500], Training Loss: 0.0000\n",
      "Epoch [391/500], Training Loss: 0.0046\n",
      "Epoch [392/500], Training Loss: 0.0000\n",
      "Epoch [393/500], Training Loss: 0.0000\n",
      "Epoch [394/500], Training Loss: 0.0579\n",
      "Epoch [395/500], Training Loss: 0.0348\n",
      "Epoch [396/500], Training Loss: 0.0073\n",
      "Epoch [397/500], Training Loss: 0.0084\n",
      "Epoch [398/500], Training Loss: 0.0131\n",
      "Epoch [399/500], Training Loss: 0.0000\n",
      "Epoch [400/500], Training Loss: 0.0004\n",
      "Epoch [401/500], Training Loss: 0.0023\n",
      "Epoch [402/500], Training Loss: 0.1407\n",
      "Epoch [403/500], Training Loss: 0.0120\n",
      "Epoch [404/500], Training Loss: 0.0002\n",
      "Epoch [405/500], Training Loss: 0.0078\n",
      "Epoch [406/500], Training Loss: 0.0001\n",
      "Epoch [407/500], Training Loss: 0.0049\n",
      "Epoch [408/500], Training Loss: 0.0000\n",
      "Epoch [409/500], Training Loss: 0.0007\n",
      "Epoch [410/500], Training Loss: 0.0005\n",
      "Epoch [411/500], Training Loss: 0.0051\n",
      "Epoch [412/500], Training Loss: 0.0036\n",
      "Epoch [413/500], Training Loss: 0.0005\n",
      "Epoch [414/500], Training Loss: 0.0050\n",
      "Epoch [415/500], Training Loss: 0.0058\n",
      "Epoch [416/500], Training Loss: 0.0008\n",
      "Epoch [417/500], Training Loss: 0.0030\n",
      "Epoch [418/500], Training Loss: 0.0022\n",
      "Epoch [419/500], Training Loss: 0.0053\n",
      "Epoch [420/500], Training Loss: 0.0000\n",
      "Epoch [421/500], Training Loss: 0.0253\n",
      "Epoch [422/500], Training Loss: 0.0028\n",
      "Epoch [423/500], Training Loss: 0.0024\n",
      "Epoch [424/500], Training Loss: 0.0002\n",
      "Epoch [425/500], Training Loss: 0.0000\n",
      "Epoch [426/500], Training Loss: 0.0176\n",
      "Epoch [427/500], Training Loss: 0.0151\n",
      "Epoch [428/500], Training Loss: 0.0067\n",
      "Epoch [429/500], Training Loss: 0.0036\n",
      "Epoch [430/500], Training Loss: 0.0001\n",
      "Epoch [431/500], Training Loss: 0.0021\n",
      "Epoch [432/500], Training Loss: 0.0000\n",
      "Epoch [433/500], Training Loss: 0.0094\n",
      "Epoch [434/500], Training Loss: 0.0002\n",
      "Epoch [435/500], Training Loss: 0.0015\n",
      "Epoch [436/500], Training Loss: 0.0280\n",
      "Epoch [437/500], Training Loss: 0.0274\n",
      "Epoch [438/500], Training Loss: 0.0134\n",
      "Epoch [439/500], Training Loss: 0.0004\n",
      "Epoch [440/500], Training Loss: 0.0000\n",
      "Epoch [441/500], Training Loss: 0.0046\n",
      "Epoch [442/500], Training Loss: 0.0014\n",
      "Epoch [443/500], Training Loss: 0.0045\n",
      "Epoch [444/500], Training Loss: 0.0000\n",
      "Epoch [445/500], Training Loss: 0.0020\n",
      "Epoch [446/500], Training Loss: 0.0177\n",
      "Epoch [447/500], Training Loss: 0.0281\n",
      "Epoch [448/500], Training Loss: 0.0175\n",
      "Epoch [449/500], Training Loss: 0.0025\n",
      "Epoch [450/500], Training Loss: 0.0014\n",
      "Epoch [451/500], Training Loss: 0.0021\n",
      "Epoch [452/500], Training Loss: 0.0033\n",
      "Epoch [453/500], Training Loss: 0.0001\n",
      "Epoch [454/500], Training Loss: 0.0005\n",
      "Epoch [455/500], Training Loss: 0.0129\n",
      "Epoch [456/500], Training Loss: 0.0028\n",
      "Epoch [457/500], Training Loss: 0.0131\n",
      "Epoch [458/500], Training Loss: 0.0057\n",
      "Epoch [459/500], Training Loss: 0.0022\n",
      "Epoch [460/500], Training Loss: 0.0007\n",
      "Epoch [461/500], Training Loss: 0.0004\n",
      "Epoch [462/500], Training Loss: 0.0008\n",
      "Epoch [463/500], Training Loss: 0.0267\n",
      "Epoch [464/500], Training Loss: 0.0282\n",
      "Epoch [465/500], Training Loss: 0.0126\n",
      "Epoch [466/500], Training Loss: 0.0002\n",
      "Epoch [467/500], Training Loss: 0.0006\n",
      "Epoch [468/500], Training Loss: 0.0014\n",
      "Epoch [469/500], Training Loss: 0.0010\n",
      "Epoch [470/500], Training Loss: 0.0198\n",
      "Epoch [471/500], Training Loss: 0.0173\n",
      "Epoch [472/500], Training Loss: 0.0077\n",
      "Epoch [473/500], Training Loss: 0.0117\n",
      "Epoch [474/500], Training Loss: 0.0029\n",
      "Epoch [475/500], Training Loss: 0.0028\n",
      "Epoch [476/500], Training Loss: 0.0151\n",
      "Epoch [477/500], Training Loss: 0.0029\n",
      "Epoch [478/500], Training Loss: 0.0000\n",
      "Epoch [479/500], Training Loss: 0.0024\n",
      "Epoch [480/500], Training Loss: 0.0043\n",
      "Epoch [481/500], Training Loss: 0.0000\n",
      "Epoch [482/500], Training Loss: 0.0016\n",
      "Epoch [483/500], Training Loss: 0.0100\n",
      "Epoch [484/500], Training Loss: 0.0180\n",
      "Epoch [485/500], Training Loss: 0.0061\n",
      "Epoch [486/500], Training Loss: 0.0046\n",
      "Epoch [487/500], Training Loss: 0.0004\n",
      "Epoch [488/500], Training Loss: 0.0027\n",
      "Epoch [489/500], Training Loss: 0.0013\n",
      "Epoch [490/500], Training Loss: 0.0085\n",
      "Epoch [491/500], Training Loss: 0.0037\n",
      "Epoch [492/500], Training Loss: 0.0008\n",
      "Epoch [493/500], Training Loss: 0.0180\n",
      "Epoch [494/500], Training Loss: 0.0031\n",
      "Epoch [495/500], Training Loss: 0.0008\n",
      "Epoch [496/500], Training Loss: 0.0003\n",
      "Epoch [497/500], Training Loss: 0.0137\n",
      "Epoch [498/500], Training Loss: 0.0094\n",
      "Epoch [499/500], Training Loss: 0.0038\n",
      "Epoch [500/500], Training Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs =500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\username\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([33])) that is different to the input size (torch.Size([33, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f'Test Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set: 0.39505788683891296\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs)\n",
    "        actuals.append(targets)\n",
    "\n",
    "predictions = torch.cat(predictions).cpu().numpy()\n",
    "actuals = torch.cat(actuals).cpu().numpy()\n",
    "\n",
    "\n",
    "rmse = root_mean_squared_error(actuals,predictions)\n",
    "print(f'RMSE on validation set: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f197b26f80>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions[:700])\n",
    "plt.plot(actuals[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66, 0.64, 0.61, ..., 1.2 , 1.23, 1.28], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_test = f\"C:/Users/username/OneDrive/Desktop/BGprediction/OhioT1DM/2018/test/570-ws-testing.xml\"\n",
    "glucose_test = read_ohio(filepath, \"glucose_level\", False)\n",
    "glucose_df_test = transfer_into_table(glucose_test)\n",
    "segments_test = segement_data_as_15min(glucose_df_test) # segment\n",
    "# interpolated_segements_test = detect_missing_and_spline_interpolate(segments_test) #spline interpolate\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
