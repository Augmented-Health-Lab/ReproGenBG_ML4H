{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Link', 'Code Available?', 'Public Dataset',\n",
      "       'Private Dataset', 'Multiple Datasets?',\n",
      "       'Dataset Distribution included?', 'Sample size for Evaluation ',\n",
      "       'Hyperparameters Reported?',\n",
      "       'Method for tuning hyperparameters reported?',\n",
      "       'Evaluation metric reported (RMSE / MAPE, MAE)',\n",
      "       'Include all reported prediction horizon (like, future 30, future 60 ...)',\n",
      "       'Sampling horizon', 'Baseline included?', 'Variance Reported?',\n",
      "       'other lifestyle factors applied to train model',\n",
      "       'Best reported result (prediction horizon) 30 is the primary',\n",
      "       'Best reported metric', 'Best reported prediction horizon',\n",
      "       'model type ', 'Link.1', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23',\n",
      "       'Unnamed: 24', 'Unnamed: 25'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "literature = pd.read_csv('./literature_cleaned.csv')\n",
    "columns = literature.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Available?\n",
      "No     42\n",
      "Yes    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Code Available?'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20754716981132076"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'OhioT1DM': 29\n",
      "Number of rows without 'OhioT1DM': 31\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with \"OhioT1DM\" in the \"Public Dataset\" column\n",
    "ohio_count = literature[literature['Public Dataset'].str.contains('OhioT1DM', na=False)].shape[0]\n",
    "\n",
    "# Count the number of rows without \"OhioT1DM\" in the \"Public Dataset\" column\n",
    "not_ohio_count = literature[~literature['Public Dataset'].str.contains('OhioT1DM', na=False)].shape[0]\n",
    "\n",
    "print(f\"Number of rows with 'OhioT1DM': {ohio_count}\")\n",
    "print(f\"Number of rows without 'OhioT1DM': {not_ohio_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Dataset\n",
      "OhioT1DM                                18\n",
      "OhioT1DM                                 7\n",
      "DirecNet                                 4\n",
      "OhioT1DM, ShanghaiT1DM, ShanghaiT2DM     2\n",
      "RT-CGM                                   2\n",
      "UCI ML Repository                        1\n",
      "OhioT1DM, Maastricht Study               1\n",
      "ShanghaiT1DM                             1\n",
      "Yes, also SUCH, but earlier data         1\n",
      "DirectNet, AI4PG                         1\n",
      "MIMIC-III                                1\n",
      "ShanghaiT1DM, ShanghaiT2DM               1\n",
      "Custom Open-Source                       1\n",
      "OhioT1DM, DCLP3, DCLP5, RT-CGM           1\n",
      "D1NAMO                                   1\n",
      "GEM-GDM                                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Public Dataset'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN rows in 'Public Dataset': 16\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "na_count = literature[\"Public Dataset\"].isna().sum()\n",
    "print(f\"Number of NaN rows in 'Public Dataset': {na_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301886792452831"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public dataset\n",
    "44/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Datasets?\n",
      "No     35\n",
      "Yes    18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Multiple Datasets?'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters Reported?\n",
      "Yes       35\n",
      "Partly    10\n",
      "No         7\n",
      "Yes        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Hyperparameters Reported?'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method for tuning hyperparameters reported?\n",
      "No                                         22\n",
      "Yes                                        15\n",
      "Grid Search                                 8\n",
      "Grid search                                 4\n",
      "Hyperband Tuner                             1\n",
      "Lipschitz order index, OBS, Grid Search     1\n",
      "Tabu search                                 1\n",
      "Trial and Error                             1\n",
      "IPSO Algorithm                              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Method for tuning hyperparameters reported?'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5849056603773585"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter tuning reported ratio\n",
    "(53-22)/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reported prediction horizon\n",
      "30          44\n",
      "60           2\n",
      "120          1\n",
      "15           1\n",
      "30 (APE)     1\n",
      "NAN          1\n",
      "120 (R)      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the column name\n",
    "column_name = 'Best reported prediction horizon'\n",
    "\n",
    "# Print the count of different types of values in the specified column\n",
    "value_counts = literature[column_name].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301886792452831"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 prediction horizon reported ratio\n",
    "44/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9245283018867925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49/53 # Only 4 paper didn't report the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           30\n",
       "1           30\n",
       "2           30\n",
       "3           30\n",
       "4           30\n",
       "5          NaN\n",
       "6           30\n",
       "7           30\n",
       "8           30\n",
       "9           30\n",
       "10         NaN\n",
       "11          30\n",
       "12         NaN\n",
       "13          30\n",
       "14          30\n",
       "15          30\n",
       "16          30\n",
       "17          30\n",
       "18          30\n",
       "19          30\n",
       "20          30\n",
       "21         NaN\n",
       "22          30\n",
       "23          30\n",
       "24          30\n",
       "25          60\n",
       "26          30\n",
       "27          30\n",
       "28         120\n",
       "29          15\n",
       "30          30\n",
       "31          30\n",
       "32         NaN\n",
       "33          30\n",
       "34          30\n",
       "35         NaN\n",
       "36          30\n",
       "37          30\n",
       "38          30\n",
       "39          60\n",
       "40          30\n",
       "41         NaN\n",
       "42          30\n",
       "43          30\n",
       "44    30 (APE)\n",
       "45          30\n",
       "46          30\n",
       "47          30\n",
       "48          30\n",
       "49          30\n",
       "50          30\n",
       "51         NAN\n",
       "52         NaN\n",
       "53          30\n",
       "54          30\n",
       "55          30\n",
       "56         NaN\n",
       "57          30\n",
       "58          30\n",
       "59     120 (R)\n",
       "Name: Best reported prediction horizon, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature[\"Best reported prediction horizon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "Metric Range\n",
      "0-5       1\n",
      "5-10      6\n",
      "10-15     2\n",
      "15-20    26\n",
      "20-25     8\n",
      "25-30     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratios:\n",
      "Metric Range\n",
      "0-5      0.022727\n",
      "5-10     0.136364\n",
      "10-15    0.045455\n",
      "15-20    0.590909\n",
      "20-25    0.181818\n",
      "25-30    0.022727\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/tbqtlr256g5b8t969rk8d5kr0000gn/T/ipykernel_60496/137885431.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"Metric Range\"] = pd.cut(filtered_df[\"Best reported metric\"], bins=bins, labels=labels, right=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Filter rows where \"Best reported prediction horizon\" equals 30\n",
    "# Convert \"Best reported prediction horizon\" to integer format\n",
    "# Convert \"Best reported prediction horizon\" to numeric format, coercing errors to NaN\n",
    "literature[\"Best reported prediction horizon\"] = pd.to_numeric(\n",
    "    literature[\"Best reported prediction horizon\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Handle NaN values (e.g., drop rows with NaN in this column)\n",
    "literature = literature.dropna(subset=[\"Best reported prediction horizon\"])\n",
    "\n",
    "# Convert the column to integer format\n",
    "literature[\"Best reported prediction horizon\"] = literature[\"Best reported prediction horizon\"].astype(int)\n",
    "\n",
    "filtered_df = literature[literature[\"Best reported prediction horizon\"] == 30]\n",
    "\n",
    "# Define bins and labels for the ranges\n",
    "bins = [0, 5, 10, 15, 20, 25, 30]\n",
    "labels = [\"0-5\", \"5-10\", \"10-15\", \"15-20\", \"20-25\", \"25-30\"]\n",
    "\n",
    "# Categorize \"Best reported metric\" into ranges\n",
    "filtered_df[\"Metric Range\"] = pd.cut(filtered_df[\"Best reported metric\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Calculate count and ratio for each range\n",
    "range_counts = filtered_df[\"Metric Range\"].value_counts(sort=False)\n",
    "range_ratios = range_counts / range_counts.sum()\n",
    "\n",
    "# Display the results\n",
    "print(\"Counts:\")\n",
    "print(range_counts)\n",
    "print(\"\\nRatios:\")\n",
    "print(range_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
