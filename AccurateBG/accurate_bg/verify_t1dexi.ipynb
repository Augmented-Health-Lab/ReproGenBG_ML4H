{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from cgms_data_seg_t1dexi import CGMSDataSeg\n",
    "from cnn_ohio import regressor, regressor_transfer, test_ckpt\n",
    "from data_reader_T1DEXI import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "List of devices available to TensorFlow:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# New method in TensorFlow 2.x:\n",
    "# This will list the devices TensorFlow recognizes\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"List of devices available to TensorFlow:\")\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess_cgm_data(subj):\n",
    "    subject = pd.read_csv(f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/{subj}.csv')\n",
    "    subject_cgm = subject.loc[subject['LBCAT'] == 'CGM']\n",
    "    # Convert the 'LBDTC' column to datetime\n",
    "    subject_cgm['LBDTC'] = pd.to_datetime(subject_cgm['LBDTC'])\n",
    "    # Extract the date part\n",
    "    subject_cgm['date'] = subject_cgm['LBDTC'].dt.date\n",
    "    return subject_cgm\n",
    "    # Count the number of occurrences of each unique date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = ['854',\n",
    " '979',\n",
    " '816',\n",
    " '953',\n",
    " '981',\n",
    " '1617',\n",
    " '1343',\n",
    " '987',\n",
    " '255',\n",
    " '907',\n",
    " '856',\n",
    " '354',\n",
    " '894',\n",
    " '862',\n",
    " '900',\n",
    " '695']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training and testing\n",
    "# Generate folder for training and test data\n",
    "\n",
    "for subj in overlap:\n",
    "    subject = pd.read_csv(f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/{subj}.csv')\n",
    "    subject_cgm = subject.loc[subject['LBCAT'] == 'CGM']\n",
    "    \n",
    "    split_index = int(len(subject_cgm) * 0.8)\n",
    "    # Split the DataFrame\n",
    "    train_df = subject[:split_index]\n",
    "    test_df = subject[split_index:]\n",
    "\n",
    "    # Save the DataFrames to CSV files\n",
    "    train_df.to_csv(f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/training/{subj}_training_data.csv', index=False)\n",
    "    test_df.to_csv(f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/testing/{subj}_testing_data.csv', index=False)\n",
    "\n",
    "    # Optionally, confirm the operation\n",
    "    print(f\"Training data saved with {len(train_df)} records.\")\n",
    "    print(f\"Testing data saved with {len(test_df)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess_cgm_training(subj):\n",
    "    subject_cgm = pd.read_csv(f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/training/{subj}_training_data.csv')\n",
    "\n",
    "    subject_cgm['LBDTC'] = pd.to_datetime(subject_cgm['LBDTC'])\n",
    "    # Extract the date part\n",
    "    subject_cgm['date'] = subject_cgm['LBDTC'].dt.date\n",
    "    subject_cgm_concise = subject_cgm[[\"LBORRES\", \"LBDTC\"]]\n",
    "    return subject_cgm_concise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example \n",
    "subject_cgm = read_preprocess_cgm_training(overlap[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Segment the data into several pieces\n",
    "# Assuming self.interval_timedelta is set, for example:\n",
    "interval_timedelta = datetime.timedelta(minutes=6)  # Example timedelta of 6 minutes, providing a range for latency\n",
    "\n",
    "# Create a list to store the results\n",
    "res = []\n",
    "\n",
    "# Initialize the first group\n",
    "if not subject_cgm.empty:\n",
    "    current_group = [subject_cgm.iloc[0]['LBORRES']]\n",
    "    last_time = subject_cgm.iloc[0]['LBDTC']\n",
    "\n",
    "# Iterate over rows in DataFrame starting from the second row\n",
    "for index, row in subject_cgm.iloc[1:].iterrows():\n",
    "    current_time = row['LBDTC']\n",
    "    if (current_time - last_time) <= interval_timedelta:\n",
    "        # If the time difference is within the limit, add to the current group\n",
    "        current_group.append(row['LBORRES'])\n",
    "    else:\n",
    "        # Otherwise, start a new group\n",
    "        res.append(current_group)\n",
    "        current_group = [row['LBORRES']]\n",
    "    last_time = current_time\n",
    "\n",
    "# Add the last group if it's not empty\n",
    "if current_group:\n",
    "    res.append(current_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocess_cgm_training(subj):\n",
    "    subject_cgm = pd.read_csv(subj)\n",
    "\n",
    "    subject_cgm['LBDTC'] = pd.to_datetime(subject_cgm['LBDTC'])\n",
    "    # Extract the date part\n",
    "    subject_cgm['date'] = subject_cgm['LBDTC'].dt.date\n",
    "    subject_cgm_concise = subject_cgm[[\"LBORRES\", \"LBDTC\"]]\n",
    "    return subject_cgm_concise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preporcess_T1DEXI(subject_id):\n",
    "    subject_cgm = read_preprocess_cgm_training(subject_id)\n",
    "    interval_timedelta = datetime.timedelta(minutes=6)  # Example timedelta of 6 minutes, providing a range for latency\n",
    "\n",
    "    # Create a list to store the results\n",
    "    res = []\n",
    "\n",
    "    # Initialize the first group\n",
    "    if not subject_cgm.empty:\n",
    "        current_group = [subject_cgm.iloc[0]['LBORRES']]\n",
    "        last_time = subject_cgm.iloc[0]['LBDTC']\n",
    "\n",
    "    # Iterate over rows in DataFrame starting from the second row\n",
    "    for index, row in subject_cgm.iloc[1:].iterrows():\n",
    "        current_time = row['LBDTC']\n",
    "        if (current_time - last_time) <= interval_timedelta:\n",
    "            # If the time difference is within the limit, add to the current group\n",
    "            current_group.append(row['LBORRES'])\n",
    "        else:\n",
    "            # Otherwise, start a new group\n",
    "            res.append(current_group)\n",
    "            current_group = [row['LBORRES']]\n",
    "        last_time = current_time\n",
    "\n",
    "    # Add the last group if it's not empty\n",
    "    if current_group:\n",
    "        res.append(current_group)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For loop to generate res for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "train_directory_path = r'C:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\LB_split\\training'  # Use a raw string for paths on Windows\n",
    "\n",
    "# List files without their extensions\n",
    "train_file_names = [os.path.splitext(file)[0] for file in os.listdir(train_directory_path)\n",
    "              if os.path.isfile(os.path.join(train_directory_path, file))]\n",
    "\n",
    "# Print the list of file names\n",
    "print(train_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1343_testing_data', '1617_testing_data', '255_testing_data', '354_testing_data', '695_testing_data', '816_testing_data', '854_testing_data', '856_testing_data', '862_testing_data', '894_testing_data', '900_testing_data', '907_testing_data', '953_testing_data', '979_testing_data', '981_testing_data', '987_testing_data']\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "test_directory_path = r'C:\\Users\\username\\OneDrive\\Desktop\\BGprediction\\LB_split\\testing'  # Use a raw string for paths on Windows\n",
    "\n",
    "# List files without their extensions\n",
    "test_file_names = [os.path.splitext(file)[0] for file in os.listdir(test_directory_path)\n",
    "              if os.path.isfile(os.path.join(test_directory_path, file))]\n",
    "\n",
    "# Print the list of file names\n",
    "print(test_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343_training_data\n",
      "1617_training_data\n",
      "255_training_data\n",
      "354_training_data\n",
      "695_training_data\n",
      "816_training_data\n",
      "854_training_data\n",
      "856_training_data\n",
      "862_training_data\n",
      "894_training_data\n",
      "900_training_data\n",
      "907_training_data\n",
      "953_training_data\n",
      "979_training_data\n",
      "981_training_data\n",
      "987_training_data\n"
     ]
    }
   ],
   "source": [
    "train_data = dict()\n",
    "for subj in train_file_names:\n",
    "    print(subj)\n",
    "    subj_path = f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/training/{subj}.csv'\n",
    "    reader = preporcess_T1DEXI(subj_path)\n",
    "    train_data[subj] = reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343_testing_data\n",
      "1617_testing_data\n",
      "255_testing_data\n",
      "354_testing_data\n",
      "695_testing_data\n",
      "816_testing_data\n",
      "854_testing_data\n",
      "856_testing_data\n",
      "862_testing_data\n",
      "894_testing_data\n",
      "900_testing_data\n",
      "907_testing_data\n",
      "953_testing_data\n",
      "979_testing_data\n",
      "981_testing_data\n",
      "987_testing_data\n"
     ]
    }
   ],
   "source": [
    "# Have not been run\n",
    "test_data = dict()\n",
    "for subj in test_file_names:\n",
    "    print(subj)\n",
    "    subj_path = f'C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/testing/{subj}.csv'\n",
    "    reader = preporcess_T1DEXI(subj_path)\n",
    "    test_data[subj] = reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "\n",
    "ph = 6 # Prediction horizon\n",
    "path = \"../t1dexi_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subjects = [s.replace(\"_training_data\", \"\") for s in train_file_names]\n",
    "cleaned_subjects.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:01:51\n",
      "Reading 8 segments\n"
     ]
    }
   ],
   "source": [
    "# a dumb dataset instance\n",
    "train_dataset = CGMSDataSeg(\n",
    "    \"ohio\", \"C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/training/255_training_data.csv\", 5\n",
    ")\n",
    "sampling_horizon = 7\n",
    "prediction_horizon = ph\n",
    "scale = 0.01\n",
    "outtype = \"Same\"\n",
    "# train on training dataset\n",
    "# k_size, nblock, nn_size, nn_layer, learning_rate, batch_size, epoch, beta\n",
    "with open(f'../t1dexi_results/config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "argv = (\n",
    "    config[\"k_size\"],\n",
    "    config[\"nblock\"],\n",
    "    config[\"nn_size\"],\n",
    "    config[\"nn_layer\"],\n",
    "    config[\"learning_rate\"],\n",
    "    config[\"batch_size\"],\n",
    "    epoch,\n",
    "    config[\"beta\"],\n",
    ")\n",
    "l_type = config[\"loss\"]\n",
    "# test on patients data\n",
    "outdir = os.path.join(path, f\"ph_{prediction_horizon}_{l_type}\")\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "all_errs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop\n",
    "standard = False  # do not use standard\n",
    "all_errs = []\n",
    "for pid in overlap:\n",
    "    # local_train_data = []\n",
    "    \n",
    "    # for k in train_data.keys():\n",
    "    #     if k != pid:\n",
    "    #         local_train_data += train_data[k]\n",
    "    train_pids = set(overlap) - set([pid])\n",
    "    local_train_data = []\n",
    "    for k in train_pids:\n",
    "        local_train_data += train_data[k + \"_training_data\"]\n",
    "    print(f\"Pretrain data: {sum([sum(x) for x in local_train_data])}\")\n",
    "\n",
    "    train_dataset.data = local_train_data\n",
    "    train_dataset.set_cutpoint = -1\n",
    "    train_dataset.reset(\n",
    "        sampling_horizon,\n",
    "        prediction_horizon,\n",
    "        scale,\n",
    "        100,\n",
    "        False,\n",
    "        outtype,\n",
    "        1,\n",
    "        standard,\n",
    "    )\n",
    "    regressor(train_dataset, *argv, l_type, outdir)\n",
    "    # Fine-tune and test\n",
    "    # target_test_dataset = CGMSDataSeg(\n",
    "    #     \"ohio\", f\"C:/Users/username/OneDrive/Desktop/BGprediction/OhioT1DM/2018/test/{pid}-ws-testing.xml\", 5\n",
    "    # )\n",
    "    target_test_dataset = CGMSDataSeg(\n",
    "    \"ohio\", f\"C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/testing/{pid}_testing_data.csv\", 5\n",
    "    )\n",
    "    target_test_dataset.set_cutpoint = 1\n",
    "    target_test_dataset.reset(\n",
    "        sampling_horizon,\n",
    "        prediction_horizon,\n",
    "        scale,\n",
    "        0.01,\n",
    "        False,\n",
    "        outtype,\n",
    "        1,\n",
    "        standard,\n",
    "    )\n",
    "    # target_train_dataset = CGMSDataSeg(\n",
    "    #     \"ohio\", f\"C:/Users/username/OneDrive/Desktop/BGprediction/OhioT1DM/2018/test/{pid}-ws-testing.xml\", 5\n",
    "    # )\n",
    "    target_train_dataset = CGMSDataSeg(\n",
    "    \"ohio\", f\"C:/Users/username/OneDrive/Desktop/BGprediction/LB_split/training/{pid}_training_data.csv\", 5\n",
    "    )\n",
    "    target_train_dataset.set_cutpoint = -1\n",
    "    target_train_dataset.reset(\n",
    "        sampling_horizon,\n",
    "        prediction_horizon,\n",
    "        scale,\n",
    "        100,\n",
    "        False,\n",
    "        outtype,\n",
    "        1,\n",
    "        standard,\n",
    "    )\n",
    "    err, labels = test_ckpt(target_test_dataset, outdir)\n",
    "    errs = [err]\n",
    "    transfer_res = [labels]\n",
    "    for i in range(1, 2):\n",
    "        err, labels = regressor_transfer(\n",
    "            target_train_dataset,\n",
    "            target_test_dataset,\n",
    "            config[\"batch_size\"],\n",
    "            epoch,\n",
    "            outdir,\n",
    "            i,\n",
    "        )\n",
    "        errs.append(err)\n",
    "        transfer_res.append(labels)\n",
    "    transfer_res = np.concatenate(transfer_res, axis=1)\n",
    "    print(transfer_res)\n",
    "    np.savetxt(\n",
    "        f\"{outdir}/{pid}.txt\",\n",
    "        transfer_res,\n",
    "        fmt=\"%.4f %.4f %.4f %.4f\", #%.4f %.4f %.4f %.4f\n",
    "    )\n",
    "    all_errs.append([pid] + errs)\n",
    "all_errs = np.array(all_errs)\n",
    "np.savetxt(f\"{outdir}/errors.txt\", all_errs, fmt=\"%s %.4f %.4f\") # %.4f %.4f\n",
    "# label pair:(groundTruth, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['854', '0.15074661', '0.14032947'],\n",
       "       ['979', '0.10964842', '0.1068475'],\n",
       "       ['816', '0.17296007', '0.15637168'],\n",
       "       ['953', '0.16875254', '0.16648282'],\n",
       "       ['981', '0.18782552', '0.1781756'],\n",
       "       ['1617', '0.18750052', '0.17405139'],\n",
       "       ['1343', '0.1479887', '0.12966709'],\n",
       "       ['987', '0.1956755', '0.18187545'],\n",
       "       ['255', '0.112035595', '0.11363354'],\n",
       "       ['907', '0.2046883', '0.18899176'],\n",
       "       ['856', '0.16526204', '0.15994464'],\n",
       "       ['354', '0.21569382', '0.21845779'],\n",
       "       ['894', '0.1430959', '0.14199'],\n",
       "       ['862', '0.2226933', '0.19469088'],\n",
       "       ['900', '0.14939056', '0.12725726'],\n",
       "       ['695', '0.16643564', '0.16699977']], dtype='<U32')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the second column: 0.16877456468750002\n",
      "Average of the third column: 0.159110415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the second and third columns to floats\n",
    "second_column = all_errs[:, 1].astype(float)\n",
    "third_column = all_errs[:, 2].astype(float)\n",
    "\n",
    "# Calculate the average\n",
    "average_second_column = np.mean(second_column)\n",
    "average_third_column = np.mean(third_column)\n",
    "\n",
    "print(\"Average of the second column:\", average_second_column)\n",
    "print(\"Average of the third column:\", average_third_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The altimate result please go into the result folder to check the evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run into an error, but all result txt files are ready, please run this section for evaluation\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# List all files and directories in the current directory\n",
    "files_and_directories = os.listdir('./t1dexi_results')\n",
    "\n",
    "# Filter for files that end with .txt\n",
    "txt_files = [file for file in files_and_directories if file.endswith('.txt')]\n",
    "\n",
    "# Read the data from the text file\n",
    "def calcuate_rmse(file):\n",
    "    data = np.loadtxt(file)  # Make sure to replace 'data.txt' with your actual file path\n",
    "    print(file)\n",
    "    # Splitting the data into groundtruth and predictions\n",
    "    groundtruth = data[:, 0]  # First column as ground truth (also same as third column)\n",
    "    predictions_1 = data[:, 1]  # Second column as predictions from method 1\n",
    "    predictions_2 = data[:, 3]  # Fourth column as predictions from method 2\n",
    "\n",
    "    # Function to calculate RMSE\n",
    "    def calculate_rmse(true_values, predictions):\n",
    "        mse = np.mean((true_values - predictions) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    # Calculate RMSE for each method\n",
    "    rmse_method_1 = calculate_rmse(groundtruth, predictions_1)\n",
    "    rmse_method_2 = calculate_rmse(groundtruth, predictions_2)\n",
    "\n",
    "    print(\"RMSE for Method 1:\", rmse_method_1)\n",
    "    print(\"RMSE for Method 2:\", rmse_method_2)\n",
    "    return rmse_method_1\n",
    "\n",
    "\n",
    "rmse_list = []\n",
    "for f in txt_files[:-1]:\n",
    "    rmse1 = calcuate_rmse(f)\n",
    "    print(rmse1)\n",
    "    rmse_list.append(rmse1)\n",
    "\n",
    "print(np.average(rmse_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
